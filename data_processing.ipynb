{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stephen King Novel NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:48:57.494641Z",
     "start_time": "2017-11-06T22:48:57.452850Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from pymongo import MongoClient\n",
    "import os\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from nltk.util import ngrams\n",
    "import operator\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from sklearn import datasets\n",
    "import json\n",
    "import spacy \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "display.clear_output(wait=True)\n",
    "from config import user_name,password,ip\n",
    "from epub_conversion.utils import open_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.846784Z",
     "start_time": "2017-11-06T22:11:11.830517Z"
    }
   },
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('english')\n",
    "stoplist += ['.', ',', '(', ')', \"'\", '\"']\n",
    "#stoplist = set(stoplist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.857174Z",
     "start_time": "2017-11-06T22:11:11.851624Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(row):\n",
    "    text = row['content'].lower()\n",
    "    text = text.strip('\\n')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.871933Z",
     "start_time": "2017-11-06T22:11:11.859951Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def book_word_count(book,n,stoplist=stoplist):\n",
    "    text = clean_text(book)\n",
    "    words = [''.join(words) for words in text.split()]\n",
    "    title = book['title']\n",
    "    counter = Counter()\n",
    "    n = n\n",
    "    words = [w for w in words if w not in stoplist]\n",
    "    bigrams = ngrams(words, n)\n",
    "    counter += Counter(bigrams)\n",
    "    sorted_counter = sorted(counter.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    return title, sorted_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T21:26:42.260226Z",
     "start_time": "2017-11-04T21:26:42.253791Z"
    }
   },
   "source": [
    "### Count Vectorizer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.887433Z",
     "start_time": "2017-11-06T22:11:11.875336Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def book_cv(dtbooks,stoplist):\n",
    "    cv = CountVectorizer(stop_words=stoplist,token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")\n",
    "    print(type(dtbooks[0]))\n",
    "    cv.fit(dtbooks)\n",
    "    x = cv.transform(dtbooks)\n",
    "    x_back = x.toarray()\n",
    "    df = pd.DataFrame(x_back, columns=cv.get_feature_names())\n",
    "    counts = cv.transform(dtbooks).transpose()\n",
    "    print(counts.shape)\n",
    "    corpus = matutils.Sparse2Corpus(counts)\n",
    "    id2word = dict((v, k) for k, v in cv.vocabulary_.items())\n",
    "    return df,corpus,id2word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.901170Z",
     "start_time": "2017-11-06T22:11:11.889883Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "#     topic_words = []\n",
    "#     for r in model.components_:\n",
    "#         a = sorted([(v,i) for i,v in enumerate(r)],reverse=True)[0:7]\n",
    "#         topic_words.append([books[e[1]-1] for e in a])\n",
    "#     return topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.908163Z",
     "start_time": "2017-11-06T22:11:11.904003Z"
    }
   },
   "outputs": [],
   "source": [
    "# def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "#     for topic_idx, topic in enumerate(H):\n",
    "#         print(\"Topic %d:\" % (topic_idx))\n",
    "#         print(\" \".join([feature_names[i]\n",
    "#                         for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "#         top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "#         for doc_index in top_doc_indices:\n",
    "#             print(documents[doc_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.916416Z",
     "start_time": "2017-11-06T22:11:11.911203Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanup(token, lower = True):\n",
    "    if lower:\n",
    "       token = token.lower()\n",
    "    return token.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.933292Z",
     "start_time": "2017-11-06T22:11:11.921208Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ie_preprocess(document):\n",
    "    document = ' '.join([i for i in document.split() if i not in stoplist])\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.950750Z",
     "start_time": "2017-11-06T22:11:11.942405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_names(document):\n",
    "    names = []\n",
    "    sentences = ie_preprocess(document)\n",
    "    for tagged_sentence in sentences:\n",
    "        for chunk in nltk.ne_chunk(tagged_sentence):\n",
    "            if type(chunk) == nltk.tree.Tree:\n",
    "                if chunk.label() == 'PERSON':\n",
    "                    names.append(' '.join([c[0] for c in chunk]))\n",
    "    return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.966435Z",
     "start_time": "2017-11-06T22:11:11.953882Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.980137Z",
     "start_time": "2017-11-06T22:11:11.969274Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a dictionary from all books**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.986503Z",
     "start_time": "2017-11-06T22:11:11.982319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# book_list = []\n",
    "# book_dict = {}\n",
    "# path = \"/Users/xavier/dev/metis/fletcher/books/\"\n",
    "# for file in os.listdir(path):\n",
    "#     if file.endswith(\".txt\"):\n",
    "#         clean_name = file.replace(\" - Stephen King.txt\",\"\")\n",
    "#         book_dict[clean_name] = open(path+file, \"r\").read()\n",
    "#         book_list.append(clean_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:11.997984Z",
     "start_time": "2017-11-06T22:11:11.990052Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Insert the books into mongo db\n",
    "# clean_list = []\n",
    "# for k,v in book_dict.items():\n",
    "#     try:\n",
    "#         year = re.search(\"[Cc]opyright ©\\s*.*_*(\\d{4}).*Stephen King|[Cc]opyright ©\\s.*Stephen King.*_*(\\d{4})|[Cc]opyright ©\\s*.*_*(\\d{4}).*Richard Bachman|[Cc]opyright ©\\s.*Richard Bachman.*_*(\\d{4})\",v).group(0) # get copyright year from book text\n",
    "#         year = re.search(\"(\\d{4})\",year).group(0)\n",
    "#     except:\n",
    "#         year = \"\"\n",
    "#     try:\n",
    "#         isbn = re.search(\".*ISBN+:*(\\d*.*)\",v)[1].split(\" \")\n",
    "#         isbn = max(isbn, key=len)\n",
    "#     except:\n",
    "#         isbn = \"\"\n",
    "#     try:\n",
    "#         start = v.find('******start_of_file******')+25\n",
    "#         end = v.find('******end_of_file******')\n",
    "#         text = v[start:end]\n",
    "#     except:\n",
    "#         text = \"\"\n",
    "        \n",
    "#     doc = {\"title\":k,\"year\":year,'isbn':isbn,\"content\":text}\n",
    "#     clean_list.append(doc)\n",
    "#     #print(doc['title'],doc['isbn'])\n",
    "#     #print(doc['title'],doc['year'])\n",
    "#     #db.books.insert_one(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:12.004052Z",
     "start_time": "2017-11-06T22:11:12.000744Z"
    }
   },
   "outputs": [],
   "source": [
    "# len(clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:12.012622Z",
     "start_time": "2017-11-06T22:11:12.006636Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #pd.DataFrame(a, index=['i',])\n",
    "# df = pd.DataFrame(clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:12.019406Z",
     "start_time": "2017-11-06T22:11:12.015168Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_pickle('books.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T21:26:34.672733Z",
     "start_time": "2017-11-06T21:26:34.669109Z"
    }
   },
   "source": [
    "### Import Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:12.230745Z",
     "start_time": "2017-11-06T22:11:12.022586Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('books.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:12.244676Z",
     "start_time": "2017-11-06T22:11:12.232878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content', 'isbn', 'title', 'year']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:12.279425Z",
     "start_time": "2017-11-06T22:11:12.249807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d by “Duel”\\n\\nJoe Hill and Stephen King\\n\\n\\n...</td>\n",
       "      <td>9780062215956</td>\n",
       "      <td>Throttle</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TS\\n\\n\\n\\nCover Page\\n\\nTitle Page\\n\\n\\n\\nIntr...</td>\n",
       "      <td>978-0-385-52884-9</td>\n",
       "      <td>Night Shift</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this Scribner eBook.\\n\\n\\n\\n* * *\\n\\n\\n\\nSign...</td>\n",
       "      <td>0-7432-0467-0</td>\n",
       "      <td>Riding the Bullet</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Page\\n\\nCopyright Page\\n\\nDedication\\n\\n\\n\\n\\...</td>\n",
       "      <td>978-1-101-13813-7</td>\n",
       "      <td>Roadwork</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dication\\n\\nIntroduction\\n\\nAuthor’s Note\\n\\n\\...</td>\n",
       "      <td>978-0-385-52822-1</td>\n",
       "      <td>Salem's Lot</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content               isbn  \\\n",
       "0  d by “Duel”\\n\\nJoe Hill and Stephen King\\n\\n\\n...      9780062215956   \n",
       "1  TS\\n\\n\\n\\nCover Page\\n\\nTitle Page\\n\\n\\n\\nIntr...  978-0-385-52884-9   \n",
       "2   this Scribner eBook.\\n\\n\\n\\n* * *\\n\\n\\n\\nSign...      0-7432-0467-0   \n",
       "3   Page\\n\\nCopyright Page\\n\\nDedication\\n\\n\\n\\n\\...  978-1-101-13813-7   \n",
       "4  dication\\n\\nIntroduction\\n\\nAuthor’s Note\\n\\n\\...  978-0-385-52822-1   \n",
       "\n",
       "               title  year  \n",
       "0           Throttle  2009  \n",
       "1        Night Shift  1976  \n",
       "2  Riding the Bullet  2000  \n",
       "3           Roadwork  1981  \n",
       "4        Salem's Lot  1975  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:12.286844Z",
     "start_time": "2017-11-06T22:11:12.282835Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document = df.iloc[28]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:12.293580Z",
     "start_time": "2017-11-06T22:11:12.289422Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['content'] = df.content.apply(lambda x: x.lower())\n",
    "# df['content'] = df.content.apply(lambda x: x.strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:12.301125Z",
     "start_time": "2017-11-06T22:11:12.296485Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# words = [''.join(words) for words in gs_text.split()]\n",
    "# vectorizer = TfidfVectorizer(stop_words=stop, ngram_range=(1))\n",
    "# doc_vectors = vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character extraction test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:27.661382Z",
     "start_time": "2017-11-06T22:11:12.303634Z"
    }
   },
   "outputs": [],
   "source": [
    "characters = extract_names(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:27.676261Z",
     "start_time": "2017-11-06T22:11:27.663767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Penguin Book',\n",
       " 'Stephen King',\n",
       " 'Penguin Putnam',\n",
       " 'Penguin Books',\n",
       " 'Penguin Putnam',\n",
       " 'Penguin Putnam',\n",
       " 'STEPHEN',\n",
       " 'Carrie',\n",
       " 'Salem',\n",
       " 'Christine Pet Sematary Cycle Werewolf',\n",
       " 'Peter Straub',\n",
       " 'Dolores Claiborne Insomnia Rose Madder',\n",
       " 'Wizard Glass Bag Bones',\n",
       " 'Tom Gordon Dreamcatcher Black House',\n",
       " 'Peter Straub',\n",
       " 'Skeleton Crew',\n",
       " 'Atlantis Everything',\n",
       " 'Eventual SCREENPLAYS Creepshow Cat',\n",
       " 'Eye Silver Bullet Maximum Overdrive Pet Sematary Golden',\n",
       " 'Century',\n",
       " 'Who',\n",
       " 'Merrys Pippins',\n",
       " 'Max Yasgur',\n",
       " 'Great Woodstock Music Festival',\n",
       " 'Gandalfs',\n",
       " 'Tolkien',\n",
       " 'Stephen Donaldson',\n",
       " 'Terry Brooks',\n",
       " 'Tolkien',\n",
       " 'Tolkien',\n",
       " 'Tricky Dick Nixon',\n",
       " 'Mr. Tolkien',\n",
       " 'Look',\n",
       " 'Stevie',\n",
       " 'Nineteen',\n",
       " 'Bob Seger',\n",
       " 'Patrol Boy',\n",
       " 'Bad Lieutenant',\n",
       " 'Patrol Boy',\n",
       " 'Mine',\n",
       " 'Stephen',\n",
       " 'God',\n",
       " 'Tolkien',\n",
       " 'Pall Malls',\n",
       " 'Patrol Boy',\n",
       " 'Maine',\n",
       " 'Sergio Leone',\n",
       " 'Bad',\n",
       " 'Ugly',\n",
       " 'Tolkien',\n",
       " 'Leone',\n",
       " 'Clint',\n",
       " 'Lee Van Cleef',\n",
       " 'Wizard Glass',\n",
       " 'Leone',\n",
       " 'Phoenix',\n",
       " 'Seems',\n",
       " 'Patrol Boy',\n",
       " 'From Buick',\n",
       " 'Dearborn',\n",
       " 'Michigan',\n",
       " 'Dark Tower',\n",
       " 'Varney Vampire',\n",
       " 'Tower',\n",
       " 'Beams',\n",
       " 'Tower',\n",
       " 'Dark Tower',\n",
       " 'Gramma',\n",
       " 'Outside',\n",
       " 'Me',\n",
       " 'Single',\n",
       " 'Marsha DiFilippo',\n",
       " 'Texas Florida',\n",
       " 'Chussit',\n",
       " 'Patrol Boy',\n",
       " 'Volume Five',\n",
       " 'Stephen',\n",
       " 'Dark Tower',\n",
       " 'Bullshit Rule',\n",
       " 'Dark',\n",
       " 'Tower',\n",
       " 'Dark Tower',\n",
       " 'Chaucer',\n",
       " 'Charles Dickens',\n",
       " 'Stephen',\n",
       " 'Volume Five',\n",
       " 'Volume Six',\n",
       " 'Volume Seven',\n",
       " 'Roland',\n",
       " 'God',\n",
       " 'Roland',\n",
       " 'Dark Tower',\n",
       " 'Dark Tower',\n",
       " 'Thomas',\n",
       " 'Wolfe Look Homeward',\n",
       " 'Had',\n",
       " 'Man Jesus',\n",
       " 'Philistine',\n",
       " 'God',\n",
       " 'Water',\n",
       " 'God',\n",
       " 'Jericho Hill',\n",
       " 'Weren',\n",
       " 'Cort',\n",
       " 'Old Mother',\n",
       " 'Silva',\n",
       " 'Man Jesus',\n",
       " 'Him',\n",
       " 'Algul Siento',\n",
       " 'Blue Haven Heaven',\n",
       " 'Manni',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Zoltan',\n",
       " 'Screw',\n",
       " 'Brown',\n",
       " 'Prayer',\n",
       " 'Lord',\n",
       " 'Brown',\n",
       " 'Thought',\n",
       " 'Did',\n",
       " 'Brown',\n",
       " 'Zoltan',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Zoltan',\n",
       " 'Screw',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'God',\n",
       " 'God',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Pappa',\n",
       " 'Brown',\n",
       " 'Zoltan',\n",
       " 'Tull',\n",
       " 'Sheemie',\n",
       " 'Brown',\n",
       " 'Didn',\n",
       " 'Tull',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Dinner',\n",
       " 'Brown',\n",
       " 'Roasted',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Garlan',\n",
       " 'Zoltan',\n",
       " 'Tull',\n",
       " 'Brown',\n",
       " 'Came',\n",
       " 'Pappa',\n",
       " 'Doc',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Tull',\n",
       " 'Tull',\n",
       " 'Tull',\n",
       " 'Hey Jude',\n",
       " 'Jude',\n",
       " 'Rub',\n",
       " 'Might',\n",
       " 'Charlie',\n",
       " 'Watch Me',\n",
       " 'Mouths',\n",
       " 'Beer',\n",
       " 'Don',\n",
       " 'Bread',\n",
       " 'Peddler',\n",
       " 'Moon',\n",
       " 'High Speech Gilead',\n",
       " 'High Speech',\n",
       " 'Numbed',\n",
       " 'Don',\n",
       " 'Reap',\n",
       " 'Mice',\n",
       " 'Nort',\n",
       " 'Jubal',\n",
       " 'Kennerly',\n",
       " 'Kennerly',\n",
       " 'Nort',\n",
       " 'Zachary',\n",
       " 'Amy Feldon',\n",
       " 'Aunt Mill',\n",
       " 'Allie',\n",
       " 'Tull',\n",
       " 'Wake',\n",
       " 'Don',\n",
       " 'Mistuh Norton',\n",
       " 'Aunt',\n",
       " 'Mill',\n",
       " 'Sheb',\n",
       " 'Aunt Mill',\n",
       " 'Aunt Mill',\n",
       " 'Thunder',\n",
       " 'Sheb',\n",
       " 'Sheb',\n",
       " 'Nort',\n",
       " 'Nort',\n",
       " 'Sheb',\n",
       " 'Allie',\n",
       " 'Nort',\n",
       " 'Nort',\n",
       " 'Hello',\n",
       " 'Allie',\n",
       " 'Kennerly',\n",
       " 'Sheb',\n",
       " 'Nort',\n",
       " 'Allie',\n",
       " 'Nort',\n",
       " 'Dim',\n",
       " 'Sooner',\n",
       " 'Life',\n",
       " 'Nort',\n",
       " 'Allie',\n",
       " 'Nort',\n",
       " 'Suppose',\n",
       " 'Land Death',\n",
       " 'Don',\n",
       " 'Walter',\n",
       " 'Dim',\n",
       " 'Sooner',\n",
       " 'Allie',\n",
       " 'Don',\n",
       " 'Nort',\n",
       " 'Kennerly',\n",
       " 'Someone',\n",
       " 'Hit',\n",
       " 'Kennerly',\n",
       " 'Soobie',\n",
       " 'Soobie',\n",
       " 'Ain',\n",
       " 'Kennerly',\n",
       " 'Ain',\n",
       " 'Book',\n",
       " 'Kennerly',\n",
       " 'Kennerly',\n",
       " 'Kennerly',\n",
       " 'Kennerly',\n",
       " 'Kennerly',\n",
       " 'Kennerly',\n",
       " 'Kennerly',\n",
       " 'Kennerly',\n",
       " 'Allie',\n",
       " 'Kennerly',\n",
       " 'Soobie',\n",
       " 'Kennerly',\n",
       " 'Allie',\n",
       " 'Sheb',\n",
       " 'Allie',\n",
       " 'Allie',\n",
       " 'Sheb',\n",
       " 'Spittle',\n",
       " 'Sheb',\n",
       " 'Allie',\n",
       " 'Allie',\n",
       " 'Sheb',\n",
       " 'Allie',\n",
       " 'Broken',\n",
       " 'Didn',\n",
       " 'Mejis',\n",
       " 'Mejis',\n",
       " 'Clean',\n",
       " 'Susan',\n",
       " 'Sheb',\n",
       " 'Eldred Jonas',\n",
       " 'Coffin Hunter',\n",
       " 'Sheb',\n",
       " 'Sabbath Tull',\n",
       " 'Allie',\n",
       " 'Allie',\n",
       " 'Kennerly',\n",
       " 'Castner',\n",
       " 'Allie',\n",
       " 'Sylvia Pittston',\n",
       " 'Mejis',\n",
       " 'Sylvia Pittston',\n",
       " 'Good Book',\n",
       " 'Daniel',\n",
       " 'David',\n",
       " 'Bathsheba',\n",
       " 'Samson',\n",
       " 'St. Paul',\n",
       " 'Damascus',\n",
       " 'Mary Golgotha.',\n",
       " 'Jezebel',\n",
       " 'Ahaz',\n",
       " 'O',\n",
       " 'Jesus',\n",
       " 'Lord',\n",
       " 'Star Wormword',\n",
       " 'LeMark',\n",
       " 'Lord',\n",
       " 'Watch Me',\n",
       " 'Jesus',\n",
       " 'Walter',\n",
       " 'Allie',\n",
       " 'Pittston',\n",
       " 'Jesus Savior',\n",
       " 'Jesus',\n",
       " 'Jonson',\n",
       " 'Lord Flies Serpents',\n",
       " 'Jonson',\n",
       " 'Jonson',\n",
       " 'Wit',\n",
       " 'Will',\n",
       " 'Main Street',\n",
       " 'Allie',\n",
       " 'Allie',\n",
       " 'Allie',\n",
       " 'Allie',\n",
       " 'Allie',\n",
       " 'Are',\n",
       " 'Sylvia Pittston',\n",
       " 'Pittston',\n",
       " 'Tongue',\n",
       " 'Antichrist.',\n",
       " 'Don',\n",
       " 'Don',\n",
       " 'Eye',\n",
       " 'Answer',\n",
       " 'Mountains',\n",
       " 'Crimson King',\n",
       " 'Kennerly',\n",
       " 'Ahead',\n",
       " 'Kennerly',\n",
       " 'Soobie',\n",
       " 'Kennerly',\n",
       " 'Kennerly',\n",
       " 'Soobie',\n",
       " 'Soobie',\n",
       " 'Allie',\n",
       " 'Sheb',\n",
       " 'God Tull',\n",
       " 'Allie',\n",
       " 'Allie',\n",
       " 'Sheb',\n",
       " 'Sheb',\n",
       " 'Sheb',\n",
       " 'Sheb Allie',\n",
       " 'Sylvia Pittston',\n",
       " 'Sheb',\n",
       " 'Aunt Mill',\n",
       " 'Sylvia Pittston',\n",
       " 'Eye Hand',\n",
       " 'Kennerly',\n",
       " 'Amy Feldon',\n",
       " 'Sylvia Pittston',\n",
       " 'Tull',\n",
       " 'None',\n",
       " 'Sheb',\n",
       " 'Kennerly',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Brown',\n",
       " 'Walk',\n",
       " 'Allie',\n",
       " 'Cort',\n",
       " 'Susan',\n",
       " 'Mejis',\n",
       " 'Cort',\n",
       " 'High Speech',\n",
       " 'Cort',\n",
       " 'John Chambers',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Zorro',\n",
       " 'Shaw',\n",
       " 'Times',\n",
       " 'Jake',\n",
       " 'Shaw',\n",
       " 'Who',\n",
       " 'Bama',\n",
       " 'Allie',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Tower',\n",
       " 'Tower',\n",
       " 'Chussit',\n",
       " 'Earth Science',\n",
       " 'Geography',\n",
       " 'None',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake Chambers',\n",
       " 'Lanes',\n",
       " 'Clay Blaisdell Western',\n",
       " 'Network',\n",
       " 'Bloomie',\n",
       " 'Shaw',\n",
       " 'Jake',\n",
       " 'Cadillac',\n",
       " 'Jake',\n",
       " 'Kiss',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Cort',\n",
       " 'Susan',\n",
       " 'Marten',\n",
       " 'Jonas',\n",
       " 'Susan',\n",
       " 'Drop',\n",
       " 'Clean Sea',\n",
       " 'Traveller',\n",
       " 'Rest',\n",
       " 'See',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Old',\n",
       " 'Old Mother',\n",
       " 'East Wing',\n",
       " 'Cuthbert Jamie',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Demon',\n",
       " 'Fathoms',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Off',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Marten',\n",
       " 'Round Table',\n",
       " 'Jake',\n",
       " 'Arthur Eld',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Marten',\n",
       " 'David',\n",
       " 'David',\n",
       " 'David',\n",
       " 'David',\n",
       " 'Cuthbert',\n",
       " 'Bert',\n",
       " 'Cort',\n",
       " 'Back Courts',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Aren',\n",
       " 'Davey',\n",
       " 'Cuthbert',\n",
       " 'Cort',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Tears',\n",
       " 'Cuthbert',\n",
       " 'Cort',\n",
       " 'Roland',\n",
       " 'Roland',\n",
       " 'Cort',\n",
       " 'Cuthbert',\n",
       " 'David',\n",
       " 'David',\n",
       " 'David',\n",
       " 'Cort',\n",
       " 'Roland',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Cuthbert',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Cuthbert',\n",
       " 'Cort',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Cort',\n",
       " 'Cuthbert',\n",
       " 'Cort',\n",
       " 'Cuthbert Allgood',\n",
       " 'Cuthbert',\n",
       " 'Cort',\n",
       " 'Roland',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Roland',\n",
       " 'Cort',\n",
       " 'Roland',\n",
       " 'Cuthbert',\n",
       " 'Hax',\n",
       " 'Bert',\n",
       " 'Guards',\n",
       " 'Guard',\n",
       " 'Don',\n",
       " 'Don',\n",
       " 'Maggie',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Someone',\n",
       " 'Cuthbert',\n",
       " 'Guards',\n",
       " 'Farson',\n",
       " 'Guard',\n",
       " 'Guard',\n",
       " 'Guard',\n",
       " 'Soldier',\n",
       " 'Guard',\n",
       " 'Taunton',\n",
       " 'Guard',\n",
       " 'Will',\n",
       " 'Guard',\n",
       " 'Hax',\n",
       " 'Soldier',\n",
       " 'Guard',\n",
       " 'Cuthbert',\n",
       " 'Roland',\n",
       " 'Hax',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Hax',\n",
       " 'Guard',\n",
       " 'Robeson',\n",
       " 'Cuthbert',\n",
       " 'Roland',\n",
       " 'Steven',\n",
       " 'Deschain',\n",
       " 'Hendrickson',\n",
       " 'Roland',\n",
       " 'Roland',\n",
       " 'Cuthbert',\n",
       " 'Does',\n",
       " 'Treason',\n",
       " 'Taunton',\n",
       " 'Cuthbert Vannay',\n",
       " 'Deschain',\n",
       " 'Father',\n",
       " 'Roland',\n",
       " 'Cook',\n",
       " 'Sooner',\n",
       " 'Roland',\n",
       " 'Hax',\n",
       " 'Susan',\n",
       " 'Oedipus',\n",
       " 'Farson',\n",
       " 'Gallows Hill Taunton Road',\n",
       " 'Cuthbert',\n",
       " 'Gilead',\n",
       " 'Cuthbert',\n",
       " 'Gallows Hill',\n",
       " 'Cuthbert',\n",
       " 'Roland',\n",
       " 'Cuthbert',\n",
       " 'Roland',\n",
       " 'Barony',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Roland',\n",
       " 'Roland',\n",
       " 'Cuthbert',\n",
       " 'Roland',\n",
       " 'Roland',\n",
       " 'Taunton',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Hax',\n",
       " 'Cuthbert',\n",
       " 'Hax',\n",
       " 'Hax',\n",
       " 'Hax',\n",
       " 'Bert',\n",
       " 'Cort',\n",
       " 'Cuthbert',\n",
       " 'Charles',\n",
       " 'Charles',\n",
       " 'Charles Charles',\n",
       " 'Hax',\n",
       " 'Guards Watch',\n",
       " 'Charles',\n",
       " 'Charles',\n",
       " 'Hax',\n",
       " 'Hax',\n",
       " 'Cuthbert',\n",
       " 'Roland',\n",
       " 'Bert',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Bert',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Cuthbert',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Vannay',\n",
       " 'Allie',\n",
       " 'Tull',\n",
       " 'Allie',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Cuthbert',\n",
       " 'Cuthbert',\n",
       " 'Far',\n",
       " 'Susan Delgado',\n",
       " 'Susan',\n",
       " 'Susan',\n",
       " 'Hey Jude',\n",
       " 'Jake',\n",
       " 'Roland',\n",
       " 'Mejis',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Susan Delgado',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'See',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Don',\n",
       " 'Jake',\n",
       " 'Cuthbert',\n",
       " 'Bert',\n",
       " 'Jake',\n",
       " 'Sylvia Pittston',\n",
       " 'Pittston',\n",
       " 'Jake',\n",
       " 'Cort',\n",
       " 'Gods',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Marten',\n",
       " 'Will',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Narcissus',\n",
       " 'Sunlight',\n",
       " 'Coherent',\n",
       " 'Susan',\n",
       " 'Make',\n",
       " 'Susan',\n",
       " 'Susan Delgado',\n",
       " 'Don',\n",
       " 'Sterile',\n",
       " 'Already',\n",
       " 'Wind',\n",
       " 'Jake',\n",
       " 'Empires',\n",
       " 'Dark Tower',\n",
       " 'Don',\n",
       " 'Marten',\n",
       " 'Sylvia Pittston',\n",
       " 'Tull',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Yar',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Trunks',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Will',\n",
       " 'Don',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Don',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Jake',\n",
       " 'Tower',\n",
       " 'Jake',\n",
       " 'Bible',\n",
       " 'Jesus Moses',\n",
       " 'Ulysses',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Aileen Ritter',\n",
       " 'Cort',\n",
       " 'Hax',\n",
       " 'Slow Mutants',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Patches',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Jeremiah',\n",
       " 'Jake',\n",
       " 'Allie',\n",
       " 'Tull',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Worlds',\n",
       " 'Coffee Thermos',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Cuthbert',\n",
       " 'Cort',\n",
       " 'Jake',\n",
       " 'Fresh Commala',\n",
       " 'Susan Delgado Mejis',\n",
       " 'Ball',\n",
       " 'Marten',\n",
       " 'Marten',\n",
       " 'Tet',\n",
       " 'Dinh Gilead',\n",
       " 'Marten',\n",
       " 'Gabrielle Verriss',\n",
       " 'Alan',\n",
       " 'Steven',\n",
       " 'Marten',\n",
       " 'Jake',\n",
       " 'Careful',\n",
       " 'Jake',\n",
       " 'Him',\n",
       " 'Roland',\n",
       " 'Jake',\n",
       " 'Handcar',\n",
       " 'Good',\n",
       " 'Jake',\n",
       " 'Good',\n",
       " 'Jake',\n",
       " 'Great Hall',\n",
       " 'Night Cotillion',\n",
       " 'Tull',\n",
       " 'Next',\n",
       " 'Cuthbert Allgood',\n",
       " 'Susan',\n",
       " 'Goodbye',\n",
       " 'Larchies',\n",
       " 'Jake',\n",
       " 'Roland',\n",
       " 'Da',\n",
       " 'Jake',\n",
       " 'Jake',\n",
       " 'Town',\n",
       " 'Tower',\n",
       " 'Dad',\n",
       " 'Roland',\n",
       " 'Full',\n",
       " 'Marten',\n",
       " 'Don',\n",
       " 'Marten',\n",
       " 'Are',\n",
       " 'Ro',\n",
       " 'Marten',\n",
       " 'Vannay',\n",
       " 'Cuthbert',\n",
       " 'Jamie',\n",
       " 'David',\n",
       " 'Marten',\n",
       " 'Marten',\n",
       " 'Marten',\n",
       " 'Cort',\n",
       " 'Marten',\n",
       " 'Marten',\n",
       " 'Marten',\n",
       " 'Will',\n",
       " 'Marten',\n",
       " 'Marten',\n",
       " 'Marten',\n",
       " 'Cort',\n",
       " 'Jamie',\n",
       " 'Roland',\n",
       " 'Cort',\n",
       " 'High Speech',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'High Speech',\n",
       " 'Cort',\n",
       " 'Rise',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Which',\n",
       " 'Great Hall',\n",
       " 'Cort',\n",
       " 'Marten',\n",
       " 'Cort',\n",
       " 'Roland',\n",
       " 'David',\n",
       " 'David',\n",
       " 'Hai',\n",
       " 'David',\n",
       " 'David',\n",
       " 'David',\n",
       " 'David',\n",
       " 'David',\n",
       " 'Great Hall',\n",
       " 'Mark',\n",
       " 'Great Hall',\n",
       " 'Garlan',\n",
       " 'Mohaine Desert',\n",
       " 'Jamie DeCurry',\n",
       " 'Cuthbert Allgood',\n",
       " 'Alain Johns',\n",
       " 'Thomas Whitman',\n",
       " 'Cuthbert',\n",
       " 'Marten',\n",
       " 'Has Cort',\n",
       " 'Cort',\n",
       " 'Eld',\n",
       " 'Cort',\n",
       " 'Steven Deschain',\n",
       " 'Cort',\n",
       " 'David',\n",
       " 'Did',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'David',\n",
       " 'Cort',\n",
       " 'Cuthbert',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'David',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'David',\n",
       " 'Cort',\n",
       " 'David',\n",
       " 'Kill',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'David',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Gran',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'David',\n",
       " 'Cort',\n",
       " 'Cort',\n",
       " 'Wipe',\n",
       " 'Cort',\n",
       " 'Fools',\n",
       " 'Given',\n",
       " 'Will',\n",
       " 'Cuthbert',\n",
       " 'Thomas Jamie',\n",
       " 'Cuthbert',\n",
       " 'Bert',\n",
       " 'Marten',\n",
       " 'Thomas Jamie',\n",
       " 'Cuthbert',\n",
       " 'Marten',\n",
       " 'Jake',\n",
       " 'Above',\n",
       " 'Slow Mutants',\n",
       " 'None',\n",
       " 'Jake',\n",
       " 'Jesus',\n",
       " 'Jake',\n",
       " 'Slow Mutie',\n",
       " 'Hold',\n",
       " 'Hard',\n",
       " 'Jake',\n",
       " 'Jersey Turnpike',\n",
       " 'Elmer Chambers',\n",
       " 'Sargasso',\n",
       " 'High Speech',\n",
       " 'Subway',\n",
       " 'Gas',\n",
       " 'Vannay',\n",
       " 'Okay',\n",
       " 'Feast Reaptide',\n",
       " 'Jake',\n",
       " 'Mother',\n",
       " 'Simon',\n",
       " 'Mother Says',\n",
       " 'Cuthbert',\n",
       " 'Jamie',\n",
       " 'Jake',\n",
       " 'Yar',\n",
       " 'Roland',\n",
       " 'Man Jesus',\n",
       " 'Hello',\n",
       " 'Tarot',\n",
       " 'Hanged Man',\n",
       " 'Tower',\n",
       " 'Cuthbert',\n",
       " 'Gather',\n",
       " 'Joshua',\n",
       " 'Are',\n",
       " 'Gilead',\n",
       " 'Mockery',\n",
       " 'Tower',\n",
       " 'Roland',\n",
       " 'Hanged Man',\n",
       " 'Na',\n",
       " 'Don',\n",
       " 'Don',\n",
       " 'Tower Hanged Man',\n",
       " 'Volcanoes',\n",
       " 'Okay',\n",
       " 'Dinosaurs',\n",
       " 'Vannay',\n",
       " 'Further',\n",
       " 'Light',\n",
       " 'Tower',\n",
       " 'Shaken',\n",
       " 'Walter',\n",
       " 'Dark Tower',\n",
       " 'Earth',\n",
       " 'Steven',\n",
       " 'Great All',\n",
       " 'Gunslinger',\n",
       " 'Tower',\n",
       " 'Daddy',\n",
       " 'Might',\n",
       " 'Horsehead Nebula',\n",
       " 'God',\n",
       " 'Mohaine Desert',\n",
       " 'Tower',\n",
       " 'Room',\n",
       " 'Afraid',\n",
       " 'Milky Way',\n",
       " 'Cort',\n",
       " 'Ageless',\n",
       " 'Stranger',\n",
       " 'Tower',\n",
       " 'Tower',\n",
       " 'Marten',\n",
       " 'Marten',\n",
       " 'Marten',\n",
       " 'Tower',\n",
       " 'Tower',\n",
       " 'Water',\n",
       " 'Oracle',\n",
       " 'Ware',\n",
       " 'Roland',\n",
       " 'Roland',\n",
       " 'Walter',\n",
       " 'Walter',\n",
       " 'Dark Tower',\n",
       " 'Bullshit Factor',\n",
       " 'Scribner',\n",
       " 'Farson',\n",
       " 'John Farson',\n",
       " 'Gilead']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:57:36.045739Z",
     "start_time": "2017-11-06T22:57:36.041680Z"
    }
   },
   "outputs": [],
   "source": [
    "stoplist = list(stoplist)\n",
    "stoplist.extend(characters)\n",
    "stoplist = set(stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:57:38.857090Z",
     "start_time": "2017-11-06T22:57:38.852191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hers', 'does', 'off', 'mustn', 'Charles Charles', 'as', 'this', 'Zachary', 'Bama', 'Ro', 'Mohaine Desert', 'Patrol Boy', 'there', 'Sooner', 'shouldn', 'Sabbath Tull', 'High Speech Gilead', 'Bathsheba', 's', 'were', 'Walter', 'Penguin Putnam', 'and', 'Eld', 'Great Woodstock Music Festival', 'to', 'Na', 'Jude', 'Elmer Chambers', 'Feast Reaptide', 'Wolfe Look Homeward', 'they', 'Tet', 'Wipe', 'is', 'Sheb Allie', 'Far', 'his', 'Didn', '(', 'he', 'we', 'Rest', 'None', 'which', 'couldn', 'Earth Science', 'Tower Hanged Man', 'Maggie', 'Gilead', 'into', 'against', 'Given', 'Tull', 'Oedipus', 'Charlie', 'Mr. Tolkien', 'Kennerly', 'Man Jesus', 'Off', 'here', 'Cadillac', 'Stephen King', 'Tom Gordon Dreamcatcher Black House', 'Bullshit Rule', 'Make', 'Zorro', 'Mockery', 'Antichrist.', 'do', 'Weren', 'below', 'Which', 'Mouths', 'Who', 'Broken', 'me', 'some', 'or', 'that', 'has', 'Town', 'Roasted', 'Suppose', 'Lee Van Cleef', 'Seems', 'while', 'how', 'whom', 'having', 'Coffee Thermos', 'Ball', 'Phoenix', 'yourself', 'STEPHEN', 'Milky Way', 'Ugly', 'Screw', 'Already', 'our', 'Tricky Dick Nixon', 'Algul Siento', 'Fools', 'Hit', 'Star Wormword', 'Thunder', 'Jeremiah', 'what', 'over', 'y', 'God Tull', 'Scribner', 'Dinh Gilead', ')', 'Sheemie', 'Gather', 'isn', 'O', 'itself', 'about', 'when', 'Worlds', 'Penguin Book', 'Nort', 'Deschain', 'himself', 'Gas', 'Thomas Whitman', 'Mother', 'ours', 'Stevie', 'Stranger', 'i', 're', 'Blue Haven Heaven', 'll', 'same', 'all', 'Garlan', 'Clean Sea', 'yours', 'God', 'Leone', 'Trunks', 'Salem', 'Jake', 'down', 've', 'Times', 'Full', 'will', 'Jezebel', 'under', 'your', 'Coherent', 'just', 'nor', 'few', 'Mistuh Norton', 'Philistine', 'am', 'Beer', 'Tarot', 'Lord', 'Ulysses', 'Rub', 'Goodbye', 'Sylvia Pittston', 'it', 'other', 'Ware', 'Wind', 'Eye Hand', 'Bible', 'Aunt Mill', 'him', 'Century', 'Sunlight', 'Crimson King', 'Network', 'Cuthbert', 'Peddler', 'the', 'Jersey Turnpike', 'Had', 'Mill', 'Mountains', 'needn', 'Wizard Glass', 'Numbed', 'Drop', 'Next', 'Bad Lieutenant', 'Sheb', 'Eldred Jonas', 'Main Street', 'Roland', 'did', 'Single', 'Chussit', 'now', 'Varney Vampire', 'Fathoms', 'Jericho Hill', 'Great Hall', ',', 'Yar', 'Jamie', 'Amy Feldon', 'Night Cotillion', 'Dark Tower', 'Spittle', 'Volume Seven', 'be', 'each', '\"', 'Steven', 'Hold', 'Volume Six', 'Chaucer', 'Susan', 'my', 'between', 'Peter Straub', 'Ain', 'Old', 'Daddy', 'Soldier', 'don', 'See', 'up', 'wasn', 'Marsha DiFilippo', 'at', 'LeMark', 'Cort', 'Sergio Leone', 'Castner', 'where', 'Watch Me', 'Hanged Man', 'Cuthbert Jamie', 'Pappa', 'From Buick', 'these', 'Gods', 'very', 'are', 'Ahead', 'Prayer', 'Bert', 'Has Cort', 'Aren', 'Tolkien', 'Manni', 'Old Mother', 'Joshua', 'Alain Johns', 'themselves', 'Traveller', 'Slow Mutie', 'Moon', 'Da', 'Mine', 'Will', 'Ahaz', 'Merrys Pippins', 'Bullshit Factor', 'ma', 'Lanes', 'myself', 'Maine', 'Bloomie', 'Don', 'Beams', 'Kill', 'Susan Delgado Mejis', 'm', 'Michigan', 'Answer', 'Jonas', 'them', 'Mice', 'mightn', 'Gallows Hill Taunton Road', 'Came', 'Jesus Moses', 'such', 'Steven Deschain', 'than', 'Mary Golgotha.', 'Bad', 'should', 'out', 'further', 'Land Death', 'East Wing', 'Oracle', 'Wake', 'why', 'Him', 'Dim', 'Fresh Commala', 'Further', 'Thomas', 'Someone', 'Eye', 'no', 'after', 'Arthur Eld', 'Dinner', 'Volume Five', 'Good Book', 'hadn', 'any', 'Treason', 'Clean', 'won', 'Charles', 'Room', 'she', 'Eye Silver Bullet Maximum Overdrive Pet Sematary Golden', 'yourselves', 'Cook', 'Shaken', 'Gramma', 'Me', 'Look', 'Sterile', 'Bob Seger', 'Subway', 'Thought', 'Lord Flies Serpents', 'theirs', 'Clint', 'Terry Brooks', 'Taunton', 'Outside', 'before', 'Jamie DeCurry', 'Horsehead Nebula', 'Jesus', 'from', 'their', 'ain', 'during', 'above', 'Gandalfs', 'Dinosaurs', 'High Speech', 'Handcar', 'Walk', 'Pall Malls', 'Skeleton Crew', 'Hax', 'Shaw', 'aren', 'was', 'Rise', 'too', 'Stephen', 't', 'John Chambers', 'ourselves', 'St. Paul', 'Farson', 'a', 'Bread', 'Gallows Hill', 'Tears', 'Daniel', 'Afraid', 'Hello', 'if', 'Gran', 'through', 'Damascus', 'because', 'Did', 'Mark', 'Reap', 'Barony', 'Hai', 'Great All', 'Soobie', 'hasn', 'Does', 'Gunslinger', 'Cuthbert Allgood', 'Zoltan', 'Pittston', 'for', 'Cuthbert Vannay', 'Tower', 'Penguin Books', 'Larchies', 'those', 'Water', 'Okay', 'Empires', 'Light', 'Hard', 'Good', 'Wit', 'haven', 'only', 'Susan Delgado', 'then', 'Charles Dickens', 'Ageless', 'Atlantis Everything', 'doesn', 'Max Yasgur', 'again', 'o', 'both', 'Eventual SCREENPLAYS Creepshow Cat', 'Clay Blaisdell Western', 'Book', 'you', 'Gabrielle Verriss', 'an', 'Thomas Jamie', 'Aunt', 'with', 'doing', 'Kiss', 'Christine Pet Sematary Cycle Werewolf', 'Dad', 'most', 'until', 'so', 'more', '.', 'on', 'David', 'Round Table', 'in', 'Dolores Claiborne Insomnia Rose Madder', 'Vannay', 'had', 'weren', 'Guards', 'own', 'shan', 'Guards Watch', 'Life', 'Jake Chambers', 'Nineteen', 'Volcanoes', 'Silva', 'Simon', 'Dark', 'Sargasso', 'Mother Says', 'Might', 'Back Courts', 'Dearborn', 'Guard', 'wouldn', 'Aileen Ritter', 'Alan', 'didn', 'its', 'Above', 'of', \"'\", 'Jubal', 'Wizard Glass Bag Bones', 'Jonson', 'Patches', 'Stephen Donaldson', 'Robeson', 'Tongue', 'herself', 'once', 'Slow Mutants', 'her', 'Father', 'who', 'John Farson', 'd', 'Demon', 'Davey', 'have', 'Samson', 'Mejis', 'but', 'Earth', 'by', 'Hey Jude', 'Careful', 'Allie', 'Marten', 'can', 'Brown', 'Are', 'Jesus Savior', 'not', 'Doc', 'Carrie', 'Coffin Hunter', 'Narcissus', 'been', 'Hendrickson', 'Geography', 'being', 'Texas Florida'}\n"
     ]
    }
   ],
   "source": [
    "print(stoplist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:27.694101Z",
     "start_time": "2017-11-06T22:11:27.689907Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['content'] = df.content.apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:27.727416Z",
     "start_time": "2017-11-06T22:11:27.697430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d by “Duel”\\n\\nJoe Hill and Stephen King\\n\\n\\n...</td>\n",
       "      <td>9780062215956</td>\n",
       "      <td>Throttle</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TS\\n\\n\\n\\nCover Page\\n\\nTitle Page\\n\\n\\n\\nIntr...</td>\n",
       "      <td>978-0-385-52884-9</td>\n",
       "      <td>Night Shift</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this Scribner eBook.\\n\\n\\n\\n* * *\\n\\n\\n\\nSign...</td>\n",
       "      <td>0-7432-0467-0</td>\n",
       "      <td>Riding the Bullet</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Page\\n\\nCopyright Page\\n\\nDedication\\n\\n\\n\\n\\...</td>\n",
       "      <td>978-1-101-13813-7</td>\n",
       "      <td>Roadwork</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dication\\n\\nIntroduction\\n\\nAuthor’s Note\\n\\n\\...</td>\n",
       "      <td>978-0-385-52822-1</td>\n",
       "      <td>Salem's Lot</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content               isbn  \\\n",
       "0  d by “Duel”\\n\\nJoe Hill and Stephen King\\n\\n\\n...      9780062215956   \n",
       "1  TS\\n\\n\\n\\nCover Page\\n\\nTitle Page\\n\\n\\n\\nIntr...  978-0-385-52884-9   \n",
       "2   this Scribner eBook.\\n\\n\\n\\n* * *\\n\\n\\n\\nSign...      0-7432-0467-0   \n",
       "3   Page\\n\\nCopyright Page\\n\\nDedication\\n\\n\\n\\n\\...  978-1-101-13813-7   \n",
       "4  dication\\n\\nIntroduction\\n\\nAuthor’s Note\\n\\n\\...  978-0-385-52822-1   \n",
       "\n",
       "               title  year  \n",
       "0           Throttle  2009  \n",
       "1        Night Shift  1976  \n",
       "2  Riding the Bullet  2000  \n",
       "3           Roadwork  1981  \n",
       "4        Salem's Lot  1975  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omit Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:27.733416Z",
     "start_time": "2017-11-06T22:11:27.730633Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['content'] = df.content.apply(lambda x: [word for word in x if word not in stoplist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:27.739385Z",
     "start_time": "2017-11-06T22:11:27.735824Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert tokens back to a long string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:27.745135Z",
     "start_time": "2017-11-06T22:11:27.741793Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['content'] = df.content.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:27.751175Z",
     "start_time": "2017-11-06T22:11:27.748701Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.429641Z",
     "start_time": "2017-11-06T22:11:27.754041Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['content'] = df.content.apply(lambda x: sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.446133Z",
     "start_time": "2017-11-06T22:11:51.432206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[d by “Duel”\\n\\nJoe Hill and Stephen King\\n\\n\\...</td>\n",
       "      <td>9780062215956</td>\n",
       "      <td>Throttle</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[TS\\n\\n\\n\\nCover Page\\n\\nTitle Page\\n\\n\\n\\nInt...</td>\n",
       "      <td>978-0-385-52884-9</td>\n",
       "      <td>Night Shift</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ this Scribner eBook., * * *\\n\\n\\n\\nSign up f...</td>\n",
       "      <td>0-7432-0467-0</td>\n",
       "      <td>Riding the Bullet</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ Page\\n\\nCopyright Page\\n\\nDedication\\n\\n\\n\\n...</td>\n",
       "      <td>978-1-101-13813-7</td>\n",
       "      <td>Roadwork</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[dication\\n\\nIntroduction\\n\\nAuthor’s Note\\n\\n...</td>\n",
       "      <td>978-0-385-52822-1</td>\n",
       "      <td>Salem's Lot</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content               isbn  \\\n",
       "0  [d by “Duel”\\n\\nJoe Hill and Stephen King\\n\\n\\...      9780062215956   \n",
       "1  [TS\\n\\n\\n\\nCover Page\\n\\nTitle Page\\n\\n\\n\\nInt...  978-0-385-52884-9   \n",
       "2  [ this Scribner eBook., * * *\\n\\n\\n\\nSign up f...      0-7432-0467-0   \n",
       "3  [ Page\\n\\nCopyright Page\\n\\nDedication\\n\\n\\n\\n...  978-1-101-13813-7   \n",
       "4  [dication\\n\\nIntroduction\\n\\nAuthor’s Note\\n\\n...  978-0-385-52822-1   \n",
       "\n",
       "               title  year  \n",
       "0           Throttle  2009  \n",
       "1        Night Shift  1976  \n",
       "2  Riding the Bullet  2000  \n",
       "3           Roadwork  1981  \n",
       "4        Salem's Lot  1975  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stem Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.452839Z",
     "start_time": "2017-11-06T22:11:51.449331Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.459162Z",
     "start_time": "2017-11-06T22:11:51.455659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['content'] = df.content.apply(lambda x: [stemmer.stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.464384Z",
     "start_time": "2017-11-06T22:11:51.461281Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.469691Z",
     "start_time": "2017-11-06T22:11:51.466528Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = df.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.476505Z",
     "start_time": "2017-11-06T22:11:51.473148Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books = df.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.491030Z",
     "start_time": "2017-11-06T22:11:51.479319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dication\\n\\nIntroduction\\n\\nAuthor’s Note\\n\\n\\n\\n’SALEM’S LOT\\n\\n\\n\\nPrologue\\n\\nPart One\\n\\nThe Marsten House\\n\\nChapter One Ben (I)\\n\\nChapter Two Susan (I)\\n\\nChapter Three The Lot (I)\\n\\nChapter Four Danny Glick and Others\\n\\nChapter Five Ben (II)\\n\\nChapter Six The Lot (II)\\n\\nChapter Seven Matt\\n\\nPart Two\\n\\nThe Emperor of Ice Cream\\n\\nChapter Eight Ben (III)\\n\\nChapter Nine Susan (II)\\n\\nChapter Ten The Lot (III)\\n\\nChapter Eleven Ben (IV)\\n\\nChapter Twelve Mark\\n\\nChapter Thirteen Father Callahan\\n\\nPart Three\\n\\nThe Deserted Village\\n\\nChapter Fourteen The Lot (IV)\\n\\nChapter Fifteen Ben and Mark\\n\\nEpilogue\\n\\n\\n\\nOne for the Road\\n\\nJerusalem’s Lot\\n\\nDeleted Scenes\\n\\n\\n\\nAfterword\\n\\nCopyright\\n\\n\\n\\n\\n\\nFor Naomi Rachel King\\n\\n“…promises to keep.”\\n\\n\\n\\n\\n\\nIntroduction to ’Salem’s Lot\\n\\nBy Stephen King\\n\\nMy father-in-law is now retired, but when he was working for Maine’s Department of Human Services, he had a very cool sign in his office.',\n",
       " 'It said ONCE I HAD NO CHILDREN AND EIGHT IDEAS.',\n",
       " 'NOW I HAVE EIGHT CHILDREN AND NO IDEAS.',\n",
       " 'I like that because once I had no published novels and roughly two hundred ideas about the art and craft of writing fiction (two hundred and fifty on a good day).',\n",
       " 'Now I have just about fifty published novels to my credit and only one surviving idea about fiction; a writing seminar as taught by yours truly would probably last about fifteen minutes.',\n",
       " 'One of the ideas I had in those good old days was that it would be perfectly possible to combine the overlord-vampire myth from Bram Stoker’s Dracula with the naturalistic fiction of Frank Norris and the EC horror comics I’d loved as a child…and come out with a great American novel.',\n",
       " 'I was twenty-three, remember, so cut me a break.',\n",
       " 'I had a teaching certificate upon which the ink had hardly dried, I had published eight short stories and I had a perfectly insane amount of confidence in my own ability, not to mention a totally ridiculous sense of my own importance.',\n",
       " 'I also had a wife with a typewriter who liked my stories—and those last two things, which I took for granted then, turned out to be the most important things of all.',\n",
       " 'Did I really think I could combine Dracula and Tales from the Crypt and come out with Moby-Dick?',\n",
       " 'I did.',\n",
       " 'I really did.',\n",
       " 'I even planned a section at the front called “Extracta,” where I would include notes, clippings, and epigrams about vampires, as Melville does about whales at the front of his book.',\n",
       " 'Was I daunted by the fact that Moby-Dick only sold about twelve copies in Melville’s lifetime?',\n",
       " 'Not I; one of my ideas was that a novelist takes the long view, the lofty view, and that does not include the price of eggs.',\n",
       " '(My wife would not have agreed, and I doubt if Mrs. Melville would have, either.)',\n",
       " 'In any case, I liked the idea of my vampire novel serving as a balance for Stoker’s, which has to go down in history as the most optimistic scary novel of all time.',\n",
       " 'Count Dracula, simultaneously feared and worshipped in his dark little European fiefdom of Transylvania, makes the fatal mistake of taking his act and putting it on the road.',\n",
       " 'In London he meets men and women of science and reason, by God—Abraham Van Helsing, who knows about blood transfusions; John Seward, who keeps his diary on wax phonograph cylinders; Mina Harker, who keeps hers in shorthand and later serves as secretary to the Fearless Vampire Hunters.',\n",
       " 'Stoker was clearly fascinated by modern inventions and innovations, and the underlying thesis of his novel is clear: in a confrontation between a foreign child of the Dark Powers and a group of fine, upstanding Britishers equipped with all mod cons, the powers of darkness don’t stand a chance.',\n",
       " 'Dracula is hounded from Carfax, his British estate, back to Transylvania, and finally staked at sunset.',\n",
       " 'The vampire-hunters pay a price for their victory—that is Stoker’s genius—but that they will come out on top is never in much doubt.',\n",
       " 'When I sat down to write my version of the story in 1972—a version whose life-force was drawn more from the nervously jokey Jewish-American mythos of William Gaines and Al Feldstein than from Romanian folk-tales—I saw a different world, one where all of the gadgets Stoker must have regarded with such hopeful wonder had begun to seem sinister and downright dangerous.',\n",
       " 'Mine was the world that had begun to choke on its own effluent, that had hooked itself through the bag on diminishing energy resources, and had to deal not only with nuclear weapons but nuclear proliferation (big-time terrorism was, thankfully, at that time still over the horizon).',\n",
       " 'I saw myself and my society at the other end of the technological rainbow, and set out to write a book that would reflect that glum idea.',\n",
       " 'One where, in short, the vampire would end up eating the fearless vampire-hunters for lunch.',\n",
       " '(Which he, as a vampire, would eat at midnight, of course.)',\n",
       " 'I was about three hundred pages into this book—then titled Second Coming—when Carrie was published, and my first idea about novel-writing went west.',\n",
       " 'It would be years before I would hear Alfred Bester’s axiom “The book is the boss,” but I didn’t need to; I learned it for myself writing the novel that eventually became ’Salem’s Lot.',\n",
       " 'Of course, the writer can impose control; it’s just a really shitty idea.',\n",
       " 'Writing controlled fiction is called “plotting.” Buckling your seatbelt and letting the story take over, however…that is called “storytelling.” Storytelling is as natural as breathing; plotting is the literary version of artificial respiration.',\n",
       " 'Given my dim view of small New England towns (I had grown up in one and knew what they were like), I had no doubt my version of Count Dracula would emerge completely triumphant over the puny representatives of the rational world arrayed against him.',\n",
       " 'What I didn’t count on was that my characters weren’t content to remain puny representatives.',\n",
       " 'Instead they came alive and began to do things—sometimes smart things, sometimes foolishly brave things—on their own.',\n",
       " 'More of Stoker’s characters are around at the finish of Dracula than at the end of ’Salem’s Lot, and yet this is—against its young author’s will—a surprisingly optimistic book.',\n",
       " 'I’m glad.',\n",
       " 'I still see all the nicks and dings on its fenders, all the scars on its hide that were inflicted by the inexperience of a craftsman new at his trade, but I still find many passages of power here.',\n",
       " 'And a few of grace.',\n",
       " 'Doubleday had published my first novel, and had an option on my second.',\n",
       " 'I had completed this one and another, what I thought of as a “serious” novel, called Roadwork.',\n",
       " 'I showed them both to my then-editor, Bill Thompson.',\n",
       " 'He liked them both.',\n",
       " 'We had a lunch at which nothing was decided, then started to walk back to Doubleday.',\n",
       " 'At the corner of Park Avenue and 54th Street—something like that—we were stopped by a DON’T WALK light.',\n",
       " 'I finally pulled the pin and asked Bill which one he thought we should publish.',\n",
       " 'He said, “Roadwork would probably get more serious attention, but Second Coming is Peyton Place with vampires.',\n",
       " 'It’s a great read and it could be a bestseller.',\n",
       " 'There’s only one problem.”\\n\\n“What’s that?” I asked, as DON’T WALK changed to WALK and people started to move around us.',\n",
       " 'Bill stepped off the curb.',\n",
       " 'In New York you don’t waste the WALK, even when decisions of moment are being made, and this—I might have sensed it even then—was one that would affect the rest of my life.',\n",
       " '“You’ll be typed as a horror writer,” he said.',\n",
       " 'I was so relieved I laughed.',\n",
       " '“I don’t care what they call me as long as the checks don’t bounce,” I said.',\n",
       " '“Let’s publish Second Coming.” And that was what we did, although the name was first changed to Jerusalem’s Lot (because my wife, Tabby, said that Second Coming sounded like a sex manual) and then to ’Salem’s Lot (because the Doubleday brass said Jerusalem’s Lot sounded like a religious book).',\n",
       " 'I was indeed typed as a horror writer, a tag I have never confirmed or denied, simply because I think it’s irrelevant to what I do.',\n",
       " 'It does, however, give bookstores a handy place to shelve my books.',\n",
       " 'Since then I have let go of all but one of my ideas about fiction-writing.',\n",
       " 'It’s the one I came to first (around age seven, as I recall), and the one I’ll probably hold onto until the end: it’s good to tell a story, and even better when people actually want to listen.',\n",
       " 'I think ’Salem’s Lot, for all its flaws, is one of the good ones.',\n",
       " 'One of the scary ones.',\n",
       " 'If you’ve never heard it before, let me tell it to you now.',\n",
       " 'And if you have, let me tell it to you again.',\n",
       " 'So turn off the television—in fact, why don’t you turn off all the lights except for the one over your favorite chair?—and we’ll talk about vampires here in the dim.',\n",
       " 'I think I can make you believe in them, because while I was working on this book, I believed in them myself.',\n",
       " 'Center Lovell, Maine\\n\\nJune 15, 2005\\n\\n\\n\\n\\n\\nAuthor’s Note\\n\\nNo one writes a long novel alone, and I would like to take a moment of your time to thank some of the people who helped with this one: G. Everett McCutcheon, of Hampden Academy, for his practical suggestions and encouragement; Dr John Pearson, of Old Town, Maine, medical examiner of Penobscot County and member in good standing of that most excellent medical specialty, general practice; Father Renald Hallee, of St John’s Catholic Church in Bangor, Maine.',\n",
       " 'And of course my wife, whose criticism is as tough and unflinching as ever.',\n",
       " 'Although the towns surrounding ’salem’s Lot are very real, ’salem’s Lot itself exists wholly in the author’s imagination, and any resemblance between the people who live there and people who live in the real world is coincidental and unintended.',\n",
       " 'S.K.',\n",
       " '******START_OF_FILE******\\nPrologue\\n\\nOld friend, what are you looking for?',\n",
       " 'After those many years abroad you come\\n\\nWith images you tended\\n\\nUnder foreign skies\\n\\nFar away from your own land.',\n",
       " 'GEORGE SEFERIS\\n\\n\\nONE\\n\\nAlmost everyone thought the man and the boy were father and son.',\n",
       " 'They crossed the country on a rambling southwest line in an old Citroën sedan, keeping mostly to secondary roads, traveling in fits and starts.',\n",
       " 'They stopped in three places along the way before reaching their final destination: first in Rhode Island, where the tall man with the black hair worked in a textile mill; then in Youngstown, Ohio, where he worked for three months on a tractor assembly line; and finally in a small California town near the Mexican border, where he pumped gas and worked at repairing small foreign cars with an amount of success that was, to him, surprising and gratifying.',\n",
       " 'Wherever they stopped, he got a Maine newspaper called the Portland Press-Herald and watched it for items concerning a small southern Maine town named Jerusalem’s Lot and the surrounding area.',\n",
       " 'There were such items from time to time.',\n",
       " 'He wrote an outline of a novel in motel rooms before they hit Central Falls, Rhode Island, and mailed it to his agent.',\n",
       " 'He had been a mildly successful novelist a million years before, in a time when the darkness had not come over his life.',\n",
       " 'The agent took the outline to his last publisher, who expressed polite interest but no inclination to part with any advance money.',\n",
       " '“Please” and “thank you,” he told the boy as he tore the agent’s letter up, were still free.',\n",
       " 'He said it without too much bitterness and set about the book anyway.',\n",
       " 'The boy did not speak much.',\n",
       " 'His face retained a perpetual pinched look, and his eyes were dark—as if they always scanned some bleak inner horizon.',\n",
       " 'In the diners and gas stations where they stopped along the way, he was polite and nothing more.',\n",
       " 'He didn’t seem to want the tall man out of his sight, and the boy seemed nervous even when the man left him to use the bathroom.',\n",
       " 'He refused to talk about the town of Jerusalem’s Lot, although the tall man tried to raise the topic from time to time, and he would not look at the Portland newspapers the man sometimes deliberately left around.',\n",
       " 'When the book was written, they were living in a beach cottage off the highway, and they both swam in the Pacific a great deal.',\n",
       " 'It was warmer than the Atlantic, and friendlier.',\n",
       " 'It held no memories.',\n",
       " 'The boy began to get very brown.',\n",
       " 'Although they were living well enough to eat three square meals a day and keep a solid roof over their heads, the man had begun to feel depressed and doubtful about the life they were living.',\n",
       " 'He was tutoring the boy, and he did not seem to be losing anything in the way of education (the boy was bright and easy about books, as the tall man had been himself), but he didn’t think that blotting ’salem’s Lot out was doing the boy any good.',\n",
       " 'Sometimes at night he screamed in his sleep and thrashed the blankets onto the floor.',\n",
       " 'A letter came from New York.',\n",
       " 'The tall man’s agent said that Random House was offering $12,000 in advance, and a book club sale was almost certain.',\n",
       " 'Was it okay?',\n",
       " 'It was.',\n",
       " 'The man quit his job at the gas station, and he and the boy crossed the border.',\n",
       " 'TWO\\n\\nLos Zapatos, which means “the shoes” (a name that secretly pleased the man to no end), was a small village not far from the ocean.',\n",
       " 'It was fairly free of tourists.',\n",
       " 'There was no good road, no ocean view (you had to go five miles further west to get that), and no historical points of interest.',\n",
       " 'Also, the local cantina was infested with cockroaches and the only whore was a fifty-year-old grandmother.',\n",
       " 'With the States behind them, an almost unearthly quiet dropped over their lives.',\n",
       " 'Few planes went overhead, there were no turnpikes, and no one owned a power lawn mower (or cared to have one) for a hundred miles.',\n",
       " 'They had a radio, but even that was noise without meaning; the news broadcasts were all in Spanish, which the boy began to pick up but which remained—and always would—gibberish to the man.',\n",
       " 'All the music seemed to consist of opera.',\n",
       " 'At night they sometimes got a pop music station from Monterey made frantic with the accents of Wolfman Jack, but it faded in and out.',\n",
       " 'The only motor within hearing distance was a quaint old Rototiller owned by a local farmer.',\n",
       " 'When the wind was right, its irregular burping noise would come to their ears faintly, like an uneasy spirit.',\n",
       " 'They drew their water from the well by hand.',\n",
       " 'Once or twice a month (not always together) they attended mass at the small church in town.',\n",
       " 'Neither of them understood the ceremony, but they went all the same.',\n",
       " 'The man found himself sometimes drowsing in the suffocating heat to the steady, familiar rhythms and the voices which gave them tongue.',\n",
       " 'One Sunday the boy came out onto the rickety back porch where the man had begun work on a new novel and told him hesitantly that he had spoken to the priest about being taken into the church.',\n",
       " 'The man nodded and asked him if he had enough Spanish to take instruction.',\n",
       " 'The boy said he didn’t think it would be a problem.',\n",
       " 'The man made a forty-mile trip once a week to get the Portland, Maine, paper, which was always at least a week old and was sometimes yellowed with dog urine.',\n",
       " 'Two weeks after the boy had told him of his intentions, he found a featured story about ’salem’s Lot and a Vermont town called Momson.',\n",
       " 'The tall man’s name was mentioned in the course of the story.',\n",
       " 'He left the paper around with no particular hope that the boy would pick it up.',\n",
       " 'The article made him uneasy for a number of reasons.',\n",
       " 'It was not over in ’salem’s Lot yet, it seemed.',\n",
       " 'The boy came to him a day later with the paper in his hand, folded open to expose the headline: “Ghost Town in Maine?”\\n\\n“I’m scared,” he said.',\n",
       " '“I am, too,” the tall man answered.',\n",
       " 'THREE\\n\\nGHOST TOWN IN MAINE?',\n",
       " 'By John Lewis\\n\\nPress-Herald Features Editor\\n\\n\\n\\nJERUSALEM’S LOT—Jerusalem’s Lot is a small town east of Cumberland and twenty miles north of Portland.',\n",
       " 'It is not the first town in American history to just dry up and blow away, and will probably not be the last, but it is one of the strangest.',\n",
       " 'Ghost towns are common in the American Southwest, where communities grew up almost overnight around rich gold and silver lodes and then disappeared almost as rapidly when the veins of ore played out, leaving empty stores and hotels and saloons to rot emptily in desert silence.',\n",
       " 'In New England the only counterpart to the mysterious emptying of Jerusalem’s Lot, or ’salem’s Lot as the natives often refer to it, seems to be a small town in Vermont called Momson.',\n",
       " 'During the summer of 1923, Momson apparently just dried up and blew away, and all 312 residents went with it.',\n",
       " 'The houses and few small business buildings in the town’s center still stand, but since that summer fifty-two years ago, they have been uninhabited.',\n",
       " 'In some cases the furnishings had been removed, but in most the houses were still furnished, as if in the middle of daily life some great wind had blown all the people away.',\n",
       " 'In one house the table had been set for the evening meal, complete with a centerpiece of long-wilted flowers.',\n",
       " 'In another the covers had been turned down neatly in an upstairs bedroom as if for sleep.',\n",
       " 'In the local mercantile store, a rotted bolt of cotton cloth was found on the counter and a price of $1.22 rung up on the cash register.',\n",
       " 'Investigators found almost $50.00 in the cash drawer, untouched.',\n",
       " 'People in the area like to entertain tourists with the story and to hint that the town is haunted—that, they say, is why it has remained empty ever since.',\n",
       " 'A more likely reason is that Momson is located in a forgotten corner of the state, far from any main road.',\n",
       " 'There is nothing there that could not be duplicated in a hundred other towns—except, of course, the Mary Celeste–like mystery of its sudden emptiness.',\n",
       " 'Much the same could be said for Jerusalem’s Lot.',\n",
       " 'In the census of 1970, ’salem’s Lot claimed 1,319 inhabitants—a gain of exactly 67 souls in the ten years since the previous census.',\n",
       " 'It is a sprawling, comfortable township, familiarly called the Lot by its previous inhabitants, where little of any note ever took place.',\n",
       " 'The only thing the oldsters who regularly gathered in the park and around the stove in Crossen’s Agricultural Market had to talk about was the Fire of ’51, when a carelessly tossed match started one of the largest forest fires in the state’s history.',\n",
       " 'If a man wanted to spin out his retirement in a small country town where everyone minded his own business and the big event of any given week was apt to be the Ladies’ Auxiliary Bake-off, then the Lot would have been a good choice.',\n",
       " 'Demographically, the census of 1970 showed a pattern familiar both to rural sociologists and to the longtime residents of any small Maine town: a lot of old folks, quite a few poor folks, and a lot of young folks who leave the area with their diplomas under their arms, never to return again.',\n",
       " 'But a little over a year ago, something began to happen in Jerusalem’s Lot that was not usual.',\n",
       " 'People began to drop out of sight.',\n",
       " 'The larger proportion of these, naturally, haven’t disappeared in the real sense of the word at all.',\n",
       " 'The Lot’s former constable, Parkins Gillespie, is living with his sister in Kittery.',\n",
       " 'Charles James, owner of a gas station across from the drugstore, is now running a repair shop in neighboring Cumberland.',\n",
       " 'Pauline Dickens has moved to Los Angeles, and Rhoda Curless is working with the St Matthew’s Mission in Portland.',\n",
       " 'The list of “un-disappearances” could go on and on.',\n",
       " 'What is mystifying about these found people is their unanimous unwillingness—or inability—to talk about Jerusalem’s Lot and what, if anything, might have happened there.',\n",
       " 'Parkins Gillespie simply looked at this reporter, lit a cigarette, and said, “I just decided to leave.” Charles James claims he was forced to leave because his business dried up with the town.',\n",
       " 'Pauline Dickens, who worked as a waitress in the Excellent Café for years, never answered this reporter’s letter of inquiry.',\n",
       " 'And Mrs Curless refuses to speak of ’salem’s Lot at all.',\n",
       " 'Some of the missing can be accounted for by educated guesswork and a little research.',\n",
       " 'Lawrence Crockett, a local real estate agent who has disappeared with his wife and daughter, has left a number of questionable business ventures and land deals behind him, including one piece of Portland land speculation where the Portland Mall and Shopping Center is now under construction.',\n",
       " 'The Royce McDougalls, also among the missing, had lost their infant son earlier in the year and there was little to hold them in town.',\n",
       " 'They might be anywhere.',\n",
       " 'Others fit into the same category.',\n",
       " 'According to State Police Chief Peter McFee, “We’ve got tracers out on a great many people from Jerusalem’s Lot—but that isn’t the only Maine town where people have dropped out of sight.',\n",
       " 'Royce McDougall, for instance, left owing money to one bank and two finance companies…in my judgment, he was just a fly-by-nighter who decided to get out from under.',\n",
       " 'Someday this year or next, he’ll use one of those credit cards he’s got in his wallet and the repossession men will land on him with both feet.',\n",
       " 'In America missing persons are as natural as cherry pie.',\n",
       " 'We’re living in an automobile-oriented society.',\n",
       " 'People pick up stakes and move on every two or three years.',\n",
       " 'Sometimes they forget to leave a forwarding address.',\n",
       " 'Especially the deadbeats.”\\n\\nYet for all the hardheaded practicality of Captain McFee’s words, there are unanswered questions in Jerusalem’s Lot.',\n",
       " 'Henry Petrie and his wife and son are gone, and Mr Petrie, a Prudential Insurance Company executive, could hardly be called a deadbeat.',\n",
       " 'The local mortician, the local librarian, and the local beautician are also in the dead-letter file.',\n",
       " 'The list is of a disquieting length.',\n",
       " 'In the surrounding towns the whispering campaign that is the beginning of legend has already begun.',\n",
       " '’Salem’s Lot is reputed to be haunted.',\n",
       " 'Sometimes colored lights are reported hovering over the Central Maine Power lines that bisect the township, and if you suggest that the inhabitants of the Lot have been carried off by UFOs, no one will laugh.',\n",
       " 'There has been some talk of a “dark coven” of young people who were practicing the black mass in town and, perhaps, brought the wrath of God Himself on the namesake of the Holy Land’s holiest city.',\n",
       " 'Others, of a less supernatural bent, remember the young men who “disappeared” in the Houston, Texas, area some three years ago only to be discovered in grisly mass graves.',\n",
       " 'An actual visit to ’salem’s Lot makes such talk seem less wild.',\n",
       " 'There is not one business left open.',\n",
       " 'The last one to go under was Spencer’s Sundries and Pharmacy, which closed its doors in January.',\n",
       " 'Crossen’s Agricultural Store, the hardware store, Barlow and Straker’s Furniture Shop, the Excellent Café, and even the Municipal Building are all boarded up.',\n",
       " 'The new grammar school is empty, and so is the tri-town consolidated high school, built in the Lot in 1967.',\n",
       " 'The school furnishings and the books have been moved to make-do facilities in Cumberland pending a referendum vote in the other towns of the school district, but it seems that no children from ’salem’s Lot will be in attendance when a new school year begins.',\n",
       " 'There are no children; only abandoned shops and stores, deserted houses, overgrown lawns, deserted streets, and back roads.',\n",
       " 'Some of the other people that the state police would like to locate or at least hear from include John Groggins, pastor of the Jerusalem’s Lot Methodist Church; Father Donald Callahan, parish priest of St Andrew’s; Mabel Werts, a local widow who was prominent in ’salem’s Lot church and social functions; Lester and Harriet Durham, a local couple who both worked at Gates Mill and Weaving; Eva Miller, who ran a local boardinghouse….',\n",
       " 'FOUR\\n\\nTwo months after the newspaper article, the boy was taken into the church.',\n",
       " 'He made his first confession—and confessed everything.',\n",
       " 'FIVE\\n\\nThe village priest was an old man with white hair and a face seamed into a net of wrinkles.',\n",
       " 'His eyes peered out of his sun-beaten face with surprising life and avidity.',\n",
       " 'They were blue eyes, very Irish.',\n",
       " 'When the tall man arrived at his house, he was sitting on the porch and drinking tea.',\n",
       " 'A man in a city suit stood beside him.',\n",
       " 'The man’s hair was parted in the middle and greased in a manner that reminded the tall man of photograph portraits from the 1890s.',\n",
       " 'The man said stiffly, “I am Jesús de la rey Muñoz.',\n",
       " 'Father Gracon has asked me to interpret, as he has no English.',\n",
       " 'Father Gracon has done my family a great service which I may not mention.',\n",
       " 'My lips are likewise sealed in the matter he wishes to discuss.',\n",
       " 'Is it agreeable to you?”\\n\\n“Yes.” He shook Muñoz’s hand and then Gracon’s.',\n",
       " 'Gracon replied in Spanish and smiled.',\n",
       " 'He had only five teeth left in his jaw, but the smile was sunny and glad.',\n",
       " '“He asks, Would you like a cup of tea?',\n",
       " 'It is green tea.',\n",
       " 'Very cooling.”\\n\\n“That would be lovely.”\\n\\nWhen the amenities had passed among them, the priest said, “The boy is not your son.”\\n\\n“No.”\\n\\n“He made a strange confession.',\n",
       " 'In fact, I have never heard a stranger confession in all my days of the priesthood.”\\n\\n“That does not surprise me.”\\n\\n“He wept,” Father Gracon said, sipping his tea.',\n",
       " '“It was a deep and terrible weeping.',\n",
       " 'It came from the cellar of his soul.',\n",
       " 'Must I ask the question this confession raises in my heart?”\\n\\n“No,” the tall man said evenly.',\n",
       " '“You don’t.',\n",
       " 'He is telling the truth.”\\n\\nGracon was nodding even before Muñoz translated, and his face had grown grave.',\n",
       " 'He leaned forward with his hands clasped between his knees and spoke for a long time.',\n",
       " 'Muñoz listened intently, his face carefully expressionless.',\n",
       " 'When the priest finished, Muñoz said:\\n\\n“He says there are strange things in the world.',\n",
       " 'Forty years ago a peasant from El Graniones brought him a lizard that screamed as though it were a woman.',\n",
       " 'He has seen a man with stigmata, the marks of Our Lord’s passion, and this man bled from his hands and feet on Good Friday.',\n",
       " 'He says this is an awful thing, a dark thing.',\n",
       " 'It is serious for you and the boy.',\n",
       " 'Particularly for the boy.',\n",
       " 'It is eating him up.',\n",
       " 'He says…”\\n\\nGracon spoke again, briefly.',\n",
       " '“He asks if you understand what you have done in this New Jerusalem.”\\n\\n“Jerusalem’s Lot,” the tall man said.',\n",
       " '“Yes.',\n",
       " 'I understand.”\\n\\nGracon spoke again.',\n",
       " '“He asks what you intend to do about it.”\\n\\nThe tall man shook his head very slowly.',\n",
       " '“I don’t know.”\\n\\nGracon spoke again.',\n",
       " '“He says he will pray for you.”\\n\\n\\nSIX\\n\\nA week later he awoke sweating from a nightmare and called out the boy’s name.',\n",
       " '“I’m going back,” he said.',\n",
       " 'The boy paled beneath his tan.',\n",
       " '“Can you come with me?” the man asked.',\n",
       " '“Do you love me?”\\n\\n“Yes.',\n",
       " 'God, yes.”\\n\\nThe boy began to weep, and the tall man held him.',\n",
       " 'SEVEN\\n\\nStill, there was no sleep for him.',\n",
       " 'Faces lurked in the shadows, swirling up at him like faces obscured in snow, and when the wind blew an overhanging tree limb against the roof, he jumped.',\n",
       " 'Jerusalem’s Lot.',\n",
       " 'He closed his eyes and put his arm across them and it all began to come back.',\n",
       " 'He could almost see the glass paperweight, the kind that will make a tiny blizzard when you shake it.',\n",
       " '’Salem’s Lot…\\n\\n\\n\\n\\n\\nPart One\\n\\nThe Marsten House\\n\\nNo live organism can continue for long to exist sanely under conditions of absolute reality; even larks and katydids are supposed, by some, to dream.',\n",
       " 'Hill House, not sane, stood by itself against its hills, holding darkness within; it had stood for eighty years and might stand for eighty more.',\n",
       " 'Within, walls continued upright, bricks met neatly, floors were firm, and doors were sensibly shut; silence lay steadily against the wood and stone of Hill House, and whatever walked there, walked alone.',\n",
       " 'SHIRLEY JACKSON\\n\\nThe Haunting of Hill House\\n\\n\\n\\n\\n\\nChapter One\\n\\nBen (I)\\n\\nBy the time he had passed Portland going north on the turnpike, Ben Mears had begun to feel a not unpleasurable tingle of excitement in his belly.',\n",
       " 'It was September 5, 1975, and summer was enjoying her final grand fling.',\n",
       " 'The trees were bursting with green, the sky was a high, soft blue, and just over the Falmouth town line he saw two boys walking a road parallel to the expressway with fishing rods settled on their shoulders like carbines.',\n",
       " 'He switched to the travel lane, slowed to the minimum turnpike speed, and began to look for anything that would jog his memory.',\n",
       " 'There was nothing at first, and he tried to caution himself against almost sure disappointment.',\n",
       " 'You were nine then.',\n",
       " 'That’s twenty-five years of water under the bridge.',\n",
       " 'Places change.',\n",
       " 'Like people.',\n",
       " 'In those days the four-lane 295 hadn’t existed.',\n",
       " 'If you wanted to go to Portland from the Lot, you went out Route 12 to Falmouth and then got on Number 1.',\n",
       " 'Time had marched on.',\n",
       " 'Stop that shit.',\n",
       " 'But it was hard to stop.',\n",
       " 'It was hard to stop when—\\n\\nA big BSA cycle with jacked handlebars suddenly roared past him in the passing lane, a kid in a T-shirt driving, a girl in a red cloth jacket and huge mirror-lensed sunglasses riding pillion behind him.',\n",
       " 'They cut in a little too quickly and he overreacted, jamming on his brakes and laying both hands on the horn.',\n",
       " 'The BSA sped up, belching blue smoke from its exhaust, and the girl jabbed her middle finger back at him.',\n",
       " 'He resumed speed, wishing for a cigarette.',\n",
       " 'His hands were trembling slightly.',\n",
       " 'The BSA was almost out of sight now, moving fast.',\n",
       " 'The kids.',\n",
       " 'The goddamned kids.',\n",
       " 'Memories tried to crowd in on him, memories of a more recent vintage.',\n",
       " 'He pushed them away.',\n",
       " 'He hadn’t been on a motorcycle in two years.',\n",
       " 'He planned never to ride on one again.',\n",
       " 'A flash of red caught his eye off to the left, and when he glanced that way, he felt a burst of pleasure and recognition.',\n",
       " 'A large red barn stood on a hill far across a rising field of timothy and clover, a barn with a cupola painted white—even at this distance he could see the sun gleam on the weather vane atop that cupola.',\n",
       " 'It had been there then and was still here now.',\n",
       " 'It looked exactly the same.',\n",
       " 'Maybe it was going to be all right after all.',\n",
       " 'Then the trees blotted it out.',\n",
       " 'As the turnpike entered Cumberland, more and more things began to seem familiar.',\n",
       " 'He passed over the Royal River, where they had fished for steelies and pickerel as boys.',\n",
       " 'Past a brief, flickering view of Cumberland Village through the trees.',\n",
       " 'In the distance the Cumberland water tower with its huge slogan painted across the side: “Keep Maine Green.” Aunt Cindy had always said someone should print “Bring Money” underneath that.',\n",
       " 'His original sense of excitement grew and he began to speed up, watching for the sign.',\n",
       " 'It came twinkling up out of the distance in reflectorized green five miles later:\\n\\n\\n\\nROUTE 12 JERUSALEM’S LOT\\n\\nCUMBERLAND CUMBERLAND CTR\\n\\n\\n\\nA sudden blackness came over him, dousing his good spirits like sand on fire.',\n",
       " 'He had been subject to these since (his mind tried to speak Miranda’s name and he would not let it) the bad time and was used to fending them off, but this one swept over him with a savage power that was dismaying.',\n",
       " 'What was he doing, coming back to a town where he had lived for four years as a boy, trying to recapture something that was irrevocably lost?',\n",
       " 'What magic could he expect to recapture by walking roads that he had once walked as a boy and were probably asphalted and straightened and logged off and littered with tourist beer cans?',\n",
       " 'The magic was gone, both white and black.',\n",
       " 'It had all gone down the chutes on that night when the motorcycle had gone out of control and then there was the yellow moving van, growing and growing, his wife Miranda’s scream, cut off with sudden finality when—\\n\\nThe exit came up on his right, and for a moment he considered driving right past it, continuing on to Chamberlain or Lewiston, stopping for lunch, and then turning around and going back.',\n",
       " 'But back where?',\n",
       " 'Home?',\n",
       " 'That was a laugh.',\n",
       " 'If there was a home, it had been here.',\n",
       " 'Even if it had only been four years, it was his.',\n",
       " 'He signaled, slowed the Citroën, and went up the ramp.',\n",
       " 'Toward the top, where the turnpike ramp joined Route 12 (which became Jointner Avenue closer to town), he glanced up toward the horizon.',\n",
       " 'What he saw there made him jam the brakes on with both feet.',\n",
       " 'The Citroën shuddered to a stop and stalled.',\n",
       " 'The trees, mostly pine and spruce, rose in gentle slopes toward the east, seeming to almost crowd against the sky at the limit of vision.',\n",
       " 'From here the town was not visible.',\n",
       " 'Only the trees, and in the distance, where those trees rose against the sky, the peaked, gabled roof of the Marsten House.',\n",
       " 'He gazed at it, fascinated.',\n",
       " 'Warring emotions crossed his face with kaleidoscopic swiftness.',\n",
       " '“Still here,” he murmured aloud.',\n",
       " '“By God.”\\n\\nHe looked down at his arms.',\n",
       " 'They had broken out in goose flesh.',\n",
       " 'TWO\\n\\nHe deliberately skirted town, crossing into Cumberland and then coming back into ’salem’s Lot from the west, taking the Burns Road.',\n",
       " 'He was amazed by how little things had changed out here.',\n",
       " 'There were a few new houses he didn’t remember, there was a tavern called Dell’s just over the town line, and a pair of fresh gravel quarries.',\n",
       " 'A good deal of the hardwood had been pulped over.',\n",
       " 'But the old tin sign pointing the way to the town dump was still there, and the road itself was still unpaved, full of chuckholes and washboards, and he could see Schoolyard Hill through the slash in the trees where the Central Maine Power pylons ran on a northwest to southeast line.',\n",
       " 'The Griffen farm was still there, although the barn had been enlarged.',\n",
       " 'He wondered if they still bottled and sold their own milk.',\n",
       " 'The logo had been a smiling cow under the name brand: “Sunshine Milk from the Griffen Farms!” He smiled.',\n",
       " 'He had splashed a lot of that milk on his corn flakes at Aunt Cindy’s house.',\n",
       " 'He turned left onto the Brooks Road, passed the wrought-iron gates and the low fieldstone wall surrounding Harmony Hill Cemetery, and then went down the steep grade and started up the far side—the side known as Marsten’s Hill.',\n",
       " 'At the top, the trees fell away on both sides of the road.',\n",
       " 'On the right, you could look right down into the town proper—Ben’s first view of it.',\n",
       " 'On the left, the Marsten House.',\n",
       " 'He pulled over and got out of the car.',\n",
       " 'It was just the same.',\n",
       " 'There was no difference, not at all.',\n",
       " 'He might have last seen it yesterday.',\n",
       " 'The witch grass grew wild and tall in the front yard, obscuring the old, frost-heaved flagstones that led to the porch.',\n",
       " 'Chirring crickets sang in it, and he could see grasshoppers jumping in erratic parabolas.',\n",
       " 'The house itself looked toward town.',\n",
       " 'It was huge and rambling and sagging, its windows haphazardly boarded shut, giving it that sinister look of all old houses that have been empty for a long time.',\n",
       " 'The paint had been weathered away, giving the house a uniform gray look.',\n",
       " 'Windstorms had ripped many of the shingles off, and a heavy snowfall had punched in the west corner of the main roof, giving it a slumped, hunched look.',\n",
       " 'A tattered no-trespassing sign was nailed to the right-hand newel post.',\n",
       " 'He felt a strong urge to walk up that overgrown path, past the crickets and hoppers that would jump around his shoes, climb the porch, peek between the haphazard boards into the hallway or the front room.',\n",
       " 'Perhaps try the front door.',\n",
       " 'If it was unlocked, go in.',\n",
       " 'He swallowed and stared up at the house, almost hypnotized.',\n",
       " 'It stared back at him with idiot indifference.',\n",
       " 'You walked down the hall, smelling wet plaster and rotting wallpaper, and mice would skitter in the walls.',\n",
       " 'There would still be a lot of junk lying around, and you might pick something up, a paperweight maybe, and put it in your pocket.',\n",
       " 'Then, at the end of the hall, instead of going through into the kitchen, you could turn left and go up the stairs, your feet gritting in the plaster dust which had sifted down from the ceiling over the years.',\n",
       " 'There were fourteen steps, exactly fourteen.',\n",
       " 'But the top one was smaller, out of proportion, as if it had been added to avoid the evil number.',\n",
       " 'At the top of the stairs you stand on the landing, looking down the hall toward a closed door.',\n",
       " 'And if you walk down the hall toward it, watching as if from outside yourself as the door gets closer and larger, you can reach out your hand and put it on the tarnished silver knob—\\n\\nHe turned away from the house, a straw-dry whistle of air slipping from his mouth.',\n",
       " 'Not yet.',\n",
       " 'Later, perhaps, but not yet.',\n",
       " 'For now it was enough to know that all of that was still here.',\n",
       " 'It had waited for him.',\n",
       " 'He put his hands on the hood of his car and looked out over the town.',\n",
       " 'He could find out down there who was handling the Marsten House, and perhaps lease it.',\n",
       " 'The kitchen would make an adequate writing room and he could bunk down in the front parlor.',\n",
       " 'But he wouldn’t allow himself to go upstairs.',\n",
       " 'Not unless it had to be done.',\n",
       " 'He got in his car, started it, and drove down the hill to Jerusalem’s Lot.',\n",
       " 'Chapter Two\\n\\nSusan (I)\\n\\nHe was sitting on a bench in the park when he observed the girl watching him.',\n",
       " 'She was a very pretty girl, and there was a silk scarf tied over her light blond hair.',\n",
       " 'She was currently reading a book, but there was a sketch pad and what looked like a charcoal pencil beside her.',\n",
       " 'It was Tuesday, September 16, the first day of school, and the park had magically emptied of the rowdier element.',\n",
       " 'What was left was a scattering of mothers with infants, a few old men sitting by the war memorial, and this girl sitting in the dappled shade of a gnarled old elm.',\n",
       " 'She looked up and saw him.',\n",
       " 'An expression of startlement crossed her face.',\n",
       " 'She looked down at her book; looked up at him again and started to rise; almost thought better of it; did rise; sat down again.',\n",
       " 'He got up and walked over, holding his own book, which was a paperback Western.',\n",
       " '“Hello,” he said agreeably.',\n",
       " '“Do we know each other?”\\n\\n“No,” she said.',\n",
       " '“That is…you’re Benjaman Mears, right?”\\n\\n“Right.” He raised his eyebrows.',\n",
       " 'She laughed nervously, not looking in his eyes except in a quick flash, to try to read the barometer of his intentions.',\n",
       " 'She was quite obviously a girl not accustomed to speaking to strange men in the park.',\n",
       " '“I thought I was seeing a ghost.” She held up the book in her lap.',\n",
       " 'He saw fleetingly that “Jerusalem’s Lot Public Library” was stamped on the thickness of pages between covers.',\n",
       " 'The book was Air Dance, his second novel.',\n",
       " 'She showed him the photograph of himself on the back jacket, a photo that was four years old now.',\n",
       " 'The face looked boyish and frighteningly serious—the eyes were black diamonds.',\n",
       " '“Of such inconsequential beginnings dynasties are begun,” he said, and although it was a joking throwaway remark, it hung oddly in the air, like prophecy spoken in jest.',\n",
       " 'Behind them, a number of toddlers were splashing happily in the wading pool and a mother was telling Roddy not to push his sister so high.',\n",
       " 'The sister went soaring up on her swing regardless, dress flying, trying for the sky.',\n",
       " 'It was a moment he remembered for years after, as though a special small slice had been cut from the cake of time.',\n",
       " 'If nothing fires between two people, such an instant simply falls back into the general wrack of memory.',\n",
       " 'Then she laughed and offered him the book.',\n",
       " '“Will you autograph it?”\\n\\n“A library book?”\\n\\n“I’ll buy it from them and replace it.”\\n\\nHe found a mechanical pencil in his sweater pocket, opened the book to the flyleaf, and asked, “What’s your name?”\\n\\n“Susan Norton.”\\n\\nHe wrote quickly, without thinking: For Susan Norton, the prettiest girl in the park.',\n",
       " 'Warm regards, Ben Mears.',\n",
       " 'He added the date below his signature in slashed notation.',\n",
       " '“Now you’ll have to steal it,” he said, handing it back.',\n",
       " '“Air Dance is out of print, alas.”\\n\\n“I’ll get a copy from one of those book finders in New York.” She hesitated, and this time her glance at his eyes was a little longer.',\n",
       " '“It’s an awfully good book.”\\n\\n“Thanks.',\n",
       " 'When I take it down and look at it, I wonder how it ever got published.”\\n\\n“Do you take it down often?”\\n\\n“Yeah, but I’m trying to quit.”\\n\\nShe grinned at him and they both laughed and that made things more natural.',\n",
       " 'Later he would have a chance to think how easily this had happened, how smoothly.',\n",
       " 'The thought was never a comfortable one.',\n",
       " 'It conjured up an image of fate, not blind at all but equipped with sentient 20/20 vision and intent on grinding helpless mortals between the great millstones of the universe to make some unknown bread.',\n",
       " '“I read Conway’s Daughter, too.',\n",
       " 'I loved that.',\n",
       " 'I suppose you hear that all the time.”\\n\\n“Remarkably little,” he said honestly.',\n",
       " 'Miranda had also loved Conway’s Daughter, but most of his coffeehouse friends had been noncommittal and most of the critics had clobbered it.',\n",
       " 'Well, that was critics for you.',\n",
       " 'Plot was out, masturbation in.',\n",
       " '“Well, I did.”\\n\\n“Have you read the new one?”\\n\\n“Billy Said Keep Going?',\n",
       " 'Not yet.',\n",
       " 'Miss Coogan at the drugstore says it’s pretty racy.”\\n\\n“Hell, it’s almost puritanical,” Ben said.',\n",
       " '“The language is rough, but when you’re writing about uneducated country boys, you can’t…look, can I buy you an ice-cream soda or something?',\n",
       " 'I was just getting a hanker on for one.”\\n\\nShe checked his eyes a third time.',\n",
       " 'Then smiled, warmly.',\n",
       " '“Sure.',\n",
       " 'I’d love one.',\n",
       " 'They’re great in Spencer’s.”\\n\\nThat was the beginning of it.',\n",
       " 'TWO\\n\\n“Is that Miss Coogan?”\\n\\nBen asked it, low-voiced.',\n",
       " 'He was looking at a tall, spare woman who was wearing a red nylon duster over her white uniform.',\n",
       " 'Her blue-rinsed hair was done in a steplike succession of finger waves.',\n",
       " '“That’s her.',\n",
       " 'She’s got a little cart she takes to the library every Thursday night.',\n",
       " 'She fills out reserve cards by the ton and drives Miss Starcher crazy.”\\n\\nThey were seated on red leather stools at the soda fountain.',\n",
       " 'He was drinking a chocolate soda; hers was strawberry.',\n",
       " 'Spencer’s also served as the local bus depot and from where they sat they could look through an old-fashioned scrolled arch and into the waiting room, where a solitary young man in Air Force blues sat glumly with his feet planted around his suitcase.',\n",
       " '“Doesn’t look happy to be going wherever he’s going, does he?” she said, following his glance.',\n",
       " '“Leave’s over, I imagine,” Ben said.',\n",
       " 'Now, he thought, she’ll ask if I’ve ever been in the service.',\n",
       " 'But instead: “I’ll be on that ten-thirty bus one of these days.',\n",
       " 'Goodby, ’salem’s Lot.',\n",
       " 'Probably I’ll be looking just as glum as that boy.”\\n\\n“Where?”\\n\\n“New York, I guess.',\n",
       " 'To see if I can’t finally become self-supporting.”\\n\\n“What’s wrong with right here?”\\n\\n“The Lot?',\n",
       " 'I love it.',\n",
       " 'But my folks, you know.',\n",
       " 'They’d always be sort of looking over my shoulder.',\n",
       " 'That’s a bummer.',\n",
       " 'And the Lot doesn’t really have that much to offer the young career girl.” She shrugged and dipped her head to suck at her straw.',\n",
       " 'Her neck was tanned, beautifully muscled.',\n",
       " 'She was wearing a colorful print shift that hinted at a good figure.',\n",
       " '“What kind of job are you looking for?”\\n\\nShe shrugged.',\n",
       " '“I’ve got a B.A.',\n",
       " 'from Boston University…not worth the paper it’s printed on, really.',\n",
       " 'Art major, English minor.',\n",
       " 'The original dipso duo.',\n",
       " 'Strictly eligible for the educated idiot category.',\n",
       " 'I’m not even trained to decorate an office.',\n",
       " 'Some of the girls I went to high school with are holding down plump secretarial jobs now.',\n",
       " 'I never got beyond Personal Typing I, myself.”\\n\\n“So what does that leave?”\\n\\n“Oh…maybe a publishing house,” she said vaguely.',\n",
       " '“Or some magazine…advertising, maybe.',\n",
       " 'Places like that can always use someone who can draw on command.',\n",
       " 'I can do that.',\n",
       " 'I have a portfolio.”\\n\\n“Do you have offers?” he asked gently.',\n",
       " '“No…no.',\n",
       " 'But…”\\n\\n“You don’t go to New York without offers,” he said.',\n",
       " '“Believe me.',\n",
       " 'You’ll wear out the heels on your shoes.”\\n\\nShe smiled uneasily.',\n",
       " '“I guess you should know.”\\n\\n“Have you sold stuff locally?”\\n\\n“Oh yes.” She laughed abruptly.',\n",
       " '“My biggest sale to date was to the Cinex Corporation.',\n",
       " 'They opened a new triple cinema in Portland and bought twelve paintings at a crack to hang in their lobby.',\n",
       " 'Paid seven hundred dollars.',\n",
       " 'I made a down payment on my little car.”\\n\\n“You ought to take a hotel room for a week or so in New York,” he said, “and hit every magazine and publishing house you can find with your portfolio.',\n",
       " 'Make your appointments six months in advance so the editors and personnel guys don’t have anything on their calendars.',\n",
       " 'But for God’s sake, don’t just haul stakes for the big city.”\\n\\n“What about you?” she asked, leaving off the straw and spooning ice cream.',\n",
       " '“What are you doing in the thriving community of Jerusalem’s Lot, Maine, population thirteen hundred?”\\n\\nHe shrugged.',\n",
       " '“Trying to write a novel.”\\n\\nShe was instantly alight with excitement.',\n",
       " '“In the Lot?',\n",
       " 'What’s it about?',\n",
       " 'Why here?',\n",
       " 'Are you—”\\n\\nHe looked at her gravely.',\n",
       " '“You’re dripping.”\\n\\n“I’m—?',\n",
       " 'Oh, I am.',\n",
       " 'Sorry.” She mopped the base of her glass with a napkin.',\n",
       " '“Say, I didn’t mean to pry.',\n",
       " 'I’m really not gushy as a rule.”\\n\\n“No apology needed,” he said.',\n",
       " '“All writers like to talk about their books.',\n",
       " 'Sometimes when I’m lying in bed at night I make up a Playboy interview about me.',\n",
       " 'Waste of time.',\n",
       " 'They only do authors if their books are big on campus.”\\n\\nThe Air Force youngster stood up.',\n",
       " 'A Greyhound was pulling up to the curb out front, air brakes chuffing.',\n",
       " '“I lived in ’salem’s Lot for four years as a kid.',\n",
       " 'Out on the Burns Road.”\\n\\n“The Burns Road?',\n",
       " 'There’s nothing out there now but the Marshes and a little graveyard.',\n",
       " 'Harmony Hill, they call it.”\\n\\n“I lived with my Aunt Cindy.',\n",
       " 'Cynthia Stowens.',\n",
       " 'My dad died, see, and my mom went through a…well, kind of a nervous breakdown.',\n",
       " 'So she farmed me out to Aunt Cindy while she got her act back together.',\n",
       " 'Aunt Cindy put me on a bus back to Long Island and my mom just about a month after the big fire.” He looked at his face in the mirror behind the soda fountain.',\n",
       " '“I cried on the bus going away from Mom, and I cried on the bus going away from Aunt Cindy and Jerusalem’s Lot.”\\n\\n“I was born the year of the fire,” Susan said.',\n",
       " '“The biggest damn thing that ever happened to this town and I slept through it.”\\n\\nBen laughed.',\n",
       " '“That makes you about seven years older than I thought in the park.”\\n\\n“Really?” She looked pleased.',\n",
       " '“Thank you…I think.',\n",
       " 'Your aunt’s house must have burned down.”\\n\\n“Yes,” he said.',\n",
       " '“That night is one of my clearest memories.',\n",
       " 'Some men with Indian pumps on their backs came to the door and said we’d have to leave.',\n",
       " 'It was very exciting.',\n",
       " 'Aunt Cindy dithered around, picking things up and loading them into her Hudson.',\n",
       " 'Christ, what a night.”\\n\\n“Was she insured?”\\n\\n“No, but the house was rented and we got just about everything valuable into the car, except for the TV.',\n",
       " 'We tried to lift it and couldn’t even budge it off the floor.',\n",
       " 'It was a Video King with a seven-inch screen and a magnifying glass over the picture tube.',\n",
       " 'Hell on the eyes.',\n",
       " 'We only got one channel anyway—lots of country music, farm reports, and Kitty the Klown.”\\n\\n“And you came back here to write a book,” she marveled.',\n",
       " 'Ben didn’t reply at once.',\n",
       " 'Miss Coogan was opening cartons of cigarettes and filling the display rack by the cash register.',\n",
       " 'The pharmacist, Mr Labree, was puttering around behind the high drug counter like a frosty ghost.',\n",
       " 'The Air Force kid was standing by the door to the bus, waiting for the driver to come back from the bathroom.',\n",
       " '“Yes,” Ben said.',\n",
       " 'He turned and looked at her, full in the face, for the first time.',\n",
       " 'She had a very pretty face, with candid blue eyes and a high, clear, tanned forehead.',\n",
       " '“Is this town your childhood?” he asked.',\n",
       " '“Yes.”\\n\\nHe nodded.',\n",
       " '“Then you know.',\n",
       " 'I was a kid in ’salem’s Lot and it’s haunted for me.',\n",
       " 'When I came back, I almost drove right by because I was afraid it would be different.”\\n\\n“Things don’t change here,” she said.',\n",
       " '“Not very much.”\\n\\n“I used to play war with the Gardener kids down in the Marshes.',\n",
       " 'Pirates out by Royal’s Pond.',\n",
       " 'Capture-the-flag and hide-and-go-seek in the park.',\n",
       " 'My mom and I knocked around some pretty hard places after I left Aunt Cindy.',\n",
       " 'She killed herself when I was fourteen, but most of the magic dust had rubbed off me long before that.',\n",
       " 'What there was of it was here.',\n",
       " 'And it’s still here.',\n",
       " 'The town hasn’t changed that much.',\n",
       " 'Looking out on Jointner Avenue is like looking through a thin pane of ice—like the one you can pick off the top of the town cistern in November if you knock it around the edges first—looking through that at your childhood.',\n",
       " 'It’s wavy and misty and in some places it trails off into nothing, but most of it is still all there.”\\n\\nHe stopped, amazed.',\n",
       " 'He had made a speech.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[4][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert sentences to Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.758919Z",
     "start_time": "2017-11-06T22:11:51.493409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d by “Duel”\\n\\nJoe Hill and Stephen King\\n\\n\\n...</td>\n",
       "      <td>Throttle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finally, in the early afternoon, they turned i...</td>\n",
       "      <td>Throttle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The overlapping thunder of their engines shook...</td>\n",
       "      <td>Throttle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They drew up together among parked long-haul t...</td>\n",
       "      <td>Throttle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Race Adamson had led them the whole way, his H...</td>\n",
       "      <td>Throttle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content     title\n",
       "0  d by “Duel”\\n\\nJoe Hill and Stephen King\\n\\n\\n...  Throttle\n",
       "1  Finally, in the early afternoon, they turned i...  Throttle\n",
       "2  The overlapping thunder of their engines shook...  Throttle\n",
       "3  They drew up together among parked long-haul t...  Throttle\n",
       "4  Race Adamson had led them the whole way, his H...  Throttle"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentDF = pd.DataFrame([(d, tup.title) for tup in df.itertuples() for d in tup.content])\n",
    "sentDF.columns = ['content','title']\n",
    "sentDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.810734Z",
     "start_time": "2017-11-06T22:11:51.762303Z"
    }
   },
   "outputs": [],
   "source": [
    "cujoDF = sentDF.loc[sentDF['title'] == 'Cujo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.826505Z",
     "start_time": "2017-11-06T22:11:51.813233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>647569</th>\n",
       "      <td>Page\\n\\nCopyright Page\\n\\nDedication\\n\\n\\n\\n\\...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647570</th>\n",
       "      <td>.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647571</th>\n",
       "      <td>.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647572</th>\n",
       "      <td>CUJO\\n\\nIt happens innocently enough, but does...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647573</th>\n",
       "      <td>A big, friendly dog chases a rabbit into a hid...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647574</th>\n",
       "      <td>A terrified four-year-old boy sees his bedroom...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647575</th>\n",
       "      <td>The little Maine town of Castle Rock is about ...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647576</th>\n",
       "      <td>“Hits the jugular.”\\n\\n—New York Times\\n\\n\\n\\n...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647577</th>\n",
       "      <td>250 Camberwell Road, Camberwell.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647578</th>\n",
       "      <td>Victoria 3124.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647579</th>\n",
       "      <td>Australia (a division of Pearson Australia Gro...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647580</th>\n",
       "      <td>Ltd.)\\n\\nPenguin Books India Pvt.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647581</th>\n",
       "      <td>Ltd., II Community Centre, Panchsheel Park, Ne...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647582</th>\n",
       "      <td>Rosedale, North Shore 0632, New Zealand (a div...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647583</th>\n",
       "      <td>Ltd., 24 Sturdee Avenue, Rosebank, Johannesbur...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647584</th>\n",
       "      <td>England\\n\\n\\n\\n\\n\\nFirst Signet Printing, June...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647585</th>\n",
       "      <td>1981\\n\\nAll rights reserved\\n\\n\\n\\n\\n\\nGratefu...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647586</th>\n",
       "      <td>Portions of text from the song “Sugaree,” word...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647587</th>\n",
       "      <td>Copyright © Ice Nine Publishing Company, 1971.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647588</th>\n",
       "      <td>All rights reserved.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647589</th>\n",
       "      <td>Random House, Inc. An excerpt from “Musée des ...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647590</th>\n",
       "      <td>Reprinted from W H. Auden: Collected Poems by ...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647591</th>\n",
       "      <td>REGISTERED TRADEMARK—MARCA REGISTRADA\\n\\n\\n\\n\\...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647592</th>\n",
       "      <td>PUBLISHER’S NOTE\\n\\nThis is a work of fiction.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647593</th>\n",
       "      <td>Names, characters, places, and incidents eithe...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647594</th>\n",
       "      <td>The publisher does not have any control over a...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647595</th>\n",
       "      <td>The scanning, uploading, and distribution of t...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647596</th>\n",
       "      <td>Please purchase only authorized electronic edi...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647597</th>\n",
       "      <td>Your support of the author’s rights is appreci...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647598</th>\n",
       "      <td>ISBN : 978-1-101-13806-9\\n\\nhttp://us.penguing...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656801</th>\n",
       "      <td>It’s started to snow again.”\\n\\n“He can come i...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656802</th>\n",
       "      <td>And if he piddles around, you clean it up.”\\n\\...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656803</th>\n",
       "      <td>“What do you want to call him, Brett?”\\n\\n“I d...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656804</th>\n",
       "      <td>There was a long, long pause.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656805</th>\n",
       "      <td>“I don’t know yet.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656806</th>\n",
       "      <td>I’ll have to think on it.”\\n\\nShe had an impre...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656807</th>\n",
       "      <td>Besides, his back was to her and she couldn’t ...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656808</th>\n",
       "      <td>He was getting to be a big boy, and as much as...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656809</th>\n",
       "      <td>He went outside and brought the dog back in, c...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656810</th>\n",
       "      <td>It remained unnamed until the following spring...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656811</th>\n",
       "      <td>It was a small, lively, short-haired dog, most...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656812</th>\n",
       "      <td>Somehow it just looked like a Willie.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656813</th>\n",
       "      <td>The name stuck.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656814</th>\n",
       "      <td>Much later, that spring, Charity got a small p...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656815</th>\n",
       "      <td>She began to put away ten dollars a week.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656816</th>\n",
       "      <td>Toward Brett’s college.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656817</th>\n",
       "      <td>Shortly following those mortal events in the C...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656818</th>\n",
       "      <td>The ashes went out with the trash and were dis...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656819</th>\n",
       "      <td>It would perhaps not be amiss to point out tha...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656820</th>\n",
       "      <td>He had tried to do all the things his MAN and ...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656821</th>\n",
       "      <td>He would have died for them, if that had been ...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656822</th>\n",
       "      <td>He had never wanted to kill anybody.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656823</th>\n",
       "      <td>He had been struck by something, possibly dest...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656824</th>\n",
       "      <td>Free will was not a factor.</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656825</th>\n",
       "      <td>The small cave into which Cujo had chased the ...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656826</th>\n",
       "      <td>Eventually, for whatever vague reasons small c...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656827</th>\n",
       "      <td>The rabbit was unable to get out and it starve...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656828</th>\n",
       "      <td>Its bones, so far as I know, still remain ther...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656829</th>\n",
       "      <td>I’m tellin you so you’ll know,\\n\\nI’m tellin y...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656830</th>\n",
       "      <td>—FOLK SONG\\n\\n\\n\\nSeptember 1977-\\n\\nMarch 198...</td>\n",
       "      <td>Cujo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9262 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  content title\n",
       "647569   Page\\n\\nCopyright Page\\n\\nDedication\\n\\n\\n\\n\\...  Cujo\n",
       "647570                                                  .  Cujo\n",
       "647571                                                  .  Cujo\n",
       "647572  CUJO\\n\\nIt happens innocently enough, but does...  Cujo\n",
       "647573  A big, friendly dog chases a rabbit into a hid...  Cujo\n",
       "647574  A terrified four-year-old boy sees his bedroom...  Cujo\n",
       "647575  The little Maine town of Castle Rock is about ...  Cujo\n",
       "647576  “Hits the jugular.”\\n\\n—New York Times\\n\\n\\n\\n...  Cujo\n",
       "647577                   250 Camberwell Road, Camberwell.  Cujo\n",
       "647578                                     Victoria 3124.  Cujo\n",
       "647579  Australia (a division of Pearson Australia Gro...  Cujo\n",
       "647580                  Ltd.)\\n\\nPenguin Books India Pvt.  Cujo\n",
       "647581  Ltd., II Community Centre, Panchsheel Park, Ne...  Cujo\n",
       "647582  Rosedale, North Shore 0632, New Zealand (a div...  Cujo\n",
       "647583  Ltd., 24 Sturdee Avenue, Rosebank, Johannesbur...  Cujo\n",
       "647584  England\\n\\n\\n\\n\\n\\nFirst Signet Printing, June...  Cujo\n",
       "647585  1981\\n\\nAll rights reserved\\n\\n\\n\\n\\n\\nGratefu...  Cujo\n",
       "647586  Portions of text from the song “Sugaree,” word...  Cujo\n",
       "647587     Copyright © Ice Nine Publishing Company, 1971.  Cujo\n",
       "647588                               All rights reserved.  Cujo\n",
       "647589  Random House, Inc. An excerpt from “Musée des ...  Cujo\n",
       "647590  Reprinted from W H. Auden: Collected Poems by ...  Cujo\n",
       "647591  REGISTERED TRADEMARK—MARCA REGISTRADA\\n\\n\\n\\n\\...  Cujo\n",
       "647592     PUBLISHER’S NOTE\\n\\nThis is a work of fiction.  Cujo\n",
       "647593  Names, characters, places, and incidents eithe...  Cujo\n",
       "647594  The publisher does not have any control over a...  Cujo\n",
       "647595  The scanning, uploading, and distribution of t...  Cujo\n",
       "647596  Please purchase only authorized electronic edi...  Cujo\n",
       "647597  Your support of the author’s rights is appreci...  Cujo\n",
       "647598  ISBN : 978-1-101-13806-9\\n\\nhttp://us.penguing...  Cujo\n",
       "...                                                   ...   ...\n",
       "656801  It’s started to snow again.”\\n\\n“He can come i...  Cujo\n",
       "656802  And if he piddles around, you clean it up.”\\n\\...  Cujo\n",
       "656803  “What do you want to call him, Brett?”\\n\\n“I d...  Cujo\n",
       "656804                      There was a long, long pause.  Cujo\n",
       "656805                                 “I don’t know yet.  Cujo\n",
       "656806  I’ll have to think on it.”\\n\\nShe had an impre...  Cujo\n",
       "656807  Besides, his back was to her and she couldn’t ...  Cujo\n",
       "656808  He was getting to be a big boy, and as much as...  Cujo\n",
       "656809  He went outside and brought the dog back in, c...  Cujo\n",
       "656810  It remained unnamed until the following spring...  Cujo\n",
       "656811  It was a small, lively, short-haired dog, most...  Cujo\n",
       "656812              Somehow it just looked like a Willie.  Cujo\n",
       "656813                                    The name stuck.  Cujo\n",
       "656814  Much later, that spring, Charity got a small p...  Cujo\n",
       "656815          She began to put away ten dollars a week.  Cujo\n",
       "656816                            Toward Brett’s college.  Cujo\n",
       "656817  Shortly following those mortal events in the C...  Cujo\n",
       "656818  The ashes went out with the trash and were dis...  Cujo\n",
       "656819  It would perhaps not be amiss to point out tha...  Cujo\n",
       "656820  He had tried to do all the things his MAN and ...  Cujo\n",
       "656821  He would have died for them, if that had been ...  Cujo\n",
       "656822               He had never wanted to kill anybody.  Cujo\n",
       "656823  He had been struck by something, possibly dest...  Cujo\n",
       "656824                        Free will was not a factor.  Cujo\n",
       "656825  The small cave into which Cujo had chased the ...  Cujo\n",
       "656826  Eventually, for whatever vague reasons small c...  Cujo\n",
       "656827  The rabbit was unable to get out and it starve...  Cujo\n",
       "656828  Its bones, so far as I know, still remain ther...  Cujo\n",
       "656829  I’m tellin you so you’ll know,\\n\\nI’m tellin y...  Cujo\n",
       "656830  —FOLK SONG\\n\\n\\n\\nSeptember 1977-\\n\\nMarch 198...  Cujo\n",
       "\n",
       "[9262 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cujoDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:11:51.831841Z",
     "start_time": "2017-11-06T22:11:51.828868Z"
    }
   },
   "outputs": [],
   "source": [
    "books = sentDF.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:18:25.133394Z",
     "start_time": "2017-11-06T22:11:51.834106Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# totalvocab_stemmed = []\n",
    "# totalvocab_tokenized = []\n",
    "# for i in books:\n",
    "#     allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n",
    "#     totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "#     allwords_tokenized = tokenize_only(i)\n",
    "#     totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:18:25.208064Z",
     "start_time": "2017-11-06T22:18:25.150383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d',\n",
       " 'by',\n",
       " 'duel',\n",
       " 'joe',\n",
       " 'hill',\n",
       " 'and',\n",
       " 'stephen',\n",
       " 'king',\n",
       " 'content',\n",
       " 'cover',\n",
       " 'titl',\n",
       " 'page',\n",
       " 'throttl',\n",
       " 'about',\n",
       " 'the',\n",
       " 'author',\n",
       " 'credit',\n",
       " 'copyright',\n",
       " 'more',\n",
       " 'from',\n",
       " 'the',\n",
       " 'author',\n",
       " 'about',\n",
       " 'the',\n",
       " 'publish',\n",
       " '******start_of_file******',\n",
       " 'throttl',\n",
       " 'they',\n",
       " 'rode',\n",
       " 'west',\n",
       " 'from',\n",
       " 'the',\n",
       " 'slaughter',\n",
       " 'through',\n",
       " 'the',\n",
       " 'paint',\n",
       " 'desert',\n",
       " 'and',\n",
       " 'did',\n",
       " 'not',\n",
       " 'stop',\n",
       " 'until',\n",
       " 'they',\n",
       " 'were',\n",
       " 'a',\n",
       " 'hundr',\n",
       " 'mile',\n",
       " 'away',\n",
       " 'final',\n",
       " 'in',\n",
       " 'the',\n",
       " 'earli',\n",
       " 'afternoon',\n",
       " 'they',\n",
       " 'turn',\n",
       " 'in',\n",
       " 'at',\n",
       " 'a',\n",
       " 'diner',\n",
       " 'with',\n",
       " 'a',\n",
       " 'white',\n",
       " 'stucco',\n",
       " 'exterior',\n",
       " 'and',\n",
       " 'pump',\n",
       " 'on',\n",
       " 'concret',\n",
       " 'island',\n",
       " 'out',\n",
       " 'front',\n",
       " 'the',\n",
       " 'overlap',\n",
       " 'thunder',\n",
       " 'of',\n",
       " 'their',\n",
       " 'engin',\n",
       " 'shook',\n",
       " 'the',\n",
       " 'plate-glass',\n",
       " 'window',\n",
       " 'as',\n",
       " 'they',\n",
       " 'roll',\n",
       " 'by',\n",
       " 'they',\n",
       " 'drew',\n",
       " 'up',\n",
       " 'togeth',\n",
       " 'among',\n",
       " 'park',\n",
       " 'long-haul',\n",
       " 'truck',\n",
       " 'on',\n",
       " 'the',\n",
       " 'west',\n",
       " 'side',\n",
       " 'of',\n",
       " 'the',\n",
       " 'build',\n",
       " 'and',\n",
       " 'there',\n",
       " 'they',\n",
       " 'put',\n",
       " 'down',\n",
       " 'their',\n",
       " 'kickstand',\n",
       " 'and',\n",
       " 'turn',\n",
       " 'off',\n",
       " 'their',\n",
       " 'bike',\n",
       " 'race',\n",
       " 'adamson',\n",
       " 'had',\n",
       " 'led',\n",
       " 'them',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'way',\n",
       " 'his',\n",
       " 'harley',\n",
       " 'run',\n",
       " 'sometim',\n",
       " 'as',\n",
       " 'much',\n",
       " 'as',\n",
       " 'a',\n",
       " 'quarter-mil',\n",
       " 'ahead',\n",
       " 'of',\n",
       " 'anyon',\n",
       " 'els',\n",
       " 's',\n",
       " 'it',\n",
       " 'had',\n",
       " 'been',\n",
       " 'race',\n",
       " 's',\n",
       " 'habit',\n",
       " 'to',\n",
       " 'ride',\n",
       " 'out',\n",
       " 'in',\n",
       " 'front',\n",
       " 'ever',\n",
       " 'sinc',\n",
       " 'he',\n",
       " 'had',\n",
       " 'return',\n",
       " 'to',\n",
       " 'them',\n",
       " 'after',\n",
       " 'two',\n",
       " 'year',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sand',\n",
       " 'he',\n",
       " 'ran',\n",
       " 'so',\n",
       " 'far',\n",
       " 'in',\n",
       " 'front',\n",
       " 'it',\n",
       " 'often',\n",
       " 'seem',\n",
       " 'he',\n",
       " 'was',\n",
       " 'dare',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'them',\n",
       " 'to',\n",
       " 'tri',\n",
       " 'and',\n",
       " 'keep',\n",
       " 'up',\n",
       " 'or',\n",
       " 'mayb',\n",
       " 'had',\n",
       " 'a',\n",
       " 'mind',\n",
       " 'to',\n",
       " 'simpli',\n",
       " 'leav',\n",
       " 'them',\n",
       " 'behind',\n",
       " 'he',\n",
       " 'hadn',\n",
       " 't',\n",
       " 'want',\n",
       " 'to',\n",
       " 'stop',\n",
       " 'here',\n",
       " 'but',\n",
       " 'vinc',\n",
       " 'had',\n",
       " 'forc',\n",
       " 'him',\n",
       " 'to',\n",
       " 'as',\n",
       " 'the',\n",
       " 'diner',\n",
       " 'came',\n",
       " 'into',\n",
       " 'sight',\n",
       " 'vinc',\n",
       " 'had',\n",
       " 'throttl',\n",
       " 'after',\n",
       " 'race',\n",
       " 'blown',\n",
       " 'past',\n",
       " 'him',\n",
       " 'and',\n",
       " 'then',\n",
       " 'shot',\n",
       " 'his',\n",
       " 'hand',\n",
       " 'left',\n",
       " 'in',\n",
       " 'a',\n",
       " 'gestur',\n",
       " 'the',\n",
       " 'tribe',\n",
       " 'knew',\n",
       " 'well',\n",
       " 'follow',\n",
       " 'me',\n",
       " 'off',\n",
       " 'the',\n",
       " 'highway',\n",
       " 'the',\n",
       " 'tribe',\n",
       " 'let',\n",
       " 'vinc',\n",
       " 's',\n",
       " 'hand',\n",
       " 'gestur',\n",
       " 'call',\n",
       " 'it',\n",
       " 'as',\n",
       " 'they',\n",
       " 'alway',\n",
       " 'did',\n",
       " 'anoth',\n",
       " 'thing',\n",
       " 'for',\n",
       " 'race',\n",
       " 'to',\n",
       " 'dislik',\n",
       " 'about',\n",
       " 'him',\n",
       " 'probabl',\n",
       " 'the',\n",
       " 'kid',\n",
       " 'had',\n",
       " 'a',\n",
       " 'pocket',\n",
       " 'of',\n",
       " 'them',\n",
       " 'race',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'first',\n",
       " 'to',\n",
       " 'park',\n",
       " 'but',\n",
       " 'the',\n",
       " 'last',\n",
       " 'to',\n",
       " 'dismount',\n",
       " 'he',\n",
       " 'stood',\n",
       " 'astrid',\n",
       " 'his',\n",
       " 'bike',\n",
       " 'slowli',\n",
       " 'strip',\n",
       " 'off',\n",
       " 'his',\n",
       " 'leather',\n",
       " 'ride',\n",
       " 'glove',\n",
       " 'glare',\n",
       " 'at',\n",
       " 'the',\n",
       " 'other',\n",
       " 'from',\n",
       " 'behind',\n",
       " 'his',\n",
       " 'mirror',\n",
       " 'sunglass',\n",
       " 'you',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'have',\n",
       " 'a',\n",
       " 'talk',\n",
       " 'with',\n",
       " 'your',\n",
       " 'boy',\n",
       " 'lemmi',\n",
       " 'chapman',\n",
       " 'said',\n",
       " 'to',\n",
       " 'vinc',\n",
       " 'lemmi',\n",
       " 'nod',\n",
       " 'in',\n",
       " 'race',\n",
       " 's',\n",
       " 'direct',\n",
       " 'not',\n",
       " 'here',\n",
       " 'vinc',\n",
       " 'said',\n",
       " 'it',\n",
       " 'could',\n",
       " 'wait',\n",
       " 'until',\n",
       " 'they',\n",
       " 'were',\n",
       " 'back',\n",
       " 'in',\n",
       " 'vega',\n",
       " 'he',\n",
       " 'want',\n",
       " 'to',\n",
       " 'put',\n",
       " 'the',\n",
       " 'road',\n",
       " 'behind',\n",
       " 'him',\n",
       " 'he',\n",
       " 'want',\n",
       " 'to',\n",
       " 'lie',\n",
       " 'down',\n",
       " 'in',\n",
       " 'the',\n",
       " 'dark',\n",
       " 'for',\n",
       " 'a',\n",
       " 'while',\n",
       " 'want',\n",
       " 'some',\n",
       " 'time',\n",
       " 'to',\n",
       " 'allow',\n",
       " 'the',\n",
       " 'sick',\n",
       " 'knot',\n",
       " 'in',\n",
       " 'his',\n",
       " 'stomach',\n",
       " 'to',\n",
       " 'abat',\n",
       " 'mayb',\n",
       " 'most',\n",
       " 'of',\n",
       " 'all',\n",
       " 'he',\n",
       " 'want',\n",
       " 'to',\n",
       " 'shower',\n",
       " 'he',\n",
       " 'hadn',\n",
       " 't',\n",
       " 'gotten',\n",
       " 'ani',\n",
       " 'blood',\n",
       " 'on',\n",
       " 'him',\n",
       " 'but',\n",
       " 'felt',\n",
       " 'contamin',\n",
       " 'all',\n",
       " 'the',\n",
       " 'same',\n",
       " 'and',\n",
       " 'wouldn',\n",
       " 't',\n",
       " 'be',\n",
       " 'at',\n",
       " 'eas',\n",
       " 'in',\n",
       " 'his',\n",
       " 'own',\n",
       " 'skin',\n",
       " 'until',\n",
       " 'he',\n",
       " 'had',\n",
       " 'wash',\n",
       " 'the',\n",
       " 'morn',\n",
       " 's',\n",
       " 'stink',\n",
       " 'off',\n",
       " 'he',\n",
       " 'took',\n",
       " 'a',\n",
       " 'step',\n",
       " 'in',\n",
       " 'the',\n",
       " 'direct',\n",
       " 'of',\n",
       " 'the',\n",
       " 'diner',\n",
       " 'but',\n",
       " 'lemmi',\n",
       " 'caught',\n",
       " 'his',\n",
       " 'arm',\n",
       " 'befor',\n",
       " 'he',\n",
       " 'could',\n",
       " 'go',\n",
       " 'ani',\n",
       " 'farther',\n",
       " 'yes',\n",
       " 'here.',\n",
       " 'vinc',\n",
       " 'look',\n",
       " 'at',\n",
       " 'the',\n",
       " 'hand',\n",
       " 'on',\n",
       " 'his',\n",
       " 'arm—lemmi',\n",
       " 'didn',\n",
       " 't',\n",
       " 'let',\n",
       " 'go',\n",
       " 'lemmi',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'men',\n",
       " 'had',\n",
       " 'no',\n",
       " 'fear',\n",
       " 'of',\n",
       " 'him—then',\n",
       " 'glanc',\n",
       " 'toward',\n",
       " 'the',\n",
       " 'kid',\n",
       " 'who',\n",
       " 'wasn',\n",
       " 't',\n",
       " 'realli',\n",
       " 'a',\n",
       " 'kid',\n",
       " 'at',\n",
       " 'all',\n",
       " 'anymor',\n",
       " 'and',\n",
       " 'hadn',\n",
       " 't',\n",
       " 'been',\n",
       " 'for',\n",
       " 'year',\n",
       " 'race',\n",
       " 'was',\n",
       " 'open',\n",
       " 'the',\n",
       " 'hardcas',\n",
       " 'over',\n",
       " 'his',\n",
       " 'back',\n",
       " 'tire',\n",
       " 'fish',\n",
       " 'through',\n",
       " 'his',\n",
       " 'gear',\n",
       " 'for',\n",
       " 'someth',\n",
       " 'what',\n",
       " 's',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'clark',\n",
       " 's',\n",
       " 'gone',\n",
       " 'so',\n",
       " 's',\n",
       " 'the',\n",
       " 'money',\n",
       " 'there',\n",
       " 's',\n",
       " 'noth',\n",
       " 'left',\n",
       " 'to',\n",
       " 'do',\n",
       " 'not',\n",
       " 'this',\n",
       " 'morning.',\n",
       " 'you',\n",
       " 'ought',\n",
       " 'to',\n",
       " 'find',\n",
       " 'out',\n",
       " 'if',\n",
       " 'race',\n",
       " 'feel',\n",
       " 'the',\n",
       " 'same',\n",
       " 'way',\n",
       " 'you',\n",
       " 'been',\n",
       " 'assum',\n",
       " 'the',\n",
       " 'two',\n",
       " 'of',\n",
       " 'you',\n",
       " 'are',\n",
       " 'on',\n",
       " 'the',\n",
       " 'same',\n",
       " 'page',\n",
       " 'even',\n",
       " 'though',\n",
       " 'these',\n",
       " 'day',\n",
       " 'he',\n",
       " 'spend',\n",
       " 'forti',\n",
       " 'minut',\n",
       " 'of',\n",
       " 'everi',\n",
       " 'hour',\n",
       " 'piss',\n",
       " 'off',\n",
       " 'at',\n",
       " 'you',\n",
       " 'tell',\n",
       " 'you',\n",
       " 'someth',\n",
       " 'els',\n",
       " 'boss',\n",
       " 'race',\n",
       " 'brought',\n",
       " 'some',\n",
       " 'of',\n",
       " 'these',\n",
       " 'guy',\n",
       " 'in',\n",
       " 'and',\n",
       " 'he',\n",
       " 'got',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'them',\n",
       " 'fire',\n",
       " 'up',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'how',\n",
       " 'rich',\n",
       " 'they',\n",
       " 'were',\n",
       " 'all',\n",
       " 'go',\n",
       " 'to',\n",
       " 'get',\n",
       " 'on',\n",
       " 'his',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'clark',\n",
       " 'he',\n",
       " 'might',\n",
       " 'not',\n",
       " 'be',\n",
       " 'the',\n",
       " 'onli',\n",
       " 'one',\n",
       " 'who',\n",
       " 'need',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'what',\n",
       " 's',\n",
       " 'next.',\n",
       " 'he',\n",
       " 'glanc',\n",
       " 'meaning',\n",
       " 'at',\n",
       " 'the',\n",
       " 'other',\n",
       " 'men',\n",
       " 'vinc',\n",
       " 'notic',\n",
       " 'for',\n",
       " 'the',\n",
       " 'first',\n",
       " 'time',\n",
       " 'that',\n",
       " 'they',\n",
       " 'weren',\n",
       " 't',\n",
       " 'drift',\n",
       " 'on',\n",
       " 'toward',\n",
       " 'the',\n",
       " 'diner',\n",
       " 'but',\n",
       " 'hang',\n",
       " 'around',\n",
       " 'by',\n",
       " 'their',\n",
       " 'bike',\n",
       " 'cast',\n",
       " 'look',\n",
       " 'toward',\n",
       " 'him',\n",
       " 'and',\n",
       " 'race',\n",
       " 'both',\n",
       " 'wait',\n",
       " 'for',\n",
       " 'someth',\n",
       " 'to',\n",
       " 'come',\n",
       " 'to',\n",
       " 'pass',\n",
       " 'vinc',\n",
       " 'didn',\n",
       " 't',\n",
       " 'want',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'the',\n",
       " 'thought',\n",
       " 'of',\n",
       " 'talk',\n",
       " 'drain',\n",
       " 'him',\n",
       " 'late',\n",
       " 'convers',\n",
       " 'with',\n",
       " 'race',\n",
       " 'was',\n",
       " 'like',\n",
       " 'throw',\n",
       " 'a',\n",
       " 'medicin',\n",
       " 'ball',\n",
       " 'back',\n",
       " 'and',\n",
       " 'forth',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'weari',\n",
       " 'effort',\n",
       " 'and',\n",
       " 'he',\n",
       " 'didn',\n",
       " 't',\n",
       " 'feel',\n",
       " 'up',\n",
       " 'to',\n",
       " 'it',\n",
       " 'not',\n",
       " 'with',\n",
       " 'what',\n",
       " 'they',\n",
       " 'were',\n",
       " 'drive',\n",
       " 'away',\n",
       " 'from',\n",
       " 'he',\n",
       " 'went',\n",
       " 'anyway',\n",
       " 'becaus',\n",
       " 'lemmi',\n",
       " 'was',\n",
       " 'almost',\n",
       " 'alway',\n",
       " 'right',\n",
       " 'when',\n",
       " 'it',\n",
       " 'came',\n",
       " 'to',\n",
       " 'tribe',\n",
       " 'preserv',\n",
       " 'lemmi',\n",
       " 'had',\n",
       " 'been',\n",
       " 'ride',\n",
       " 'six',\n",
       " 'to',\n",
       " 'vinc',\n",
       " 's',\n",
       " 'twelv',\n",
       " 'go',\n",
       " 'back',\n",
       " 'to',\n",
       " 'when',\n",
       " 'they',\n",
       " 'had',\n",
       " 'met',\n",
       " 'in',\n",
       " 'the',\n",
       " 'mekong',\n",
       " 'delta',\n",
       " 'and',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'world',\n",
       " 'was',\n",
       " 'dinki',\n",
       " 'dau',\n",
       " 'they',\n",
       " 'had',\n",
       " 'been',\n",
       " 'on',\n",
       " 'the',\n",
       " 'lookout',\n",
       " 'for',\n",
       " 'trip',\n",
       " 'wire',\n",
       " 'and',\n",
       " 'buri',\n",
       " 'mine',\n",
       " 'then',\n",
       " 'noth',\n",
       " 'much',\n",
       " 'had',\n",
       " 'chang',\n",
       " 'in',\n",
       " 'the',\n",
       " 'almost',\n",
       " 'forti',\n",
       " 'year',\n",
       " 'sinc',\n",
       " 'vinc',\n",
       " 'left',\n",
       " 'his',\n",
       " 'bike',\n",
       " 'and',\n",
       " 'cross',\n",
       " 'to',\n",
       " 'race',\n",
       " 'who',\n",
       " 'stood',\n",
       " 'between',\n",
       " 'his',\n",
       " 'harley',\n",
       " 'and',\n",
       " 'a',\n",
       " 'park',\n",
       " 'truck',\n",
       " 'an',\n",
       " 'oil',\n",
       " 'hauler',\n",
       " 'race',\n",
       " 'had',\n",
       " 'found',\n",
       " 'what',\n",
       " 'he',\n",
       " 'was',\n",
       " 'look',\n",
       " 'for',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hardcas',\n",
       " 'on',\n",
       " 'the',\n",
       " 'back',\n",
       " 'of',\n",
       " 'his',\n",
       " 'bike',\n",
       " 'a',\n",
       " 'flask',\n",
       " 'slosh',\n",
       " 'with',\n",
       " 'what',\n",
       " 'look',\n",
       " 'like',\n",
       " 'tea',\n",
       " 'and',\n",
       " 'wasn',\n",
       " 't',\n",
       " 'he',\n",
       " 'drank',\n",
       " 'earlier',\n",
       " 'and',\n",
       " 'earlier',\n",
       " 'someth',\n",
       " 'els',\n",
       " 'vinc',\n",
       " 'didn',\n",
       " 't',\n",
       " 'like',\n",
       " 'race',\n",
       " 'had',\n",
       " 'a',\n",
       " 'pull',\n",
       " 'wipe',\n",
       " 'his',\n",
       " 'mouth',\n",
       " 'held',\n",
       " 'it',\n",
       " 'out',\n",
       " 'to',\n",
       " 'vinc',\n",
       " 'vinc',\n",
       " 'shook',\n",
       " 'his',\n",
       " 'head',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'vinc',\n",
       " 'said',\n",
       " 'if',\n",
       " 'we',\n",
       " 'pick',\n",
       " 'up',\n",
       " 'rout',\n",
       " 'race',\n",
       " 'said',\n",
       " 'we',\n",
       " 'could',\n",
       " 'be',\n",
       " 'down',\n",
       " 'in',\n",
       " 'show',\n",
       " 'low',\n",
       " 'in',\n",
       " 'three',\n",
       " 'hour',\n",
       " 'assum',\n",
       " 'that',\n",
       " 'pussi',\n",
       " 'rice-burn',\n",
       " 'of',\n",
       " 'your',\n",
       " 'can',\n",
       " 'keep',\n",
       " 'up.',\n",
       " 'what',\n",
       " 's',\n",
       " 'in',\n",
       " 'show',\n",
       " 'low',\n",
       " 'clark',\n",
       " 's',\n",
       " 'sister.',\n",
       " 'whi',\n",
       " 'would',\n",
       " 'we',\n",
       " 'want',\n",
       " 'to',\n",
       " 'see',\n",
       " 'her',\n",
       " 'for',\n",
       " 'the',\n",
       " 'money',\n",
       " 'case',\n",
       " 'you',\n",
       " 'hadn',\n",
       " 't',\n",
       " 'notic',\n",
       " 'we',\n",
       " 'just',\n",
       " 'got',\n",
       " 'fuck',\n",
       " 'out',\n",
       " 'of',\n",
       " 'sixti',\n",
       " 'grand.',\n",
       " 'and',\n",
       " 'you',\n",
       " 'think',\n",
       " 'his',\n",
       " 'sister',\n",
       " 'will',\n",
       " 'have',\n",
       " 'it.',\n",
       " 'place',\n",
       " 'to',\n",
       " 'start.',\n",
       " 'let',\n",
       " 's',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'it',\n",
       " 'back',\n",
       " 'in',\n",
       " 'vega',\n",
       " 'look',\n",
       " 'at',\n",
       " 'our',\n",
       " 'option',\n",
       " 'there.',\n",
       " 'how',\n",
       " 'about',\n",
       " 'we',\n",
       " 'look',\n",
       " 'at',\n",
       " 'em',\n",
       " 'now',\n",
       " 'you',\n",
       " 'see',\n",
       " 'clark',\n",
       " 'hang',\n",
       " 'up',\n",
       " 'the',\n",
       " 'phone',\n",
       " 'when',\n",
       " 'we',\n",
       " 'walk',\n",
       " 'in',\n",
       " 'i',\n",
       " 'heard',\n",
       " 'a',\n",
       " 'snatch',\n",
       " 'of',\n",
       " 'what',\n",
       " 'he',\n",
       " 'was',\n",
       " 'say',\n",
       " 'through',\n",
       " 'the',\n",
       " 'door',\n",
       " 'i',\n",
       " 'think',\n",
       " 'he',\n",
       " 'tri',\n",
       " 'to',\n",
       " 'get',\n",
       " 'his',\n",
       " 'sister',\n",
       " 'and',\n",
       " 'when',\n",
       " 'he',\n",
       " 'didn',\n",
       " 't',\n",
       " 'he',\n",
       " 'left',\n",
       " 'a',\n",
       " 'messag',\n",
       " 'with',\n",
       " 'someon',\n",
       " 'who',\n",
       " 'know',\n",
       " 'her',\n",
       " 'now',\n",
       " 'whi',\n",
       " 'do',\n",
       " 'you',\n",
       " 'think',\n",
       " 'he',\n",
       " 'felt',\n",
       " 'a',\n",
       " 'press',\n",
       " 'need',\n",
       " 'to',\n",
       " 'reach',\n",
       " 'out',\n",
       " 'and',\n",
       " 'touch',\n",
       " 'that',\n",
       " 'toe-rag',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'all',\n",
       " 'of',\n",
       " 'us',\n",
       " 'in',\n",
       " 'the',\n",
       " 'driveway',\n",
       " 'to',\n",
       " 'say',\n",
       " 'his',\n",
       " 'goodby',\n",
       " 'was',\n",
       " 'vinc',\n",
       " 's',\n",
       " 'theori',\n",
       " 'but',\n",
       " 'he',\n",
       " 'didn',\n",
       " 't',\n",
       " 'tell',\n",
       " 'race',\n",
       " 'that',\n",
       " 'she',\n",
       " ...]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# totalvocab_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T23:06:11.502355Z",
     "start_time": "2017-11-06T23:06:03.035905Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words=stoplist,max_df=.4,min_df=.05)\n",
    "x = cv.fit_transform(books)\n",
    "cv_feature_names = cv.get_feature_names()\n",
    "#x = cv.transform(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T23:06:11.509141Z",
     "start_time": "2017-11-06T23:06:11.504796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748650, 3)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:00:51.684136Z",
     "start_time": "2017-11-06T22:00:51.679996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_back = x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:00:51.691446Z",
     "start_time": "2017-11-06T22:00:51.687266Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bookDF = pd.DataFrame(x_back, columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:00:51.699340Z",
     "start_time": "2017-11-06T22:00:51.694857Z"
    }
   },
   "outputs": [],
   "source": [
    "# bookDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T23:11:53.799029Z",
     "start_time": "2017-11-06T23:11:45.269203Z"
    }
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(stop_words=stoplist,use_idf=True,min_df=.01,max_df=.2)\n",
    "x2 = tf.fit_transform(books)\n",
    "tf_feature_names = tf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T23:11:53.807778Z",
     "start_time": "2017-11-06T23:11:53.801171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748650, 80)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-06T22:00:44.790Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist = 1 - cosine_similarity(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-06T22:00:45.583Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_clusters = 5\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(x2)\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle Kmeans Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-06T22:00:46.423Z"
    }
   },
   "outputs": [],
   "source": [
    "# joblib.dump(km, 'doc_cluster.pkl')\n",
    "# km = joblib.load('doc_cluster.pkl')\n",
    "# clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T21:21:31.978018Z",
     "start_time": "2017-11-04T21:21:31.973811Z"
    }
   },
   "source": [
    "#### With Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T23:10:36.099120Z",
     "start_time": "2017-11-06T23:08:16.700858Z"
    }
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=20, init='random')\n",
    "fit = nmf.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T23:10:36.119703Z",
     "start_time": "2017-11-06T23:10:36.101582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "said one like\n",
      "Topic 1:\n",
      "one said like\n",
      "Topic 2:\n",
      "one said like\n",
      "Topic 3:\n",
      "one like said\n",
      "Topic 4:\n",
      "one said like\n",
      "Topic 5:\n",
      "like said one\n",
      "Topic 6:\n",
      "said one like\n",
      "Topic 7:\n",
      "like said one\n",
      "Topic 8:\n",
      "said one like\n",
      "Topic 9:\n",
      "said one like\n",
      "Topic 10:\n",
      "said one like\n",
      "Topic 11:\n",
      "said one like\n",
      "Topic 12:\n",
      "like said one\n",
      "Topic 13:\n",
      "one said like\n",
      "Topic 14:\n",
      "like said one\n",
      "Topic 15:\n",
      "said like one\n",
      "Topic 16:\n",
      "one said like\n",
      "Topic 17:\n",
      "one said like\n",
      "Topic 18:\n",
      "said one like\n",
      "Topic 19:\n",
      "said one like\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf,cv_feature_names,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T23:10:40.600010Z",
     "start_time": "2017-11-06T23:10:36.122093Z"
    }
   },
   "outputs": [],
   "source": [
    "nmf2 = NMF(n_components=20, init='random').fit(x2)\n",
    "fit2 = nmf2.transform(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T23:10:40.606051Z",
     "start_time": "2017-11-06T23:10:40.602737Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# no_top_words = 5\n",
    "# no_top_documents = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T23:10:40.630662Z",
     "start_time": "2017-11-06T23:10:40.609275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "like one said\n",
      "Topic 1:\n",
      "one said like\n",
      "Topic 2:\n",
      "said one like\n",
      "Topic 3:\n",
      "said one like\n",
      "Topic 4:\n",
      "one like said\n",
      "Topic 5:\n",
      "like said one\n",
      "Topic 6:\n",
      "said one like\n",
      "Topic 7:\n",
      "like said one\n",
      "Topic 8:\n",
      "like said one\n",
      "Topic 9:\n",
      "said one like\n",
      "Topic 10:\n",
      "one said like\n",
      "Topic 11:\n",
      "said one like\n",
      "Topic 12:\n",
      "said one like\n",
      "Topic 13:\n",
      "said like one\n",
      "Topic 14:\n",
      "like said one\n",
      "Topic 15:\n",
      "one said like\n",
      "Topic 16:\n",
      "like said one\n",
      "Topic 17:\n",
      "one like said\n",
      "Topic 18:\n",
      "one said like\n",
      "Topic 19:\n",
      "one said like\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf2,tf_feature_names,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T21:25:35.299501Z",
     "start_time": "2017-11-04T21:25:35.296533Z"
    }
   },
   "source": [
    "#### With Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-06T22:00:52.875Z"
    }
   },
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(stop_words=stoplist)\n",
    "x3 = cv2.fit_transform(books)\n",
    "cv2_feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-06T22:50:19.058595Z",
     "start_time": "2017-11-06T22:50:19.043526Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-402c5828c327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'online'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x3' is not defined"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=20, max_iter=5, learning_method='online', learning_offset=50.,random_state=0).fit(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-11-06T22:00:53.419Z"
    }
   },
   "outputs": [],
   "source": [
    "display_topics(lda,cv2_feature_names,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T21:45:59.353350Z",
     "start_time": "2017-11-02T21:40:37.735808Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-02 17:40:37,750 : INFO : using symmetric alpha at 0.1\n",
      "2017-11-02 17:40:37,751 : INFO : using symmetric eta at 2.13193251154e-06\n",
      "2017-11-02 17:40:37,826 : INFO : using serial LDA version on this node\n",
      "2017-11-02 17:40:58,603 : INFO : running online (multi-pass) LDA training, 10 topics, 10 passes over the supplied corpus of 7 documents, updating model once every 7 documents, evaluating perplexity every 7 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2017-11-02 17:41:47,044 : INFO : -17.591 per-word bound, 197481.1 perplexity estimate based on a held-out corpus of 7 documents with 1304555 words\n",
      "2017-11-02 17:41:47,046 : INFO : PROGRESS: pass 0, at document #7/7\n",
      "2017-11-02 17:41:48,766 : INFO : topic #7 (0.100): 0.005*\"said\" + 0.005*\"roland\" + 0.004*\"eddie\" + 0.003*\"like\" + 0.003*\"jake\" + 0.003*\"one\" + 0.003*\"would\" + 0.002*\"back\" + 0.002*\"susannah\" + 0.002*\"could\"\n",
      "2017-11-02 17:41:48,772 : INFO : topic #1 (0.100): 0.006*\"said\" + 0.004*\"roland\" + 0.004*\"one\" + 0.004*\"eddie\" + 0.003*\"would\" + 0.003*\"like\" + 0.002*\"jake\" + 0.002*\"could\" + 0.002*\"back\" + 0.002*\"susannah\"\n",
      "2017-11-02 17:41:48,776 : INFO : topic #5 (0.100): 0.006*\"roland\" + 0.004*\"one\" + 0.004*\"said\" + 0.003*\"eddie\" + 0.003*\"jake\" + 0.002*\"would\" + 0.002*\"back\" + 0.002*\"time\" + 0.002*\"like\" + 0.002*\"could\"\n",
      "2017-11-02 17:41:48,781 : INFO : topic #2 (0.100): 0.006*\"roland\" + 0.005*\"one\" + 0.004*\"eddie\" + 0.004*\"said\" + 0.003*\"like\" + 0.002*\"jake\" + 0.002*\"back\" + 0.002*\"would\" + 0.002*\"susannah\" + 0.002*\"time\"\n",
      "2017-11-02 17:41:48,786 : INFO : topic #3 (0.100): 0.003*\"said\" + 0.003*\"eddie\" + 0.003*\"one\" + 0.003*\"like\" + 0.003*\"roland\" + 0.003*\"would\" + 0.003*\"jake\" + 0.002*\"back\" + 0.002*\"susannah\" + 0.002*\"could\"\n",
      "2017-11-02 17:41:48,803 : INFO : topic diff=3.357278, rho=1.000000\n",
      "2017-11-02 17:42:09,432 : INFO : -13.317 per-word bound, 10205.0 perplexity estimate based on a held-out corpus of 7 documents with 1304555 words\n",
      "2017-11-02 17:42:09,433 : INFO : PROGRESS: pass 1, at document #7/7\n",
      "2017-11-02 17:42:11,406 : INFO : topic #1 (0.100): 0.005*\"said\" + 0.004*\"roland\" + 0.003*\"one\" + 0.003*\"would\" + 0.003*\"like\" + 0.003*\"eddie\" + 0.002*\"back\" + 0.002*\"could\" + 0.002*\"jake\" + 0.002*\"looked\"\n",
      "2017-11-02 17:42:11,412 : INFO : topic #5 (0.100): 0.006*\"roland\" + 0.005*\"one\" + 0.004*\"said\" + 0.004*\"eddie\" + 0.003*\"jake\" + 0.003*\"would\" + 0.003*\"like\" + 0.003*\"could\" + 0.002*\"back\" + 0.002*\"time\"\n",
      "2017-11-02 17:42:11,418 : INFO : topic #4 (0.100): 0.003*\"roland\" + 0.003*\"said\" + 0.003*\"eddie\" + 0.002*\"one\" + 0.002*\"would\" + 0.002*\"could\" + 0.002*\"like\" + 0.002*\"know\" + 0.001*\"jake\" + 0.001*\"gunslinger\"\n",
      "2017-11-02 17:42:11,422 : INFO : topic #3 (0.100): 0.003*\"said\" + 0.002*\"eddie\" + 0.002*\"one\" + 0.002*\"like\" + 0.002*\"roland\" + 0.002*\"would\" + 0.002*\"jake\" + 0.002*\"back\" + 0.001*\"susannah\" + 0.001*\"could\"\n",
      "2017-11-02 17:42:11,427 : INFO : topic #0 (0.100): 0.004*\"said\" + 0.003*\"gunslinger\" + 0.003*\"one\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"roland\" + 0.002*\"man\" + 0.002*\"jake\" + 0.002*\"boy\" + 0.002*\"would\"\n",
      "2017-11-02 17:42:11,442 : INFO : topic diff=1.742990, rho=0.577350\n",
      "2017-11-02 17:42:34,317 : INFO : -12.175 per-word bound, 4625.2 perplexity estimate based on a held-out corpus of 7 documents with 1304555 words\n",
      "2017-11-02 17:42:34,319 : INFO : PROGRESS: pass 2, at document #7/7\n",
      "2017-11-02 17:42:36,180 : INFO : topic #6 (0.100): 0.002*\"roland\" + 0.001*\"one\" + 0.001*\"would\" + 0.001*\"like\" + 0.001*\"said\" + 0.001*\"eddie\" + 0.001*\"thought\" + 0.001*\"jake\" + 0.001*\"time\" + 0.001*\"could\"\n",
      "2017-11-02 17:42:36,186 : INFO : topic #3 (0.100): 0.002*\"said\" + 0.002*\"eddie\" + 0.002*\"one\" + 0.001*\"like\" + 0.001*\"roland\" + 0.001*\"would\" + 0.001*\"jake\" + 0.001*\"back\" + 0.001*\"susannah\" + 0.001*\"could\"\n",
      "2017-11-02 17:42:36,191 : INFO : topic #5 (0.100): 0.006*\"roland\" + 0.005*\"said\" + 0.005*\"one\" + 0.005*\"eddie\" + 0.003*\"jake\" + 0.003*\"would\" + 0.003*\"like\" + 0.003*\"could\" + 0.003*\"back\" + 0.002*\"susannah\"\n",
      "2017-11-02 17:42:36,196 : INFO : topic #7 (0.100): 0.004*\"said\" + 0.004*\"roland\" + 0.002*\"would\" + 0.002*\"eddie\" + 0.002*\"one\" + 0.002*\"like\" + 0.002*\"jake\" + 0.002*\"susannah\" + 0.002*\"back\" + 0.001*\"could\"\n",
      "2017-11-02 17:42:36,202 : INFO : topic #0 (0.100): 0.004*\"gunslinger\" + 0.004*\"said\" + 0.002*\"one\" + 0.002*\"man\" + 0.002*\"boy\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"would\" + 0.002*\"jake\" + 0.002*\"roland\"\n",
      "2017-11-02 17:42:36,222 : INFO : topic diff=1.024486, rho=0.500000\n",
      "2017-11-02 17:42:56,616 : INFO : -11.817 per-word bound, 3607.3 perplexity estimate based on a held-out corpus of 7 documents with 1304555 words\n",
      "2017-11-02 17:42:56,617 : INFO : PROGRESS: pass 3, at document #7/7\n",
      "2017-11-02 17:43:01,297 : INFO : topic #3 (0.100): 0.001*\"said\" + 0.001*\"eddie\" + 0.001*\"one\" + 0.001*\"like\" + 0.001*\"roland\" + 0.001*\"would\" + 0.001*\"jake\" + 0.001*\"back\" + 0.001*\"susannah\" + 0.001*\"could\"\n",
      "2017-11-02 17:43:01,303 : INFO : topic #0 (0.100): 0.005*\"gunslinger\" + 0.003*\"said\" + 0.003*\"boy\" + 0.002*\"man\" + 0.002*\"one\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"would\" + 0.002*\"jake\" + 0.001*\"black\"\n",
      "2017-11-02 17:43:01,308 : INFO : topic #2 (0.100): 0.005*\"said\" + 0.004*\"eddie\" + 0.004*\"roland\" + 0.004*\"one\" + 0.003*\"susannah\" + 0.002*\"like\" + 0.002*\"mia\" + 0.002*\"jake\" + 0.002*\"would\" + 0.002*\"back\"\n",
      "2017-11-02 17:43:01,313 : INFO : topic #9 (0.100): 0.003*\"eddie\" + 0.002*\"said\" + 0.002*\"roland\" + 0.002*\"one\" + 0.002*\"gunslinger\" + 0.001*\"would\" + 0.001*\"like\" + 0.001*\"man\" + 0.001*\"back\" + 0.001*\"thought\"\n",
      "2017-11-02 17:43:01,317 : INFO : topic #8 (0.100): 0.006*\"said\" + 0.006*\"roland\" + 0.004*\"one\" + 0.004*\"eddie\" + 0.003*\"like\" + 0.003*\"jake\" + 0.003*\"would\" + 0.003*\"back\" + 0.002*\"could\" + 0.002*\"looked\"\n",
      "2017-11-02 17:43:01,333 : INFO : topic diff=0.634346, rho=0.447214\n",
      "2017-11-02 17:43:23,162 : INFO : -11.680 per-word bound, 3282.0 perplexity estimate based on a held-out corpus of 7 documents with 1304555 words\n",
      "2017-11-02 17:43:23,163 : INFO : PROGRESS: pass 4, at document #7/7\n",
      "2017-11-02 17:43:30,222 : INFO : topic #4 (0.100): 0.001*\"roland\" + 0.001*\"said\" + 0.001*\"eddie\" + 0.001*\"one\" + 0.001*\"would\" + 0.001*\"could\" + 0.001*\"like\" + 0.000*\"know\" + 0.000*\"jake\" + 0.000*\"gunslinger\"\n",
      "2017-11-02 17:43:30,227 : INFO : topic #2 (0.100): 0.005*\"said\" + 0.004*\"eddie\" + 0.004*\"roland\" + 0.004*\"one\" + 0.003*\"susannah\" + 0.003*\"mia\" + 0.002*\"like\" + 0.002*\"jake\" + 0.002*\"would\" + 0.002*\"back\"\n",
      "2017-11-02 17:43:30,232 : INFO : topic #9 (0.100): 0.003*\"eddie\" + 0.001*\"gunslinger\" + 0.001*\"said\" + 0.001*\"roland\" + 0.001*\"one\" + 0.001*\"would\" + 0.001*\"like\" + 0.001*\"man\" + 0.001*\"back\" + 0.001*\"balazar\"\n",
      "2017-11-02 17:43:30,238 : INFO : topic #0 (0.100): 0.005*\"gunslinger\" + 0.003*\"said\" + 0.003*\"boy\" + 0.002*\"man\" + 0.002*\"one\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"would\" + 0.002*\"black\" + 0.002*\"jake\"\n",
      "2017-11-02 17:43:30,242 : INFO : topic #1 (0.100): 0.002*\"said\" + 0.002*\"roland\" + 0.001*\"one\" + 0.001*\"would\" + 0.001*\"like\" + 0.001*\"eddie\" + 0.001*\"back\" + 0.001*\"could\" + 0.001*\"looked\" + 0.001*\"jake\"\n",
      "2017-11-02 17:43:30,258 : INFO : topic diff=0.406852, rho=0.408248\n",
      "2017-11-02 17:43:53,934 : INFO : -11.615 per-word bound, 3135.8 perplexity estimate based on a held-out corpus of 7 documents with 1304555 words\n",
      "2017-11-02 17:43:53,935 : INFO : PROGRESS: pass 5, at document #7/7\n",
      "2017-11-02 17:44:00,612 : INFO : topic #0 (0.100): 0.005*\"gunslinger\" + 0.003*\"said\" + 0.003*\"boy\" + 0.002*\"man\" + 0.002*\"one\" + 0.002*\"like\" + 0.002*\"would\" + 0.002*\"back\" + 0.002*\"black\" + 0.002*\"jake\"\n",
      "2017-11-02 17:44:00,617 : INFO : topic #5 (0.100): 0.006*\"roland\" + 0.005*\"said\" + 0.005*\"eddie\" + 0.005*\"one\" + 0.004*\"jake\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"could\" + 0.003*\"back\" + 0.002*\"susannah\"\n",
      "2017-11-02 17:44:00,622 : INFO : topic #8 (0.100): 0.006*\"said\" + 0.006*\"roland\" + 0.004*\"one\" + 0.004*\"eddie\" + 0.003*\"like\" + 0.003*\"jake\" + 0.003*\"would\" + 0.003*\"back\" + 0.002*\"could\" + 0.002*\"time\"\n",
      "2017-11-02 17:44:00,627 : INFO : topic #3 (0.100): 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"roland\" + 0.000*\"would\" + 0.000*\"jake\" + 0.000*\"back\" + 0.000*\"susannah\" + 0.000*\"could\"\n",
      "2017-11-02 17:44:00,631 : INFO : topic #2 (0.100): 0.005*\"said\" + 0.004*\"eddie\" + 0.004*\"roland\" + 0.004*\"one\" + 0.003*\"susannah\" + 0.003*\"mia\" + 0.002*\"like\" + 0.002*\"jake\" + 0.002*\"would\" + 0.002*\"back\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-02 17:44:00,647 : INFO : topic diff=0.267182, rho=0.377964\n",
      "2017-11-02 17:44:23,423 : INFO : -11.579 per-word bound, 3060.3 perplexity estimate based on a held-out corpus of 7 documents with 1304555 words\n",
      "2017-11-02 17:44:23,424 : INFO : PROGRESS: pass 6, at document #7/7\n",
      "2017-11-02 17:44:30,039 : INFO : topic #7 (0.100): 0.001*\"said\" + 0.001*\"roland\" + 0.001*\"would\" + 0.001*\"eddie\" + 0.001*\"one\" + 0.001*\"like\" + 0.001*\"jake\" + 0.001*\"susannah\" + 0.000*\"back\" + 0.000*\"could\"\n",
      "2017-11-02 17:44:30,044 : INFO : topic #3 (0.100): 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"roland\" + 0.000*\"would\" + 0.000*\"jake\" + 0.000*\"back\" + 0.000*\"susannah\" + 0.000*\"could\"\n",
      "2017-11-02 17:44:30,048 : INFO : topic #4 (0.100): 0.000*\"roland\" + 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"could\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"jake\" + 0.000*\"gunslinger\"\n",
      "2017-11-02 17:44:30,052 : INFO : topic #8 (0.100): 0.006*\"said\" + 0.006*\"roland\" + 0.004*\"one\" + 0.004*\"eddie\" + 0.003*\"like\" + 0.003*\"jake\" + 0.003*\"would\" + 0.003*\"back\" + 0.002*\"could\" + 0.002*\"time\"\n",
      "2017-11-02 17:44:30,057 : INFO : topic #6 (0.100): 0.000*\"roland\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"like\" + 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"thought\" + 0.000*\"jake\" + 0.000*\"time\" + 0.000*\"could\"\n",
      "2017-11-02 17:44:30,072 : INFO : topic diff=0.179337, rho=0.353553\n",
      "2017-11-02 17:44:52,891 : INFO : -11.559 per-word bound, 3017.7 perplexity estimate based on a held-out corpus of 7 documents with 1304555 words\n",
      "2017-11-02 17:44:52,893 : INFO : PROGRESS: pass 7, at document #7/7\n",
      "2017-11-02 17:44:59,560 : INFO : topic #5 (0.100): 0.006*\"roland\" + 0.005*\"said\" + 0.005*\"eddie\" + 0.005*\"one\" + 0.004*\"jake\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"could\" + 0.003*\"back\" + 0.002*\"susannah\"\n",
      "2017-11-02 17:44:59,566 : INFO : topic #3 (0.100): 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"roland\" + 0.000*\"would\" + 0.000*\"jake\" + 0.000*\"back\" + 0.000*\"susannah\" + 0.000*\"could\"\n",
      "2017-11-02 17:44:59,572 : INFO : topic #6 (0.100): 0.000*\"roland\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"like\" + 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"thought\" + 0.000*\"jake\" + 0.000*\"time\" + 0.000*\"could\"\n",
      "2017-11-02 17:44:59,578 : INFO : topic #1 (0.100): 0.001*\"said\" + 0.001*\"roland\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"like\" + 0.000*\"eddie\" + 0.000*\"back\" + 0.000*\"could\" + 0.000*\"looked\" + 0.000*\"jake\"\n",
      "2017-11-02 17:44:59,582 : INFO : topic #8 (0.100): 0.006*\"said\" + 0.006*\"roland\" + 0.004*\"one\" + 0.004*\"eddie\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"jake\" + 0.003*\"back\" + 0.002*\"could\" + 0.002*\"time\"\n",
      "2017-11-02 17:44:59,597 : INFO : topic diff=0.122909, rho=0.333333\n",
      "2017-11-02 17:45:23,074 : INFO : -11.547 per-word bound, 2991.9 perplexity estimate based on a held-out corpus of 7 documents with 1304555 words\n",
      "2017-11-02 17:45:23,075 : INFO : PROGRESS: pass 8, at document #7/7\n",
      "2017-11-02 17:45:29,696 : INFO : topic #8 (0.100): 0.006*\"said\" + 0.006*\"roland\" + 0.004*\"one\" + 0.004*\"eddie\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"jake\" + 0.003*\"back\" + 0.002*\"could\" + 0.002*\"time\"\n",
      "2017-11-02 17:45:29,701 : INFO : topic #4 (0.100): 0.000*\"roland\" + 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"could\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"jake\" + 0.000*\"gunslinger\"\n",
      "2017-11-02 17:45:29,706 : INFO : topic #5 (0.100): 0.006*\"roland\" + 0.005*\"said\" + 0.005*\"eddie\" + 0.005*\"one\" + 0.004*\"jake\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"could\" + 0.003*\"back\" + 0.002*\"susannah\"\n",
      "2017-11-02 17:45:29,710 : INFO : topic #1 (0.100): 0.001*\"said\" + 0.000*\"roland\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"like\" + 0.000*\"eddie\" + 0.000*\"back\" + 0.000*\"could\" + 0.000*\"looked\" + 0.000*\"jake\"\n",
      "2017-11-02 17:45:29,715 : INFO : topic #2 (0.100): 0.005*\"said\" + 0.004*\"eddie\" + 0.004*\"roland\" + 0.003*\"one\" + 0.003*\"susannah\" + 0.003*\"mia\" + 0.002*\"like\" + 0.002*\"would\" + 0.002*\"jake\" + 0.002*\"back\"\n",
      "2017-11-02 17:45:29,732 : INFO : topic diff=0.085938, rho=0.316228\n",
      "2017-11-02 17:45:52,696 : INFO : -11.539 per-word bound, 2975.4 perplexity estimate based on a held-out corpus of 7 documents with 1304555 words\n",
      "2017-11-02 17:45:52,697 : INFO : PROGRESS: pass 9, at document #7/7\n",
      "2017-11-02 17:45:59,256 : INFO : topic #8 (0.100): 0.006*\"said\" + 0.006*\"roland\" + 0.004*\"one\" + 0.004*\"eddie\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"jake\" + 0.003*\"back\" + 0.002*\"could\" + 0.002*\"time\"\n",
      "2017-11-02 17:45:59,261 : INFO : topic #2 (0.100): 0.005*\"said\" + 0.004*\"eddie\" + 0.004*\"roland\" + 0.003*\"one\" + 0.003*\"susannah\" + 0.003*\"mia\" + 0.002*\"like\" + 0.002*\"would\" + 0.002*\"jake\" + 0.002*\"back\"\n",
      "2017-11-02 17:45:59,266 : INFO : topic #5 (0.100): 0.006*\"roland\" + 0.005*\"said\" + 0.005*\"eddie\" + 0.005*\"one\" + 0.004*\"jake\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"could\" + 0.003*\"back\" + 0.002*\"susannah\"\n",
      "2017-11-02 17:45:59,270 : INFO : topic #4 (0.100): 0.000*\"roland\" + 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"could\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"jake\" + 0.000*\"gunslinger\"\n",
      "2017-11-02 17:45:59,275 : INFO : topic #3 (0.100): 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"roland\" + 0.000*\"would\" + 0.000*\"jake\" + 0.000*\"back\" + 0.000*\"susannah\" + 0.000*\"could\"\n",
      "2017-11-02 17:45:59,291 : INFO : topic diff=0.061250, rho=0.301511\n"
     ]
    }
   ],
   "source": [
    "# lda = models.LdaModel(corpus=corp, num_topics=10, id2word=id2word, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T21:45:59.423758Z",
     "start_time": "2017-11-02T21:45:59.356125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-02 17:45:59,374 : INFO : topic #0 (0.100): 0.005*\"gunslinger\" + 0.003*\"said\" + 0.003*\"boy\" + 0.003*\"man\" + 0.002*\"one\" + 0.002*\"like\" + 0.002*\"would\" + 0.002*\"back\" + 0.002*\"black\" + 0.001*\"jake\"\n",
      "2017-11-02 17:45:59,380 : INFO : topic #1 (0.100): 0.000*\"said\" + 0.000*\"roland\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"like\" + 0.000*\"eddie\" + 0.000*\"back\" + 0.000*\"could\" + 0.000*\"looked\" + 0.000*\"jake\"\n",
      "2017-11-02 17:45:59,384 : INFO : topic #2 (0.100): 0.005*\"said\" + 0.004*\"eddie\" + 0.004*\"roland\" + 0.003*\"one\" + 0.003*\"susannah\" + 0.003*\"mia\" + 0.002*\"like\" + 0.002*\"would\" + 0.002*\"jake\" + 0.002*\"back\"\n",
      "2017-11-02 17:45:59,388 : INFO : topic #3 (0.100): 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"roland\" + 0.000*\"would\" + 0.000*\"jake\" + 0.000*\"back\" + 0.000*\"susannah\" + 0.000*\"could\"\n",
      "2017-11-02 17:45:59,392 : INFO : topic #4 (0.100): 0.000*\"roland\" + 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"could\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"jake\" + 0.000*\"gunslinger\"\n",
      "2017-11-02 17:45:59,396 : INFO : topic #5 (0.100): 0.006*\"roland\" + 0.005*\"said\" + 0.005*\"eddie\" + 0.005*\"one\" + 0.004*\"jake\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"could\" + 0.003*\"back\" + 0.002*\"susannah\"\n",
      "2017-11-02 17:45:59,399 : INFO : topic #6 (0.100): 0.000*\"roland\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"like\" + 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"thought\" + 0.000*\"jake\" + 0.000*\"time\" + 0.000*\"could\"\n",
      "2017-11-02 17:45:59,404 : INFO : topic #7 (0.100): 0.000*\"said\" + 0.000*\"roland\" + 0.000*\"would\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"jake\" + 0.000*\"susannah\" + 0.000*\"back\" + 0.000*\"could\"\n",
      "2017-11-02 17:45:59,408 : INFO : topic #8 (0.100): 0.006*\"said\" + 0.006*\"roland\" + 0.004*\"one\" + 0.004*\"eddie\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"jake\" + 0.003*\"back\" + 0.002*\"could\" + 0.002*\"time\"\n",
      "2017-11-02 17:45:59,414 : INFO : topic #9 (0.100): 0.002*\"eddie\" + 0.001*\"balazar\" + 0.001*\"gunslinger\" + 0.001*\"jack\" + 0.001*\"andolini\" + 0.001*\"henry\" + 0.001*\"odetta\" + 0.001*\"mort\" + 0.001*\"delevan\" + 0.001*\"customs\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"gunslinger\" + 0.003*\"said\" + 0.003*\"boy\" + 0.003*\"man\" + 0.002*\"one\" + 0.002*\"like\" + 0.002*\"would\" + 0.002*\"back\" + 0.002*\"black\" + 0.001*\"jake\"'),\n",
       " (1,\n",
       "  '0.000*\"said\" + 0.000*\"roland\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"like\" + 0.000*\"eddie\" + 0.000*\"back\" + 0.000*\"could\" + 0.000*\"looked\" + 0.000*\"jake\"'),\n",
       " (2,\n",
       "  '0.005*\"said\" + 0.004*\"eddie\" + 0.004*\"roland\" + 0.003*\"one\" + 0.003*\"susannah\" + 0.003*\"mia\" + 0.002*\"like\" + 0.002*\"would\" + 0.002*\"jake\" + 0.002*\"back\"'),\n",
       " (3,\n",
       "  '0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"roland\" + 0.000*\"would\" + 0.000*\"jake\" + 0.000*\"back\" + 0.000*\"susannah\" + 0.000*\"could\"'),\n",
       " (4,\n",
       "  '0.000*\"roland\" + 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"could\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"jake\" + 0.000*\"gunslinger\"'),\n",
       " (5,\n",
       "  '0.006*\"roland\" + 0.005*\"said\" + 0.005*\"eddie\" + 0.005*\"one\" + 0.004*\"jake\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"could\" + 0.003*\"back\" + 0.002*\"susannah\"'),\n",
       " (6,\n",
       "  '0.000*\"roland\" + 0.000*\"one\" + 0.000*\"would\" + 0.000*\"like\" + 0.000*\"said\" + 0.000*\"eddie\" + 0.000*\"thought\" + 0.000*\"jake\" + 0.000*\"time\" + 0.000*\"could\"'),\n",
       " (7,\n",
       "  '0.000*\"said\" + 0.000*\"roland\" + 0.000*\"would\" + 0.000*\"eddie\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"jake\" + 0.000*\"susannah\" + 0.000*\"back\" + 0.000*\"could\"'),\n",
       " (8,\n",
       "  '0.006*\"said\" + 0.006*\"roland\" + 0.004*\"one\" + 0.004*\"eddie\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"jake\" + 0.003*\"back\" + 0.002*\"could\" + 0.002*\"time\"'),\n",
       " (9,\n",
       "  '0.002*\"eddie\" + 0.001*\"balazar\" + 0.001*\"gunslinger\" + 0.001*\"jack\" + 0.001*\"andolini\" + 0.001*\"henry\" + 0.001*\"odetta\" + 0.001*\"mort\" + 0.001*\"delevan\" + 0.001*\"customs\"')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T21:45:59.985675Z",
     "start_time": "2017-11-02T21:45:59.427197Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Transform the docs from the word space to the topic space (like \"transform\" in sklearn)\n",
    "# lda_corpus = lda[corp]\n",
    "# lda_docs = [doc for doc in lda_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T21:45:59.995215Z",
     "start_time": "2017-11-02T21:45:59.988441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 0.99999309930389702)],\n",
       " [(8, 0.99999659776824634)],\n",
       " [(5, 0.99999504978884213)],\n",
       " [(0, 0.9999867660232642)],\n",
       " [(5, 0.80863682693916183), (9, 0.19135691336193036)],\n",
       " [(5, 0.9999967903172694)],\n",
       " [(8, 0.99999642158611446)]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda_docs[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T21:46:00.002476Z",
     "start_time": "2017-11-02T21:45:59.997923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LdaModel.log_perplexity of <gensim.models.ldamodel.LdaModel object at 0x1a29cd38d0>>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda.log_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T21:49:53.212960Z",
     "start_time": "2017-11-02T21:49:14.280746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "(2680972, 67)\n"
     ]
    }
   ],
   "source": [
    "# corp2,id2word2 = book_cv(all_text,stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T23:37:39.919136Z",
     "start_time": "2017-11-02T22:59:21.348750Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-02 18:59:21,423 : INFO : using symmetric alpha at 0.1\n",
      "2017-11-02 18:59:21,425 : INFO : using symmetric eta at 3.72999046614e-07\n",
      "2017-11-02 18:59:21,803 : INFO : using serial LDA version on this node\n",
      "2017-11-02 19:01:16,931 : INFO : running online (multi-pass) LDA training, 10 topics, 10 passes over the supplied corpus of 67 documents, updating model once every 67 documents, evaluating perplexity every 67 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2017-11-02 19:06:27,225 : INFO : -18.245 per-word bound, 310611.4 perplexity estimate based on a held-out corpus of 67 documents with 10236337 words\n",
      "2017-11-02 19:06:27,227 : INFO : PROGRESS: pass 0, at document #67/67\n",
      "2017-11-02 19:06:41,693 : INFO : topic #0 (0.100): 0.005*\"said\" + 0.003*\"would\" + 0.003*\"like\" + 0.003*\"one\" + 0.002*\"time\" + 0.002*\"could\" + 0.002*\"back\" + 0.002*\"looked\" + 0.002*\"go\" + 0.002*\"way\"\n",
      "2017-11-02 19:06:41,733 : INFO : topic #5 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.002*\"would\" + 0.002*\"time\" + 0.002*\"could\" + 0.002*\"right\" + 0.002*\"see\" + 0.002*\"little\"\n",
      "2017-11-02 19:06:41,787 : INFO : topic #9 (0.100): 0.003*\"said\" + 0.003*\"one\" + 0.003*\"like\" + 0.002*\"back\" + 0.002*\"could\" + 0.002*\"would\" + 0.002*\"know\" + 0.002*\"thought\" + 0.002*\"right\" + 0.001*\"looked\"\n",
      "2017-11-02 19:06:41,840 : INFO : topic #8 (0.100): 0.005*\"said\" + 0.004*\"like\" + 0.003*\"one\" + 0.003*\"back\" + 0.003*\"would\" + 0.002*\"could\" + 0.002*\"little\" + 0.002*\"looked\" + 0.002*\"time\" + 0.002*\"got\"\n",
      "2017-11-02 19:06:41,893 : INFO : topic #4 (0.100): 0.005*\"said\" + 0.004*\"like\" + 0.003*\"one\" + 0.003*\"would\" + 0.002*\"back\" + 0.002*\"could\" + 0.002*\"little\" + 0.001*\"looked\" + 0.001*\"get\" + 0.001*\"even\"\n",
      "2017-11-02 19:06:42,029 : INFO : topic diff=3.440557, rho=1.000000\n",
      "2017-11-02 19:09:26,493 : INFO : -13.682 per-word bound, 13141.3 perplexity estimate based on a held-out corpus of 67 documents with 10236337 words\n",
      "2017-11-02 19:09:26,494 : INFO : PROGRESS: pass 1, at document #67/67\n",
      "2017-11-02 19:09:42,549 : INFO : topic #5 (0.100): 0.004*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.002*\"would\" + 0.002*\"could\" + 0.002*\"time\" + 0.002*\"right\" + 0.002*\"know\" + 0.002*\"little\"\n",
      "2017-11-02 19:09:42,596 : INFO : topic #7 (0.100): 0.003*\"said\" + 0.003*\"one\" + 0.002*\"back\" + 0.002*\"would\" + 0.001*\"thought\" + 0.001*\"could\" + 0.001*\"like\" + 0.001*\"know\" + 0.001*\"right\" + 0.001*\"see\"\n",
      "2017-11-02 19:09:42,656 : INFO : topic #9 (0.100): 0.002*\"said\" + 0.002*\"one\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"could\" + 0.002*\"would\" + 0.001*\"know\" + 0.001*\"thought\" + 0.001*\"right\" + 0.001*\"looked\"\n",
      "2017-11-02 19:09:42,692 : INFO : topic #6 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.003*\"back\" + 0.003*\"like\" + 0.003*\"would\" + 0.002*\"could\" + 0.002*\"time\" + 0.002*\"thought\" + 0.002*\"little\" + 0.002*\"know\"\n",
      "2017-11-02 19:09:42,741 : INFO : topic #4 (0.100): 0.004*\"said\" + 0.004*\"like\" + 0.003*\"one\" + 0.002*\"would\" + 0.002*\"back\" + 0.002*\"could\" + 0.001*\"little\" + 0.001*\"looked\" + 0.001*\"get\" + 0.001*\"time\"\n",
      "2017-11-02 19:09:42,865 : INFO : topic diff=1.682576, rho=0.577350\n",
      "2017-11-02 19:12:26,366 : INFO : -12.749 per-word bound, 6884.5 perplexity estimate based on a held-out corpus of 67 documents with 10236337 words\n",
      "2017-11-02 19:12:26,368 : INFO : PROGRESS: pass 2, at document #67/67\n",
      "2017-11-02 19:12:42,705 : INFO : topic #0 (0.100): 0.004*\"said\" + 0.003*\"one\" + 0.003*\"roland\" + 0.003*\"would\" + 0.003*\"like\" + 0.002*\"back\" + 0.002*\"could\" + 0.002*\"time\" + 0.002*\"looked\" + 0.002*\"thought\"\n",
      "2017-11-02 19:12:42,762 : INFO : topic #5 (0.100): 0.004*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.002*\"would\" + 0.002*\"could\" + 0.002*\"time\" + 0.002*\"right\" + 0.002*\"know\" + 0.002*\"little\"\n",
      "2017-11-02 19:12:42,819 : INFO : topic #9 (0.100): 0.002*\"said\" + 0.001*\"one\" + 0.001*\"like\" + 0.001*\"back\" + 0.001*\"could\" + 0.001*\"would\" + 0.001*\"know\" + 0.001*\"thought\" + 0.001*\"right\" + 0.001*\"looked\"\n",
      "2017-11-02 19:12:42,864 : INFO : topic #4 (0.100): 0.004*\"said\" + 0.003*\"like\" + 0.002*\"one\" + 0.002*\"would\" + 0.002*\"back\" + 0.002*\"could\" + 0.001*\"danny\" + 0.001*\"little\" + 0.001*\"looked\" + 0.001*\"get\"\n",
      "2017-11-02 19:12:42,897 : INFO : topic #6 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.003*\"would\" + 0.002*\"could\" + 0.002*\"thought\" + 0.002*\"time\" + 0.002*\"know\" + 0.002*\"man\"\n",
      "2017-11-02 19:12:43,033 : INFO : topic diff=1.089075, rho=0.500000\n",
      "2017-11-02 19:15:28,331 : INFO : -12.462 per-word bound, 5642.3 perplexity estimate based on a held-out corpus of 67 documents with 10236337 words\n",
      "2017-11-02 19:15:28,350 : INFO : PROGRESS: pass 3, at document #67/67\n",
      "2017-11-02 19:16:06,296 : INFO : topic #4 (0.100): 0.003*\"said\" + 0.003*\"like\" + 0.002*\"one\" + 0.002*\"would\" + 0.002*\"back\" + 0.002*\"could\" + 0.001*\"danny\" + 0.001*\"jack\" + 0.001*\"time\" + 0.001*\"get\"\n",
      "2017-11-02 19:16:06,340 : INFO : topic #0 (0.100): 0.004*\"said\" + 0.004*\"roland\" + 0.003*\"one\" + 0.003*\"would\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"could\" + 0.002*\"time\" + 0.002*\"looked\" + 0.002*\"eddie\"\n",
      "2017-11-02 19:16:06,397 : INFO : topic #5 (0.100): 0.004*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.002*\"would\" + 0.002*\"could\" + 0.002*\"time\" + 0.002*\"know\" + 0.002*\"right\" + 0.002*\"little\"\n",
      "2017-11-02 19:16:06,452 : INFO : topic #2 (0.100): 0.003*\"said\" + 0.003*\"one\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"would\" + 0.002*\"could\" + 0.001*\"dan\" + 0.001*\"know\" + 0.001*\"time\" + 0.001*\"little\"\n",
      "2017-11-02 19:16:06,510 : INFO : topic #3 (0.100): 0.002*\"said\" + 0.002*\"one\" + 0.001*\"like\" + 0.001*\"back\" + 0.001*\"could\" + 0.001*\"know\" + 0.001*\"would\" + 0.001*\"think\" + 0.001*\"thought\" + 0.001*\"man\"\n",
      "2017-11-02 19:16:06,649 : INFO : topic diff=0.686293, rho=0.447214\n",
      "2017-11-02 19:19:01,556 : INFO : -12.356 per-word bound, 5242.0 perplexity estimate based on a held-out corpus of 67 documents with 10236337 words\n",
      "2017-11-02 19:19:01,558 : INFO : PROGRESS: pass 4, at document #67/67\n",
      "2017-11-02 19:19:46,159 : INFO : topic #7 (0.100): 0.001*\"said\" + 0.001*\"one\" + 0.001*\"back\" + 0.001*\"would\" + 0.000*\"thought\" + 0.000*\"could\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"right\" + 0.000*\"see\"\n",
      "2017-11-02 19:19:46,203 : INFO : topic #5 (0.100): 0.004*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.002*\"would\" + 0.002*\"could\" + 0.002*\"time\" + 0.002*\"know\" + 0.002*\"right\" + 0.002*\"little\"\n",
      "2017-11-02 19:19:46,258 : INFO : topic #2 (0.100): 0.003*\"said\" + 0.002*\"one\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"dan\" + 0.002*\"would\" + 0.001*\"could\" + 0.001*\"know\" + 0.001*\"abra\" + 0.001*\"time\"\n",
      "2017-11-02 19:19:46,302 : INFO : topic #8 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.004*\"like\" + 0.003*\"back\" + 0.003*\"would\" + 0.003*\"could\" + 0.002*\"time\" + 0.002*\"little\" + 0.002*\"looked\" + 0.002*\"know\"\n",
      "2017-11-02 19:19:46,347 : INFO : topic #4 (0.100): 0.003*\"said\" + 0.002*\"like\" + 0.002*\"one\" + 0.002*\"would\" + 0.002*\"back\" + 0.002*\"danny\" + 0.001*\"could\" + 0.001*\"jack\" + 0.001*\"time\" + 0.001*\"get\"\n",
      "2017-11-02 19:19:46,460 : INFO : topic diff=0.439985, rho=0.408248\n",
      "2017-11-02 19:22:37,314 : INFO : -12.307 per-word bound, 5067.8 perplexity estimate based on a held-out corpus of 67 documents with 10236337 words\n",
      "2017-11-02 19:22:37,316 : INFO : PROGRESS: pass 5, at document #67/67\n",
      "2017-11-02 19:23:19,804 : INFO : topic #2 (0.100): 0.003*\"said\" + 0.002*\"one\" + 0.002*\"like\" + 0.002*\"dan\" + 0.002*\"back\" + 0.001*\"would\" + 0.001*\"could\" + 0.001*\"abra\" + 0.001*\"know\" + 0.001*\"little\"\n",
      "2017-11-02 19:23:19,846 : INFO : topic #4 (0.100): 0.003*\"said\" + 0.002*\"like\" + 0.002*\"one\" + 0.002*\"danny\" + 0.002*\"would\" + 0.002*\"back\" + 0.001*\"could\" + 0.001*\"jack\" + 0.001*\"time\" + 0.001*\"know\"\n",
      "2017-11-02 19:23:19,886 : INFO : topic #7 (0.100): 0.001*\"said\" + 0.001*\"one\" + 0.000*\"back\" + 0.000*\"would\" + 0.000*\"thought\" + 0.000*\"could\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"right\" + 0.000*\"see\"\n",
      "2017-11-02 19:23:19,937 : INFO : topic #3 (0.100): 0.001*\"said\" + 0.001*\"one\" + 0.001*\"wesley\" + 0.001*\"like\" + 0.000*\"back\" + 0.000*\"know\" + 0.000*\"could\" + 0.000*\"would\" + 0.000*\"think\" + 0.000*\"thought\"\n",
      "2017-11-02 19:23:19,979 : INFO : topic #5 (0.100): 0.004*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.002*\"would\" + 0.002*\"could\" + 0.002*\"time\" + 0.002*\"know\" + 0.002*\"little\" + 0.002*\"right\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-02 19:23:20,101 : INFO : topic diff=0.286577, rho=0.377964\n",
      "2017-11-02 19:26:11,274 : INFO : -12.282 per-word bound, 4981.2 perplexity estimate based on a held-out corpus of 67 documents with 10236337 words\n",
      "2017-11-02 19:26:11,276 : INFO : PROGRESS: pass 6, at document #67/67\n",
      "2017-11-02 19:26:53,785 : INFO : topic #9 (0.100): 0.000*\"said\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"back\" + 0.000*\"could\" + 0.000*\"would\" + 0.000*\"know\" + 0.000*\"thought\" + 0.000*\"right\" + 0.000*\"looked\"\n",
      "2017-11-02 19:26:53,833 : INFO : topic #2 (0.100): 0.003*\"said\" + 0.002*\"one\" + 0.002*\"dan\" + 0.002*\"like\" + 0.002*\"back\" + 0.001*\"would\" + 0.001*\"could\" + 0.001*\"abra\" + 0.001*\"know\" + 0.001*\"little\"\n",
      "2017-11-02 19:26:53,871 : INFO : topic #7 (0.100): 0.000*\"said\" + 0.000*\"one\" + 0.000*\"back\" + 0.000*\"would\" + 0.000*\"thought\" + 0.000*\"could\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"right\" + 0.000*\"see\"\n",
      "2017-11-02 19:26:53,916 : INFO : topic #3 (0.100): 0.001*\"said\" + 0.001*\"wesley\" + 0.001*\"one\" + 0.000*\"like\" + 0.000*\"back\" + 0.000*\"kindle\" + 0.000*\"robbie\" + 0.000*\"know\" + 0.000*\"could\" + 0.000*\"would\"\n",
      "2017-11-02 19:26:53,944 : INFO : topic #1 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.003*\"would\" + 0.002*\"could\" + 0.002*\"know\" + 0.002*\"little\" + 0.002*\"looked\" + 0.002*\"time\"\n",
      "2017-11-02 19:26:54,059 : INFO : topic diff=0.189872, rho=0.353553\n",
      "2017-11-02 19:29:47,655 : INFO : -12.269 per-word bound, 4934.5 perplexity estimate based on a held-out corpus of 67 documents with 10236337 words\n",
      "2017-11-02 19:29:47,656 : INFO : PROGRESS: pass 7, at document #67/67\n",
      "2017-11-02 19:30:31,350 : INFO : topic #3 (0.100): 0.001*\"wesley\" + 0.001*\"said\" + 0.000*\"one\" + 0.000*\"kindle\" + 0.000*\"robbie\" + 0.000*\"like\" + 0.000*\"ur\" + 0.000*\"back\" + 0.000*\"know\" + 0.000*\"could\"\n",
      "2017-11-02 19:30:31,393 : INFO : topic #0 (0.100): 0.004*\"roland\" + 0.004*\"said\" + 0.004*\"one\" + 0.003*\"would\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"could\" + 0.002*\"eddie\" + 0.002*\"susannah\" + 0.002*\"jake\"\n",
      "2017-11-02 19:30:31,440 : INFO : topic #2 (0.100): 0.002*\"said\" + 0.002*\"one\" + 0.002*\"dan\" + 0.002*\"like\" + 0.002*\"back\" + 0.001*\"would\" + 0.001*\"abra\" + 0.001*\"could\" + 0.001*\"know\" + 0.001*\"little\"\n",
      "2017-11-02 19:30:31,483 : INFO : topic #4 (0.100): 0.003*\"said\" + 0.002*\"one\" + 0.002*\"like\" + 0.002*\"danny\" + 0.002*\"back\" + 0.002*\"would\" + 0.001*\"jack\" + 0.001*\"could\" + 0.001*\"time\" + 0.001*\"know\"\n",
      "2017-11-02 19:30:31,530 : INFO : topic #8 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.004*\"like\" + 0.003*\"back\" + 0.003*\"would\" + 0.003*\"could\" + 0.002*\"time\" + 0.002*\"little\" + 0.002*\"looked\" + 0.002*\"know\"\n",
      "2017-11-02 19:30:31,654 : INFO : topic diff=0.127954, rho=0.333333\n",
      "2017-11-02 19:33:24,438 : INFO : -12.261 per-word bound, 4907.4 perplexity estimate based on a held-out corpus of 67 documents with 10236337 words\n",
      "2017-11-02 19:33:24,440 : INFO : PROGRESS: pass 8, at document #67/67\n",
      "2017-11-02 19:34:06,793 : INFO : topic #8 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.004*\"like\" + 0.003*\"back\" + 0.003*\"would\" + 0.003*\"could\" + 0.002*\"time\" + 0.002*\"little\" + 0.002*\"looked\" + 0.002*\"know\"\n",
      "2017-11-02 19:34:06,842 : INFO : topic #5 (0.100): 0.004*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.002*\"would\" + 0.002*\"could\" + 0.002*\"time\" + 0.002*\"know\" + 0.002*\"little\" + 0.002*\"right\"\n",
      "2017-11-02 19:34:06,873 : INFO : topic #1 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.003*\"would\" + 0.002*\"could\" + 0.002*\"know\" + 0.002*\"little\" + 0.002*\"looked\" + 0.002*\"time\"\n",
      "2017-11-02 19:34:06,914 : INFO : topic #0 (0.100): 0.004*\"roland\" + 0.004*\"said\" + 0.004*\"one\" + 0.003*\"would\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"eddie\" + 0.002*\"could\" + 0.002*\"susannah\" + 0.002*\"jake\"\n",
      "2017-11-02 19:34:06,961 : INFO : topic #3 (0.100): 0.001*\"wesley\" + 0.000*\"said\" + 0.000*\"kindle\" + 0.000*\"robbie\" + 0.000*\"one\" + 0.000*\"ur\" + 0.000*\"like\" + 0.000*\"ellen\" + 0.000*\"back\" + 0.000*\"know\"\n",
      "2017-11-02 19:34:07,076 : INFO : topic diff=0.087617, rho=0.316228\n",
      "2017-11-02 19:36:57,146 : INFO : -12.256 per-word bound, 4890.9 perplexity estimate based on a held-out corpus of 67 documents with 10236337 words\n",
      "2017-11-02 19:36:57,148 : INFO : PROGRESS: pass 9, at document #67/67\n",
      "2017-11-02 19:37:39,408 : INFO : topic #9 (0.100): 0.000*\"said\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"back\" + 0.000*\"could\" + 0.000*\"would\" + 0.000*\"know\" + 0.000*\"thought\" + 0.000*\"right\" + 0.000*\"looked\"\n",
      "2017-11-02 19:37:39,441 : INFO : topic #6 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"back\" + 0.002*\"could\" + 0.002*\"know\" + 0.002*\"thought\" + 0.002*\"time\" + 0.002*\"man\"\n",
      "2017-11-02 19:37:39,488 : INFO : topic #2 (0.100): 0.002*\"said\" + 0.002*\"dan\" + 0.002*\"one\" + 0.002*\"like\" + 0.001*\"back\" + 0.001*\"abra\" + 0.001*\"would\" + 0.001*\"could\" + 0.001*\"know\" + 0.001*\"little\"\n",
      "2017-11-02 19:37:39,525 : INFO : topic #8 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.004*\"like\" + 0.003*\"back\" + 0.003*\"would\" + 0.003*\"could\" + 0.002*\"time\" + 0.002*\"little\" + 0.002*\"looked\" + 0.002*\"know\"\n",
      "2017-11-02 19:37:39,567 : INFO : topic #7 (0.100): 0.000*\"said\" + 0.000*\"one\" + 0.000*\"back\" + 0.000*\"would\" + 0.000*\"thought\" + 0.000*\"could\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"right\" + 0.000*\"see\"\n",
      "2017-11-02 19:37:39,690 : INFO : topic diff=0.060899, rho=0.301511\n"
     ]
    }
   ],
   "source": [
    "# lda2 = models.LdaModel(corpus=corp2, num_topics=10, id2word=id2word2, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T23:37:40.429516Z",
     "start_time": "2017-11-02T23:37:39.921916Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-02 19:37:40,060 : INFO : topic #0 (0.100): 0.005*\"roland\" + 0.004*\"said\" + 0.004*\"one\" + 0.003*\"would\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"eddie\" + 0.002*\"could\" + 0.002*\"susannah\" + 0.002*\"jake\"\n",
      "2017-11-02 19:37:40,086 : INFO : topic #1 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.003*\"would\" + 0.002*\"could\" + 0.002*\"know\" + 0.002*\"little\" + 0.002*\"looked\" + 0.002*\"time\"\n",
      "2017-11-02 19:37:40,132 : INFO : topic #2 (0.100): 0.002*\"said\" + 0.002*\"dan\" + 0.002*\"one\" + 0.002*\"like\" + 0.001*\"back\" + 0.001*\"abra\" + 0.001*\"would\" + 0.001*\"could\" + 0.001*\"know\" + 0.001*\"little\"\n",
      "2017-11-02 19:37:40,180 : INFO : topic #3 (0.100): 0.001*\"wesley\" + 0.000*\"kindle\" + 0.000*\"robbie\" + 0.000*\"said\" + 0.000*\"ur\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"ellen\" + 0.000*\"back\" + 0.000*\"know\"\n",
      "2017-11-02 19:37:40,220 : INFO : topic #4 (0.100): 0.003*\"said\" + 0.002*\"one\" + 0.002*\"danny\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"would\" + 0.002*\"jack\" + 0.001*\"could\" + 0.001*\"time\" + 0.001*\"know\"\n",
      "2017-11-02 19:37:40,267 : INFO : topic #5 (0.100): 0.004*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.002*\"would\" + 0.002*\"could\" + 0.002*\"time\" + 0.002*\"know\" + 0.002*\"little\" + 0.002*\"right\"\n",
      "2017-11-02 19:37:40,295 : INFO : topic #6 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"back\" + 0.002*\"could\" + 0.002*\"know\" + 0.002*\"thought\" + 0.002*\"time\" + 0.002*\"man\"\n",
      "2017-11-02 19:37:40,336 : INFO : topic #7 (0.100): 0.000*\"said\" + 0.000*\"one\" + 0.000*\"back\" + 0.000*\"would\" + 0.000*\"thought\" + 0.000*\"could\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"right\" + 0.000*\"see\"\n",
      "2017-11-02 19:37:40,371 : INFO : topic #8 (0.100): 0.005*\"said\" + 0.004*\"one\" + 0.004*\"like\" + 0.003*\"back\" + 0.003*\"would\" + 0.003*\"could\" + 0.002*\"time\" + 0.002*\"little\" + 0.002*\"looked\" + 0.002*\"know\"\n",
      "2017-11-02 19:37:40,415 : INFO : topic #9 (0.100): 0.000*\"said\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"back\" + 0.000*\"could\" + 0.000*\"would\" + 0.000*\"know\" + 0.000*\"thought\" + 0.000*\"right\" + 0.000*\"looked\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.005*\"roland\" + 0.004*\"said\" + 0.004*\"one\" + 0.003*\"would\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"eddie\" + 0.002*\"could\" + 0.002*\"susannah\" + 0.002*\"jake\"'),\n",
       " (1,\n",
       "  '0.005*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.003*\"would\" + 0.002*\"could\" + 0.002*\"know\" + 0.002*\"little\" + 0.002*\"looked\" + 0.002*\"time\"'),\n",
       " (2,\n",
       "  '0.002*\"said\" + 0.002*\"dan\" + 0.002*\"one\" + 0.002*\"like\" + 0.001*\"back\" + 0.001*\"abra\" + 0.001*\"would\" + 0.001*\"could\" + 0.001*\"know\" + 0.001*\"little\"'),\n",
       " (3,\n",
       "  '0.001*\"wesley\" + 0.000*\"kindle\" + 0.000*\"robbie\" + 0.000*\"said\" + 0.000*\"ur\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"ellen\" + 0.000*\"back\" + 0.000*\"know\"'),\n",
       " (4,\n",
       "  '0.003*\"said\" + 0.002*\"one\" + 0.002*\"danny\" + 0.002*\"like\" + 0.002*\"back\" + 0.002*\"would\" + 0.002*\"jack\" + 0.001*\"could\" + 0.001*\"time\" + 0.001*\"know\"'),\n",
       " (5,\n",
       "  '0.004*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"back\" + 0.002*\"would\" + 0.002*\"could\" + 0.002*\"time\" + 0.002*\"know\" + 0.002*\"little\" + 0.002*\"right\"'),\n",
       " (6,\n",
       "  '0.005*\"said\" + 0.004*\"one\" + 0.003*\"like\" + 0.003*\"would\" + 0.003*\"back\" + 0.002*\"could\" + 0.002*\"know\" + 0.002*\"thought\" + 0.002*\"time\" + 0.002*\"man\"'),\n",
       " (7,\n",
       "  '0.000*\"said\" + 0.000*\"one\" + 0.000*\"back\" + 0.000*\"would\" + 0.000*\"thought\" + 0.000*\"could\" + 0.000*\"like\" + 0.000*\"know\" + 0.000*\"right\" + 0.000*\"see\"'),\n",
       " (8,\n",
       "  '0.005*\"said\" + 0.004*\"one\" + 0.004*\"like\" + 0.003*\"back\" + 0.003*\"would\" + 0.003*\"could\" + 0.002*\"time\" + 0.002*\"little\" + 0.002*\"looked\" + 0.002*\"know\"'),\n",
       " (9,\n",
       "  '0.000*\"said\" + 0.000*\"one\" + 0.000*\"like\" + 0.000*\"back\" + 0.000*\"could\" + 0.000*\"would\" + 0.000*\"know\" + 0.000*\"thought\" + 0.000*\"right\" + 0.000*\"looked\"')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda2.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T18:28:38.767770Z",
     "start_time": "2017-11-03T18:28:38.762790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shan', 'too', 'wasn', 'under', 'about', 'than', 'can', 'further', 'above', 'o', 't', 'herself', 'again', 'at', 'was', 'didn', 'we', 'isn', 'does', 'me', 'i', 'couldn', 'the', 'been', 'she', 'her', \"'\", 'as', 'those', 'then', 'until', 'these', 'when', 'both', 'y', 'before', 'they', 'same', 're', ')', 'each', 'were', 'are', 'mightn', 'mustn', 'nor', 'very', 'of', 'how', 'don', 'any', 'ours', 'your', 'there', 'our', 'm', 'being', 'aren', 'do', 'so', 'am', 'some', 'such', '.', 'did', 'up', 'through', 'not', 'myself', 'you', 'should', 'between', 'out', 'where', 'to', 'weren', 'for', 's', 'haven', 'yourself', 'whom', 'down', '(', 'from', 'my', 'yours', 'ain', 'is', 'yourselves', 'their', 'which', 'what', 've', 'had', 'needn', 'himself', 'more', 'an', 'few', 'here', 'a', 'but', 'below', 'if', '\"', 'why', 'doing', 'all', 'on', 'itself', 'just', 'hadn', 'them', 'own', 'hasn', 'only', 'will', 'wouldn', 'be', 'him', ',', 'shouldn', 'by', 'against', 'with', 'it', 'into', 'he', 'theirs', 'ourselves', 'd', 'and', 'now', 'll', 'no', 'most', 'having', 'because', 'once', 'themselves', 'off', 'his', 'in', 'other', 'while', 'during', 'ma', 'this', 'hers', 'doesn', 'over', 'won', 'or', 'has', 'after', 'who', 'that', 'have', 'its'}\n"
     ]
    }
   ],
   "source": [
    "# print(stoplist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Scrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Splitting the text for just the story content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T20:37:19.451144Z",
     "start_time": "2017-11-01T20:37:19.447273Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start = gs_text.find('******start_of_file******')+25\n",
    "# end = gs_text.find('******end_of_file******')\n",
    "# gs_text = gs_text[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-01T20:38:21.803187Z",
     "start_time": "2017-11-01T20:38:21.798369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ble final battle.\\n\\n'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gs_text[-20:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:42:12.701995Z",
     "start_time": "2017-11-04T19:42:12.694825Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# words = [''.join(words) for words in gs_text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T19:04:35.541898Z",
     "start_time": "2017-11-02T19:04:35.494259Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "n = 1\n",
    "words = [w for w in words if w not in stoplist]\n",
    "bigrams = ngrams(words, n)\n",
    "counter += Counter(bigrams)\n",
    "\n",
    "sorted_counter = sorted(counter.items(), key=operator.itemgetter(1),reverse=True)\n",
    "# for word, count in gBlob.word_counts.items():\n",
    "#     print(\"%15s %i\" % (word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T19:04:36.793976Z",
     "start_time": "2017-11-02T19:04:36.743195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('gunslinger',), 531),\n",
       " (('man',), 243),\n",
       " (('boy',), 236),\n",
       " (('one',), 218),\n",
       " (('like',), 201),\n",
       " (('would',), 186),\n",
       " (('“i',), 169),\n",
       " (('black',), 156),\n",
       " (('said.',), 151),\n",
       " (('looked',), 147),\n",
       " (('back',), 143),\n",
       " (('could',), 136),\n",
       " (('said',), 129),\n",
       " (('jake',), 120),\n",
       " (('made',), 103),\n",
       " (('don’t',), 99),\n",
       " (('even',), 92),\n",
       " (('him.',), 92),\n",
       " (('it.',), 90),\n",
       " (('him,',), 89),\n",
       " (('eyes',), 88),\n",
       " (('seemed',), 87),\n",
       " (('came',), 85),\n",
       " (('roland',), 85),\n",
       " (('face',), 83),\n",
       " (('went',), 82),\n",
       " (('felt',), 81),\n",
       " (('might',), 80),\n",
       " (('way',), 77),\n",
       " (('still',), 77),\n",
       " (('know',), 76),\n",
       " (('time',), 75),\n",
       " (('never',), 74),\n",
       " (('come',), 74),\n",
       " (('“you',), 73),\n",
       " (('see',), 71),\n",
       " (('first',), 69),\n",
       " (('two',), 69),\n",
       " (('thought',), 68),\n",
       " (('cort',), 68),\n",
       " (('began',), 66),\n",
       " (('hands',), 66),\n",
       " (('said,',), 66),\n",
       " (('long',), 65),\n",
       " (('it,',), 65),\n",
       " (('last',), 65),\n",
       " (('go',), 64),\n",
       " (('almost',), 63),\n",
       " (('head',), 60),\n",
       " (('didn’t',), 59),\n",
       " (('saw',), 59),\n",
       " (('perhaps',), 59),\n",
       " (('old',), 58),\n",
       " (('three',), 57),\n",
       " (('think',), 57),\n",
       " (('“the',), 57),\n",
       " (('little',), 55),\n",
       " (('left',), 55),\n",
       " (('light',), 54),\n",
       " (('stood',), 54),\n",
       " (('turned',), 53),\n",
       " (('sound',), 53),\n",
       " (('voice',), 53),\n",
       " (('hand',), 53),\n",
       " (('put',), 52),\n",
       " (('want',), 52),\n",
       " (('around',), 50),\n",
       " (('knew',), 50),\n",
       " (('held',), 49),\n",
       " (('away',), 49),\n",
       " (('brown',), 47),\n",
       " (('dark',), 46),\n",
       " (('something',), 46),\n",
       " (('cuthbert',), 46),\n",
       " (('great',), 45),\n",
       " (('got',), 45),\n",
       " (('toward',), 45),\n",
       " (('tell',), 44),\n",
       " (('let',), 44),\n",
       " (('going',), 44),\n",
       " (('father',), 44),\n",
       " (('get',), 43),\n",
       " (('it’s',), 43),\n",
       " (('yet',), 43),\n",
       " (('moment',), 43),\n",
       " (('walked',), 42),\n",
       " (('far',), 42),\n",
       " (('again.',), 42),\n",
       " (('across',), 42),\n",
       " (('always',), 41),\n",
       " (('again,',), 41),\n",
       " (('boy’s',), 40),\n",
       " (('make',), 39),\n",
       " (('moved',), 39),\n",
       " (('world',), 38),\n",
       " (('although',), 38),\n",
       " (('say',), 38),\n",
       " (('nothing',), 38),\n",
       " (('much',), 38),\n",
       " (('them,',), 38),\n",
       " (('gone',), 38),\n",
       " (('fell',), 38),\n",
       " (('took',), 37),\n",
       " (('looking',), 37),\n",
       " (('them.',), 37),\n",
       " (('sat',), 37),\n",
       " (('enough',), 36),\n",
       " (('right',), 35),\n",
       " (('good',), 35),\n",
       " (('seen',), 35),\n",
       " (('gunslinger’s',), 35),\n",
       " (('beyond',), 35),\n",
       " (('feel',), 34),\n",
       " (('mind',), 34),\n",
       " (('behind',), 34),\n",
       " (('told',), 33),\n",
       " (('end',), 33),\n",
       " (('must',), 33),\n",
       " (('water',), 33),\n",
       " (('i’m',), 32),\n",
       " (('heard',), 32),\n",
       " (('now,',), 32),\n",
       " (('now.',), 32),\n",
       " (('slow',), 31),\n",
       " (('passed',), 31),\n",
       " (('look',), 31),\n",
       " (('you,',), 31),\n",
       " (('another',), 31),\n",
       " (('found',), 31),\n",
       " (('watched',), 31),\n",
       " (('up,',), 31),\n",
       " (('years',), 30),\n",
       " (('day',), 30),\n",
       " (('beneath',), 30),\n",
       " (('smell',), 30),\n",
       " (('dead',), 29),\n",
       " (('side',), 29),\n",
       " (('“what',), 29),\n",
       " (('may',), 28),\n",
       " (('without',), 28),\n",
       " (('body',), 28),\n",
       " (('back.',), 28),\n",
       " (('desert',), 28),\n",
       " (('ever',), 28),\n",
       " (('struck',), 28),\n",
       " (('coming',), 28),\n",
       " (('wind',), 28),\n",
       " (('place',), 28),\n",
       " (('asked.',), 28),\n",
       " (('“he',), 28),\n",
       " (('.”',), 28),\n",
       " (('boys',), 28),\n",
       " (('huge',), 28),\n",
       " (('blood',), 28),\n",
       " (('tower',), 27),\n",
       " (('green',), 27),\n",
       " (('wanted',), 27),\n",
       " (('face.',), 27),\n",
       " (('called',), 27),\n",
       " (('mouth',), 27),\n",
       " (('white',), 27),\n",
       " (('small',), 27),\n",
       " (('asked',), 27),\n",
       " (('suddenly',), 27),\n",
       " (('caught',), 27),\n",
       " (('hawk',), 27),\n",
       " (('feet',), 26),\n",
       " (('high',), 26),\n",
       " (('door',), 26),\n",
       " (('“it',), 26),\n",
       " (('cort’s',), 26),\n",
       " (('that,',), 25),\n",
       " (('mother',), 25),\n",
       " (('every',), 25),\n",
       " (('find',), 25),\n",
       " (('up.',), 25),\n",
       " (('sun',), 25),\n",
       " (('head.',), 25),\n",
       " (('“i’m',), 25),\n",
       " (('“but',), 25),\n",
       " (('new',), 24),\n",
       " (('things',), 24),\n",
       " (('four',), 24),\n",
       " (('eye',), 24),\n",
       " (('take',), 24),\n",
       " (('gunslinger,',), 24),\n",
       " (('on.',), 24),\n",
       " (('reached',), 24),\n",
       " (('also',), 23),\n",
       " (('night',), 23),\n",
       " (('sense',), 23),\n",
       " (('feeling',), 23),\n",
       " (('since',), 23),\n",
       " (('later',), 23),\n",
       " (('open',), 23),\n",
       " (('rising',), 23),\n",
       " (('fire',), 23),\n",
       " (('lay',), 23),\n",
       " (('shook',), 23),\n",
       " (('he’d',), 23),\n",
       " (('kill',), 23),\n",
       " (('become',), 23),\n",
       " (('woman',), 23),\n",
       " (('her.',), 23),\n",
       " (('stone',), 23),\n",
       " (('many',), 22),\n",
       " (('love',), 22),\n",
       " (('need',), 22),\n",
       " (('tiny',), 22),\n",
       " (('spoke',), 22),\n",
       " (('“and',), 22),\n",
       " (('“it’s',), 22),\n",
       " (('face,',), 22),\n",
       " (('allie',), 22),\n",
       " (('probably',), 21),\n",
       " (('me,',), 21),\n",
       " (('maybe',), 21),\n",
       " (('time.',), 21),\n",
       " (('thing',), 21),\n",
       " (('us',), 21),\n",
       " (('beside',), 21),\n",
       " (('turn',), 21),\n",
       " (('words',), 21),\n",
       " (('i’ll',), 21),\n",
       " (('close',), 21),\n",
       " (('nodded',), 21),\n",
       " (('gunslinger.',), 21),\n",
       " (('dropped',), 21),\n",
       " (('hear',), 21),\n",
       " (('boy,',), 21),\n",
       " (('kennerly',), 21),\n",
       " (('rolled',), 21),\n",
       " (('jake’s',), 21),\n",
       " (('rock',), 20),\n",
       " (('you.',), 20),\n",
       " (('watch',), 20),\n",
       " (('large',), 20),\n",
       " (('really',), 20),\n",
       " (('out.',), 20),\n",
       " (('gave',), 20),\n",
       " (('sky',), 20),\n",
       " (('already',), 20),\n",
       " (('blue',), 20),\n",
       " (('drew',), 20),\n",
       " (('eyes,',), 20),\n",
       " (('speak',), 20),\n",
       " (('half',), 19),\n",
       " (('gray',), 19),\n",
       " (('next',), 19),\n",
       " (('can’t',), 19),\n",
       " (('young',), 19),\n",
       " (('lost',), 19),\n",
       " (('remember',), 19),\n",
       " (('guns',), 19),\n",
       " (('light.',), 19),\n",
       " (('shadows',), 19),\n",
       " (('sometimes',), 19),\n",
       " (('“yes.”',), 19),\n",
       " (('eyes.',), 19),\n",
       " (('hard',), 19),\n",
       " (('“all',), 19),\n",
       " (('“do',), 19),\n",
       " (('sleep',), 19),\n",
       " (('time,',), 19),\n",
       " (('fingers',), 19),\n",
       " (('darkness',), 19),\n",
       " (('hair',), 18),\n",
       " (('you’re',), 18),\n",
       " (('able',), 18),\n",
       " (('pushed',), 18),\n",
       " (('final',), 18),\n",
       " (('people',), 18),\n",
       " (('someone',), 18),\n",
       " (('hold',), 18),\n",
       " (('wasn’t',), 18),\n",
       " (('god',), 18),\n",
       " (('followed',), 18),\n",
       " (('threw',), 18),\n",
       " (('know.',), 18),\n",
       " (('“a',), 18),\n",
       " (('stepped',), 18),\n",
       " (('shot',), 18),\n",
       " (('smiled',), 18),\n",
       " (('you.”',), 18),\n",
       " (('arms',), 18),\n",
       " (('nort',), 18),\n",
       " (('arm',), 18),\n",
       " (('stand',), 17),\n",
       " (('full',), 17),\n",
       " (('set',), 17),\n",
       " (('bad',), 17),\n",
       " (('hand.',), 17),\n",
       " (('me.',), 17),\n",
       " (('away,',), 17),\n",
       " (('word',), 17),\n",
       " (('flat',), 17),\n",
       " (('“that’s',), 17),\n",
       " (('hung',), 17),\n",
       " (('it.”',), 17),\n",
       " (('thought.',), 17),\n",
       " (('touched',), 17),\n",
       " (('screamed',), 17),\n",
       " (('none',), 17),\n",
       " (('hax',), 17),\n",
       " (('red',), 16),\n",
       " (('mountains',), 16),\n",
       " (('five',), 16),\n",
       " (('kind',), 16),\n",
       " (('started',), 16),\n",
       " (('idea',), 16),\n",
       " (('ran',), 16),\n",
       " (('somewhere',), 16),\n",
       " (('run',), 16),\n",
       " (('roland’s',), 16),\n",
       " (('given',), 16),\n",
       " (('strange',), 16),\n",
       " (('flew',), 16),\n",
       " (('“i’ll',), 16),\n",
       " (('away.',), 16),\n",
       " (('closed',), 16),\n",
       " (('won’t',), 16),\n",
       " (('sheb',), 16),\n",
       " (('heavy',), 16),\n",
       " (('filled',), 16),\n",
       " (('handcar',), 16),\n",
       " (('whole',), 15),\n",
       " (('read',), 15),\n",
       " (('men',), 15),\n",
       " (('age',), 15),\n",
       " (('way,',), 15),\n",
       " (('smoke',), 15),\n",
       " (('ask',), 15),\n",
       " (('part',), 15),\n",
       " (('“not',), 15),\n",
       " (('all,',), 15),\n",
       " (('this,',), 15),\n",
       " (('lips',), 15),\n",
       " (('tracks',), 15),\n",
       " (('wondered',), 15),\n",
       " (('others',), 15),\n",
       " (('corn',), 15),\n",
       " (('name',), 15),\n",
       " (('you?”',), 15),\n",
       " (('“how',), 15),\n",
       " (('nodded.',), 15),\n",
       " (('catch',), 15),\n",
       " (('fire.',), 15),\n",
       " (('black.',), 15),\n",
       " (('onto',), 15),\n",
       " (('stared',), 15),\n",
       " (('faces',), 15),\n",
       " (('led',), 15),\n",
       " (('front',), 15),\n",
       " (('“go',), 15),\n",
       " (('air.',), 15),\n",
       " (('fear',), 15),\n",
       " (('stopped',), 15),\n",
       " (('silent',), 15),\n",
       " (('making',), 14),\n",
       " (('rose',), 14),\n",
       " (('girl',), 14),\n",
       " (('mutants',), 14),\n",
       " (('paused',), 14),\n",
       " (('big',), 14),\n",
       " (('rather',), 14),\n",
       " (('then,',), 14),\n",
       " (('story',), 14),\n",
       " (('comes',), 14),\n",
       " (('carried',), 14),\n",
       " (('smile',), 14),\n",
       " (('done',), 14),\n",
       " (('known',), 14),\n",
       " (('upon',), 14),\n",
       " (('deep',), 14),\n",
       " (('seem',), 14),\n",
       " (('way.',), 14),\n",
       " (('better',), 14),\n",
       " (('there.',), 14),\n",
       " (('brought',), 14),\n",
       " (('yellow',), 14),\n",
       " (('light,',), 14),\n",
       " (('cold',), 14),\n",
       " (('thin',), 14),\n",
       " (('together',), 14),\n",
       " (('mule',), 14),\n",
       " (('ain’t',), 14),\n",
       " (('sudden',), 14),\n",
       " (('turning',), 14),\n",
       " (('dry',), 14),\n",
       " (('hot',), 14),\n",
       " (('“if',), 14),\n",
       " (('nearly',), 14),\n",
       " (('taken',), 14),\n",
       " (('back,',), 14),\n",
       " (('became',), 14),\n",
       " (('holding',), 14),\n",
       " (('pulled',), 14),\n",
       " (('land',), 14),\n",
       " (('air',), 14),\n",
       " (('boy.',), 14),\n",
       " (('marten',), 14),\n",
       " (('either',), 13),\n",
       " (('used',), 13),\n",
       " (('book',), 13),\n",
       " (('writing',), 13),\n",
       " (('(the',), 13),\n",
       " (('sure',), 13),\n",
       " (('begun',), 13),\n",
       " (('that’s',), 13),\n",
       " (('heart',), 13),\n",
       " (('he’s',), 13),\n",
       " (('start',), 13),\n",
       " (('empty',), 13),\n",
       " (('understand',), 13),\n",
       " (('single',), 13),\n",
       " (('line',), 13),\n",
       " (('quite',), 13),\n",
       " (('along',), 13),\n",
       " (('longer',), 13),\n",
       " (('flesh',), 13),\n",
       " (('work',), 13),\n",
       " (('hands.',), 13),\n",
       " (('beginning',), 13),\n",
       " (('right.',), 13),\n",
       " (('give',), 13),\n",
       " (('cut',), 13),\n",
       " (('father’s',), 13),\n",
       " (('huge,',), 13),\n",
       " (('raised',), 13),\n",
       " (('grass',), 13),\n",
       " (('desert.',), 13),\n",
       " (('nothing.',), 13),\n",
       " (('laid',), 13),\n",
       " (('drawn',), 13),\n",
       " (('watching',), 13),\n",
       " (('“then',), 13),\n",
       " (('bird',), 13),\n",
       " (('room',), 13),\n",
       " (('piano',), 13),\n",
       " (('“there',), 13),\n",
       " (('“no',), 13),\n",
       " (('children',), 13),\n",
       " (('water.',), 13),\n",
       " (('there,',), 13),\n",
       " (('more.',), 13),\n",
       " (('shirt',), 13),\n",
       " (('legs',), 13),\n",
       " (('faint',), 13),\n",
       " (('living',), 12),\n",
       " (('walk',), 12),\n",
       " (('(and',), 12),\n",
       " (('least',), 12),\n",
       " (('write',), 12),\n",
       " (('out,',), 12),\n",
       " (('change',), 12),\n",
       " (('fine',), 12),\n",
       " (('fall',), 12),\n",
       " (('whose',), 12),\n",
       " (('side,',), 12),\n",
       " (('trying',), 12),\n",
       " (('clear',), 12),\n",
       " (('man,',), 12),\n",
       " (('point',), 12),\n",
       " (('sand',), 12),\n",
       " (('ate',), 12),\n",
       " (('ancient',), 12),\n",
       " (('moving',), 12),\n",
       " (('steel',), 12),\n",
       " (('town',), 12),\n",
       " (('dweller',), 12),\n",
       " (('afraid',), 12),\n",
       " (('me.”',), 12),\n",
       " (('it?”',), 12),\n",
       " (('other,',), 12),\n",
       " (('earth',), 12),\n",
       " (('touch',), 12),\n",
       " (('killed',), 12),\n",
       " (('“will',), 12),\n",
       " (('slowly',), 12),\n",
       " (('crossed',), 12),\n",
       " (('continued',), 12),\n",
       " (('center',), 12),\n",
       " (('“are',), 12),\n",
       " (('ones',), 12),\n",
       " (('david',), 12),\n",
       " (('cry',), 12),\n",
       " (('thought,',), 12),\n",
       " (('lot',), 11),\n",
       " (('one.',), 11),\n",
       " (('wouldn’t',), 11),\n",
       " (('anything',), 11),\n",
       " (('else',), 11),\n",
       " (('here.',), 11),\n",
       " (('(or',), 11),\n",
       " (('mean',), 11),\n",
       " (('yes,',), 11),\n",
       " (('sort',), 11),\n",
       " (('believe',), 11),\n",
       " (('tried',), 11),\n",
       " (('less',), 11),\n",
       " (('near',), 11),\n",
       " (('“why',), 11),\n",
       " (('urge',), 11),\n",
       " (('thinking',), 11),\n",
       " (('edge',), 11),\n",
       " (('doesn’t',), 11),\n",
       " (('man’s',), 11),\n",
       " (('here,',), 11),\n",
       " (('thick',), 11),\n",
       " (('rain',), 11),\n",
       " (('grin',), 11),\n",
       " (('burned',), 11),\n",
       " (('true',), 11),\n",
       " (('stars',), 11),\n",
       " (('do.”',), 11),\n",
       " (('that?”',), 11),\n",
       " (('rabbit',), 11),\n",
       " (('rest',), 11),\n",
       " (('cigarette',), 11),\n",
       " (('move',), 11),\n",
       " (('wearing',), 11),\n",
       " (('shadow',), 11),\n",
       " (('gold',), 11),\n",
       " (('bright',), 11),\n",
       " (('smile.',), 11),\n",
       " (('knife',), 11),\n",
       " (('“who',), 11),\n",
       " (('wet',), 11),\n",
       " (('not.',), 11),\n",
       " (('faded',), 11),\n",
       " (('trap',), 11),\n",
       " (('“when',), 11),\n",
       " (('feet.',), 11),\n",
       " (('sylvia',), 11),\n",
       " (('know.”',), 11),\n",
       " (('“we',), 11),\n",
       " (('cort,',), 11),\n",
       " (('climbed',), 11),\n",
       " (('king',), 10),\n",
       " (('wide',), 10),\n",
       " (('past',), 10),\n",
       " (('chapter',), 10),\n",
       " (('station',), 10),\n",
       " (('oracle',), 10),\n",
       " (('twice',), 10),\n",
       " (('nineteen,',), 10),\n",
       " (('that.',), 10),\n",
       " (('show',), 10),\n",
       " (('isn’t',), 10),\n",
       " (('down,',), 10),\n",
       " (('card',), 10),\n",
       " (('ring',), 10),\n",
       " (('second',), 10),\n",
       " (('over,',), 10),\n",
       " (('well',), 10),\n",
       " (('tale',), 10),\n",
       " (('her,',), 10),\n",
       " (('call',), 10),\n",
       " (('course,',), 10),\n",
       " (('tower.',), 10),\n",
       " (('except',), 10),\n",
       " (('hall',), 10),\n",
       " (('down.',), 10),\n",
       " (('mind,',), 10),\n",
       " (('was,',), 10),\n",
       " (('grown',), 10),\n",
       " (('mind.',), 10),\n",
       " (('piece',), 10),\n",
       " (('falling',), 10),\n",
       " (('all.',), 10),\n",
       " (('standing',), 10),\n",
       " (('devil-grass',), 10),\n",
       " (('miles',), 10),\n",
       " (('dying',), 10),\n",
       " (('kicked',), 10),\n",
       " (('remains',), 10),\n",
       " (('hadn’t',), 10),\n",
       " (('belly.',), 10),\n",
       " (('wild',), 10),\n",
       " (('shoulder.',), 10),\n",
       " (('laughed',), 10),\n",
       " (('trembling',), 10),\n",
       " (('talk',), 10),\n",
       " (('whatever',), 10),\n",
       " (('folded',), 10),\n",
       " (('right.”',), 10),\n",
       " (('“no.”',), 10),\n",
       " (('playing',), 10),\n",
       " (('leaning',), 10),\n",
       " (('on,',), 10),\n",
       " (('window',), 10),\n",
       " (('“that',), 10),\n",
       " (('meat',), 10),\n",
       " (('“don’t',), 10),\n",
       " (('fingers.',), 10),\n",
       " (('merely',), 10),\n",
       " (('this.',), 10),\n",
       " (('cast',), 10),\n",
       " (('wood',), 10),\n",
       " (('before.',), 10),\n",
       " (('played',), 10),\n",
       " (('softly.',), 10),\n",
       " (('broke',), 10),\n",
       " (('sky.',), 10),\n",
       " (('blind',), 10),\n",
       " (('it,”',), 10),\n",
       " (('handle',), 10),\n",
       " (('opened',), 10),\n",
       " (('times',), 10),\n",
       " (('“what’s',), 10),\n",
       " (('finally',), 10),\n",
       " (('“come',), 10),\n",
       " (('“my',), 10),\n",
       " (('hand,',), 10),\n",
       " (('ripped',), 10),\n",
       " (('drank',), 10),\n",
       " (('mother,',), 10),\n",
       " (('rails',), 10),\n",
       " (('ahead',), 10),\n",
       " (('step',), 10),\n",
       " (('“yes,”',), 10),\n",
       " (('cuthbert’s',), 10),\n",
       " (('west',), 10),\n",
       " (('leave',), 10),\n",
       " (('willow',), 10),\n",
       " (('universe',), 10),\n",
       " (('drawing',), 9),\n",
       " (('loved',), 9),\n",
       " (('running',), 9),\n",
       " (('in,',), 9),\n",
       " (('women',), 9),\n",
       " (('i’d',), 9),\n",
       " (('usually',), 9),\n",
       " (('middle',), 9),\n",
       " (('inside',), 9),\n",
       " (('supposed',), 9),\n",
       " (('grow',), 9),\n",
       " (('waited.',), 9),\n",
       " (('fact',), 9),\n",
       " (('thousand',), 9),\n",
       " (('hundred',), 9),\n",
       " (('please',), 9),\n",
       " (('occurred',), 9),\n",
       " (('live',), 9),\n",
       " (('hate',), 9),\n",
       " (('enjoy',), 9),\n",
       " (('keep',), 9),\n",
       " (('so,',), 9),\n",
       " (('everything',), 9),\n",
       " (('blade',), 9),\n",
       " (('hands,',), 9),\n",
       " (('third',), 9),\n",
       " (('pointed',), 9),\n",
       " (('little.',), 9),\n",
       " (('life',), 9),\n",
       " (('gone.',), 9),\n",
       " (('dust',), 9),\n",
       " (('pull',), 9),\n",
       " (('dreams',), 9),\n",
       " (('days',), 9),\n",
       " (('moment,',), 9),\n",
       " (('guess',), 9),\n",
       " (('“you’ll',), 9),\n",
       " (('head,',), 9),\n",
       " (('steps',), 9),\n",
       " (('dark.',), 9),\n",
       " (('table',), 9),\n",
       " (('ask.',), 9),\n",
       " (('“is',), 9),\n",
       " (('glow',), 9),\n",
       " (('dark,',), 9),\n",
       " (('floor',), 9),\n",
       " (('hostler',), 9),\n",
       " (('picked',), 9),\n",
       " (('me,”',), 9),\n",
       " (('eat',), 9),\n",
       " (('lit',), 9),\n",
       " (('boots',), 9),\n",
       " (('kept',), 9),\n",
       " (('steady',), 9),\n",
       " (('warm',), 9),\n",
       " (('hurt',), 9),\n",
       " (('“you’re',), 9),\n",
       " (('faced',), 9),\n",
       " (('neck',), 9),\n",
       " (('black,',), 9),\n",
       " (('allie,',), 9),\n",
       " (('sleep.',), 9),\n",
       " (('“yes.',), 9),\n",
       " (('seeing',), 9),\n",
       " (('“where',), 9),\n",
       " (('pump',), 9),\n",
       " (('himself.',), 9),\n",
       " (('“she',), 9),\n",
       " (('strong',), 9),\n",
       " (('off.',), 9),\n",
       " (('makes',), 9),\n",
       " (('twisted',), 9),\n",
       " (('kitchen',), 9),\n",
       " (('bring',), 9),\n",
       " (('stable',), 9),\n",
       " (('mrs.',), 9),\n",
       " (('it?',), 9),\n",
       " (('central',), 9),\n",
       " (('guard',), 9),\n",
       " (('river',), 9),\n",
       " (('books',), 8),\n",
       " (('nineteen',), 8),\n",
       " (('number',), 8),\n",
       " (('suppose',), 8),\n",
       " (('late',), 8),\n",
       " (('question.',), 8),\n",
       " (('one’s',), 8),\n",
       " (('then.',), 8),\n",
       " (('forever',), 8),\n",
       " (('twenty',), 8),\n",
       " (('pretty',), 8),\n",
       " (('best',), 8),\n",
       " (('did.',), 8),\n",
       " (('you’ve',), 8),\n",
       " (('novel',), 8),\n",
       " (('tower,',), 8),\n",
       " (('saying',), 8),\n",
       " (('couldn’t',), 8),\n",
       " (('question',), 8),\n",
       " (('real',), 8),\n",
       " (('hardly',), 8),\n",
       " (('hell',), 8),\n",
       " (('year',), 8),\n",
       " (('volume',), 8),\n",
       " (('you’ll',), 8),\n",
       " (('finished',), 8),\n",
       " (('years.',), 8),\n",
       " (('begin',), 8),\n",
       " (('spring',), 8),\n",
       " (('world.',), 8),\n",
       " (('door.',), 8),\n",
       " (('alone',), 8),\n",
       " (('mother’s',), 8),\n",
       " (('sweet',), 8),\n",
       " (('occasional',), 8),\n",
       " (('sign',), 8),\n",
       " (('track',), 8),\n",
       " (('swung',), 8),\n",
       " (('bit',), 8),\n",
       " (('others.',), 8),\n",
       " (('short',), 8),\n",
       " (('fire,',), 8),\n",
       " (('straight',), 8),\n",
       " (('so.',), 8),\n",
       " (('grass,',), 8),\n",
       " (('stay',), 8),\n",
       " (('slept.',), 8),\n",
       " (('in.',), 8),\n",
       " (('coach',), 8),\n",
       " (('break',), 8),\n",
       " (('you,”',), 8),\n",
       " (('zoltan',), 8),\n",
       " (('horse',), 8),\n",
       " (('too.',), 8),\n",
       " (('drop',), 8),\n",
       " (('water,',), 8),\n",
       " (('named',), 8),\n",
       " (('dull',), 8),\n",
       " (('asked,',), 8),\n",
       " (('open.',), 8),\n",
       " (('man.',), 8),\n",
       " (('day.',), 8),\n",
       " (('dust.',), 8),\n",
       " (('dim',), 8),\n",
       " (('loose',), 8),\n",
       " (('forward,',), 8),\n",
       " (('answer.',), 8),\n",
       " (('broken',), 8),\n",
       " (('bar',), 8),\n",
       " (('wore',), 8),\n",
       " (('forehead.',), 8),\n",
       " (('meant',), 8),\n",
       " (('nodded,',), 8),\n",
       " (('smiling',), 8),\n",
       " (('color',), 8),\n",
       " (('aware',), 8),\n",
       " (('push',), 8),\n",
       " (('staring',), 8),\n",
       " (('itself.',), 8),\n",
       " (('“no,”',), 8),\n",
       " (('worn',), 8),\n",
       " (('hood',), 8),\n",
       " (('mixed',), 8),\n",
       " (('within',), 8),\n",
       " (('stick',), 8),\n",
       " (('knowing',), 8),\n",
       " (('path',), 8),\n",
       " (('grew',), 8),\n",
       " (('circle',), 8),\n",
       " (('bed',), 8),\n",
       " (('place.',), 8),\n",
       " (('closer',), 8),\n",
       " (('skin',), 8),\n",
       " (('screaming',), 8),\n",
       " (('demon',), 8),\n",
       " (('wall',), 8),\n",
       " (('ironwood',), 8),\n",
       " (('beat',), 8),\n",
       " (('peered',), 8),\n",
       " (('shoulder',), 8),\n",
       " (('fired',), 8),\n",
       " (('forehead',), 8),\n",
       " (('sent',), 8),\n",
       " (('“let’s',), 8),\n",
       " (('rise',), 8),\n",
       " (('cook',), 8),\n",
       " (('susan',), 8),\n",
       " (('wished',), 8),\n",
       " (('giant',), 8),\n",
       " (('penguin',), 7),\n",
       " (('street,',), 7),\n",
       " (('filling',), 7),\n",
       " (('page',), 7),\n",
       " (('one,',), 7),\n",
       " (('written',), 7),\n",
       " (('truth',), 7),\n",
       " (('world,',), 7),\n",
       " (('pocket',), 7),\n",
       " (('nineteen.',), 7),\n",
       " (('road',), 7),\n",
       " (('i’ve',), 7),\n",
       " (('beer',), 7),\n",
       " (('dream',), 7),\n",
       " (('anyway.',), 7),\n",
       " (('sit',), 7),\n",
       " (('no,',), 7),\n",
       " (('realized',), 7),\n",
       " (('volumes',), 7),\n",
       " (('growing',), 7),\n",
       " (('side.',), 7),\n",
       " (('heads',), 7),\n",
       " (('finish',), 7),\n",
       " (('sick',), 7),\n",
       " (('landed',), 7),\n",
       " (('death',), 7),\n",
       " (('remained',), 7),\n",
       " (('sharp',), 7),\n",
       " (('anyone',), 7),\n",
       " (('period',), 7),\n",
       " (('particularly',), 7),\n",
       " (('telling',), 7),\n",
       " (('deal',), 7),\n",
       " (('hidden',), 7),\n",
       " (('surprised',), 7),\n",
       " (('matter',), 7),\n",
       " (('forgotten',), 7),\n",
       " (('faces.',), 7),\n",
       " (('desert,',), 7),\n",
       " (('death.',), 7),\n",
       " (('hide',), 7),\n",
       " (('carefully',), 7),\n",
       " (('looped',), 7),\n",
       " (('buried',), 7),\n",
       " (('ground',), 7),\n",
       " (('blow',), 7),\n",
       " (('worlds',), 7),\n",
       " (('heat.',), 7),\n",
       " (('hill',), 7),\n",
       " (('scrawny',), 7),\n",
       " (('while.',), 7),\n",
       " (('low',), 7),\n",
       " (('stones',), 7),\n",
       " (('well.',), 7),\n",
       " (('tull,',), 7),\n",
       " (('right,',), 7),\n",
       " (('spread',), 7),\n",
       " (('“tell',), 7),\n",
       " (('expected',), 7),\n",
       " (('brief',), 7),\n",
       " (('halfway',), 7),\n",
       " (('offered',), 7),\n",
       " (('come.',), 7),\n",
       " (('unless',), 7),\n",
       " (('night.',), 7),\n",
       " (('neither',), 7),\n",
       " (('sky,',), 7),\n",
       " (('dead.',), 7),\n",
       " (('main',), 7),\n",
       " (('tull.',), 7),\n",
       " (('bodies',), 7),\n",
       " (('crashed',), 7),\n",
       " (('old,',), 7),\n",
       " (('grasped',), 7),\n",
       " (('outside',), 7),\n",
       " (('floor,',), 7),\n",
       " (('approached',), 7),\n",
       " (('cracked',), 7),\n",
       " (('sees',), 7),\n",
       " (('player',), 7),\n",
       " (('everything.',), 7),\n",
       " (('breathing',), 7),\n",
       " (('grass.',), 7),\n",
       " (('blood.',), 7),\n",
       " (('over.',), 7),\n",
       " (('sleep.”',), 7),\n",
       " (('afternoon',), 7),\n",
       " (('wake',), 7),\n",
       " (('flying',), 7),\n",
       " (('corner,',), 7),\n",
       " (('soft',), 7),\n",
       " (('“get',), 7),\n",
       " (('right,”',), 7),\n",
       " (('leaving',), 7),\n",
       " (('grinned',), 7),\n",
       " (('grinning',), 7),\n",
       " (('waiting',), 7),\n",
       " (('sitting',), 7),\n",
       " (('later,',), 7),\n",
       " (('word.',), 7),\n",
       " (('o’',), 7),\n",
       " (('rolling',), 7),\n",
       " (('getting',), 7),\n",
       " (('you’d',), 7),\n",
       " (('pain',), 7),\n",
       " (('now,”',), 7),\n",
       " (('weight',), 7),\n",
       " (('ten',), 7),\n",
       " (('was.',), 7),\n",
       " (('quick',), 7),\n",
       " (('walking',), 7),\n",
       " (('dressed',), 7),\n",
       " (('perfectly',), 7),\n",
       " (('end,',), 7),\n",
       " (('marten,',), 7),\n",
       " (('jamie',), 7),\n",
       " (('smiled.',), 7),\n",
       " (('granite',), 7),\n",
       " (('trees',), 7),\n",
       " (('jawbone',), 7),\n",
       " (('good.',), 7),\n",
       " (('mechanical',), 7),\n",
       " (('power',), 7),\n",
       " (('darkness.',), 7),\n",
       " (('metal',), 7),\n",
       " (('dead,',), 6),\n",
       " (('business',), 6),\n",
       " (('part,',), 6),\n",
       " (('lands',), 6),\n",
       " (('glass',), 6),\n",
       " (('bones',), 6),\n",
       " (('bullet',), 6),\n",
       " (('silence',), 6),\n",
       " (('facing',), 6),\n",
       " (('following',), 6),\n",
       " (('fallen',), 6),\n",
       " (('street.',), 6),\n",
       " (('rotten',), 6),\n",
       " (('cared',), 6),\n",
       " (('use',), 6),\n",
       " (('met',), 6),\n",
       " (('he’ll',), 6),\n",
       " (('off,',), 6),\n",
       " (('size',), 6),\n",
       " (('there’s',), 6),\n",
       " (('ii',), 6),\n",
       " (('possible',), 6),\n",
       " (('liked',), 6),\n",
       " (('showed',), 6),\n",
       " (('contained',), 6),\n",
       " (('talking',), 6),\n",
       " (('size.',), 6),\n",
       " (('added',), 6),\n",
       " (('iii',), 6),\n",
       " (('somehow',), 6),\n",
       " (('lines',), 6),\n",
       " (('knocked',), 6),\n",
       " (('done,',), 6),\n",
       " (('done.',), 6),\n",
       " (('hope',), 6),\n",
       " (('life.',), 6),\n",
       " (('readers',), 6),\n",
       " (('died',), 6),\n",
       " (('ones.',), 6),\n",
       " (('before,',), 6),\n",
       " (('remain',), 6),\n",
       " (('years,',), 6),\n",
       " (('three.',), 6),\n",
       " (('course',), 6),\n",
       " (('wants',), 6),\n",
       " (('removed',), 6),\n",
       " (('usual',), 6),\n",
       " (('do.',), 6),\n",
       " (('slightly',), 6),\n",
       " (('earth.',), 6),\n",
       " (('cloudy',), 6),\n",
       " (('hat',), 6),\n",
       " (('stretched',), 6),\n",
       " (('crumbled',), 6),\n",
       " (('oddly',), 6),\n",
       " (('answer',), 6),\n",
       " (('bitter',), 6),\n",
       " (('camp',), 6),\n",
       " (('letting',), 6),\n",
       " (('wind.',), 6),\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T19:54:18.043109Z",
     "start_time": "2017-11-03T19:54:18.039911Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_books = db.books.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T22:51:36.658485Z",
     "start_time": "2017-11-04T22:51:36.654272Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=['title','isbn','text'])\n",
    "# for book in all_books:\n",
    "#     df2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T22:51:36.859492Z",
     "start_time": "2017-11-04T22:51:36.854045Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# book_counts = {}\n",
    "# for book in all_books:\n",
    "#     title,counts = book_word_count(book,1)\n",
    "#     book_counts[title] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T22:51:37.085862Z",
     "start_time": "2017-11-04T22:51:37.081933Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean_books = []\n",
    "# for book in all_books:\n",
    "#     text = clean_text(book)\n",
    "#     clean_books.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T22:51:41.383281Z",
     "start_time": "2017-11-04T22:51:41.380214Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# book_list = sorted(book_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T22:51:43.830724Z",
     "start_time": "2017-11-04T22:51:43.827125Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_books = ['Gunslinger, The','Drawing of the Three, The','Waste Lands, The',\n",
    "            'Wizard and Glass','Wolves of the Calla','Song of Susannah','Dark Tower, The']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-02T21:34:52.276435Z",
     "start_time": "2017-11-02T21:34:52.272037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gunslinger, The', 'Drawing of the Three, The', 'Waste Lands, The', 'Wizard and Glass', 'Wolves of the Calla', 'Song of Susannah', 'Dark Tower, The']\n"
     ]
    }
   ],
   "source": [
    "print(dt_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T22:51:46.255349Z",
     "start_time": "2017-11-04T22:51:46.251254Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_books = db.books.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T22:51:50.018258Z",
     "start_time": "2017-11-04T22:51:50.014685Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all_text = []\n",
    "# for book in all_books:\n",
    "#     text = clean_text(book)\n",
    "#     all_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T22:51:01.248141Z",
     "start_time": "2017-11-04T22:51:01.242598Z"
    }
   },
   "outputs": [],
   "source": [
    "# dt_text = []\n",
    "# for book in all_books:\n",
    "#     if book['title'] in dt_books:\n",
    "#         text  = clean_text(book)\n",
    "#         name = book['title']\n",
    "#         print(book['title'])\n",
    "#         dt_text.append(text)\n",
    "#     #else:\n",
    "#         #print(\"Haha Fuck you!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T19:50:15.265374Z",
     "start_time": "2017-11-03T19:50:15.260374Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-03T19:51:16.442046Z",
     "start_time": "2017-11-03T19:51:14.140428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "(29598, 7)\n"
     ]
    }
   ],
   "source": [
    "df,corp,id2word = book_cv(dt_text,stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {
    "height": "669px",
    "left": "0px",
    "right": "1228px",
    "top": "90px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
